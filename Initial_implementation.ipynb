{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys, fitz\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import docx2txt\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "import phonenumbers\n",
    "from phonenumbers import geocoder\n",
    "from phonenumbers import carrier\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys,fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Devansh Menaria Third', ['+919024196343'], 'menaria.1@iitj.ac.in', {'MySQL', 'process', 'communication', 'interactive', 'CSS', 'Software Engineering', 'Design', 'Architecture', 'JS', 'Statistics', 'Video', 'Java', 'Js', 'Illustrator', 'Python', 'HTML', 'Operating Systems', 'Programming', 'JavaScript', 'Algorithms', 'Pattern', 'PROGRAMMING', 'Editing', 'RESEARCH PROJECTS', 'Computer Science', 'DESIGN', 'Machine Learning', 'Flask', 'Database', 'Photoshop', 'scheduling', 'Technical', 'algorithms', 'Engineering', 'RESEARCH', 'analysis'}, [('BTech', '2024'), ('CBSE', '2018')], 'Last Updated on 1st December 2022 Devansh Menaria Third Year Undergraduate | Computer Science Engineering | IIT Jodhpur menaria.1@iitj.ac.in | 90241- 96343 EDUCATION IIT JODHPUR Third Year B.Tech in Computer Science Expected 2024 | Jodhpur, India Cum. GPA: 7.88 (Sem 4) DPS, UDAIPUR Class 12 | CBSE 2020 | Udaipur, India Percentage: 94.2% DPS, UDAIPUR Class 10 | CBSE 2018 | Udaipur, India Percentage: 95.2% COURSEWORK UNDERGRADUATE Pattern Recognition and Machine Learning Data Structures and Algorithms Operating Systems Software Engineering Database Management Systems Computer Architecture Design analysis of Algorithms Principles of Programming Languages Maths For Computing Probability and Statistics Mathematics- I, II SKILLS PROGRAMMING Proficient: •Python • C++ Familiar: •Java • Java Script WEB •HTML/CSS/Bootstrap •Django •Express Js •MongoDB •Node.js •React OTHERS •Adobe Premiere Pro •Adobe After Effects •Adobe Photoshop •Adobe Illustrator •Adobe Audition RESEARCH & PROJECTS CPU SCHEDULER VISUALIZER | Course Project Mentor: Dr. Suchetana Chakraborty | Aug 2022 – November 2022 •Applied wide range of CPU scheduling algorithms such as FCFS, LJF, Priority, Round Robin etc. to make a dynamic scheduler for understanding and visualising the different scheduling algorithms. •HTML, CSS, JS, Node.js ACTIVE NOISE CONTROL | Design Credit Project Mentor: Dr. Amrita Puri | December 2021 – May 2022 •Worked on understanding active noise control using different basic algorithms like FxLMS, FxBPNN. Worked on implementing ANC using RNN, RBF and Deep RNN. •Matlab DESIGN CREDITS PORTAL | Course Project Mentor: Dr. Suman Kundu | March 2022 - April 2022 •Portal for communication between Professors and Students of IITJ regarding Design Credits Project Applications. •Solved problem for faculty compiling and communicating with students •Django, Bootstrap FLIGHT TICKET PRICE PREDICTION | Bonus Course Project Mentor: Dr. Richa Singh | May 2022 •Applied ML techniques to make an estimator that predicts flight ticket prices. •Created an interactive front-end page for the user to enter the flight details. •Jupyter Notebook , Python, HTML, CSS, Flask TIME TABLE MANAGER | Course Project Mentor: Dr. Romi Banerjee | Aug 2022 – November 2022 •Developed a time table manager that allows students, admin and class representatives with an effective medium of communication of important information such as time table, notices and personal time tables. •PHP, MySQL Database, HTML, CSS, and JavaScript POSITIONS OF RESPONSIBILITIES 2022-2023 Vice-President, Board of Art Culture | Student Activity Council, IIT Jodhpur •Represented Managed 8 different societies as a part of Board of Art Culture in Student Senate IIT Jodhpur. 2021-2022 Joint Secretary, The Film Making and Video Editing Society | Board of Art and Culture, IIT Jodhpur •Lead the society of 100+ members and managed its activities related to Film Making and Video Editing. 2021-2022 Student Guide | Student Well-being Committee, IIT Jodhpur. •Guided 10 Freshers and helped 450+ students during the registration process, conducted different events as a part of student well-being committee 2022 Assistant Head | Prometeo, The Technical and Entrepreneurial Fest, IIT Jodhpur •Managed the fest with an online footfall of over 5000 attendees. ')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class resumeExtraction:\n",
    "    def __init__(self):\n",
    "        self.STOPWORDS = set(stopwords.words('english')+['``',\"''\"])\n",
    "        # Education Degrees\n",
    "        self.EDUCATION = [\n",
    "                    'BE', 'BSC', 'BS', \n",
    "                    'ME','MS','BCOM','BCS','BCA','MCA',\n",
    "                    'BTECH', 'MTECH','DIPLOMA','12TH','10TH',\n",
    "                    'SSC', 'HSC', 'CBSE', 'ICSE', 'X', 'XII', 'XTH','XIITH','FE','SE','TE'\n",
    "                ]\n",
    "        self.data= pd.read_csv(r\"C:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\ResumeRanker_Shared\\assets\\data\\newskill2.csv\") \n",
    "        self.SKILLS_DB = list(self.data.columns.values)\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        self.matcher = Matcher(self.nlp.vocab)\n",
    "    \n",
    "    def __clean_text(self,resume_text):\n",
    "        resume_text = re.sub('http\\S+\\s*', ' ', resume_text)  # remove URLs\n",
    "        resume_text = re.sub('RT|cc', ' ', resume_text)  # remove RT and cc\n",
    "        resume_text = re.sub('#\\S+', '', resume_text)  # remove hashtags\n",
    "        resume_text = re.sub('@\\S+', '  ', resume_text)  # remove mentions\n",
    "        resume_text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resume_text)  # remove punctuations\n",
    "        resume_text = re.sub(r'[^\\x00-\\x7f]',r' ', resume_text) \n",
    "        resume_text = re.sub('\\s+', ' ', resume_text)  # remove extra whitespace\n",
    "        resume_text = resume_text.lower()  # convert to lowercase\n",
    "        resume_text_tokens = word_tokenize(resume_text)  # tokenize\n",
    "        filtered_text = [w for w in resume_text_tokens if not w in self.STOPWORDS]  # remove stopwords\n",
    "        return ' '.join(filtered_text)\n",
    "       \n",
    "    def __extract_name(self,resume_text):\n",
    "        #gave little inaccurate results\n",
    "        nlp_text = self.nlp(resume_text)\n",
    "        pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "        \n",
    "        self.matcher.add('NAME',[pattern])\n",
    "        \n",
    "        matches = self.matcher(nlp_text)\n",
    "        for match_id, start, end in matches:\n",
    "            span = nlp_text[start:end+1]\n",
    "            return span.text\n",
    "        \n",
    "        #the below code extracts all the nouns\n",
    "        # Sentences = nltk.sent_tokenize(resume_text)\n",
    "        # Tokens = []\n",
    "        # for Sent in Sentences:\n",
    "        #     Tokens.append(nltk.word_tokenize(Sent)) \n",
    "        # Words_List = [nltk.pos_tag(Token) for Token in Tokens]\n",
    "\n",
    "        # Nouns_List = []\n",
    "\n",
    "        # for List in Words_List:\n",
    "        #     for Word in List:\n",
    "        #         if re.match('[NN.*]', Word[1]):\n",
    "        #             Nouns_List.append(Word[0])\n",
    "\n",
    "        # Names = []\n",
    "        # for Nouns in Nouns_List:\n",
    "        #     if not wordnet.synsets(Nouns):\n",
    "        #         Names.append(Nouns)\n",
    "\n",
    "        # return Names\n",
    "       \n",
    "    \n",
    "    def __extract_mobile_number(self,text):\n",
    "        # phone = re.findall(re.compile(r'(?:(?:\\+?([1-9]|[0-9][0-9]|[0-9][0-9][0-9])\\s*(?:[.-]\\s*)?)?(?:\\(\\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|([0-9][1-9]|[0-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?([0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(\\d+))?'), text)\n",
    "        # if phone:\n",
    "        #     number = ''.join(phone[0])\n",
    "        #     if len(number) > 10:\n",
    "        #         return '+' + number\n",
    "        #     else:\n",
    "        #         return number\n",
    "        numbers = []\n",
    "        for match in phonenumbers.PhoneNumberMatcher(text, \"IN\"):  # Replace \"IN\" with the appropriate country code\n",
    "            numbers.append(phonenumbers.format_number(match.number, phonenumbers.PhoneNumberFormat.E164))\n",
    "        return numbers\n",
    "        \n",
    "    def __extract_email(self,email):\n",
    "        email = re.findall(\"([^@|\\s]+@[^@]+\\.[^@|\\s]+)\", email)\n",
    "        if email:\n",
    "            try:\n",
    "                return email[0].split()[0].strip(';')\n",
    "            except IndexError:\n",
    "                return None\n",
    "    \n",
    "    def __extract_education(self,resume_text):\n",
    "        nlp_text = self.nlp(resume_text)\n",
    "        \n",
    "        # Sentence Tokenizer\n",
    "        nlp_text = [str(sent).strip() for sent in nlp_text.sents]\n",
    "        edu = {}\n",
    "        # Extract education degree\n",
    "        for index, text in enumerate(nlp_text):\n",
    "            for tex in text.split():\n",
    "                # Replace all special symbols\n",
    "                tex = re.sub(r'[?|$|.|!|,|(|)]', r'', tex)\n",
    "                if tex.upper() in self.EDUCATION and tex not in self.STOPWORDS:\n",
    "                    edu[tex] = text + nlp_text[index + 1]\n",
    "                \n",
    "        # Extract year\n",
    "        education = []\n",
    "        for key in edu.keys():\n",
    "            year = re.search(re.compile(r'(((20|19)(\\d{2})))'), edu[key])\n",
    "            if year:\n",
    "                education.append((key, ''.join(year[0])))\n",
    "            else:\n",
    "                education.append(key)\n",
    "        return education\n",
    "    \n",
    "    def __extract_skills(self,input_text):\n",
    "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "        word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
    "\n",
    "        # remove the stop words\n",
    "        filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
    "\n",
    "        # remove the punctuation\n",
    "        filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
    "\n",
    "        # generate bigrams and trigrams (such as artificial intelligence)\n",
    "        bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
    "\n",
    "        # we create a set to keep the results in.\n",
    "        found_skills = set()\n",
    "\n",
    "        # we search for each token in our skills database\n",
    "        for token in filtered_tokens:\n",
    "            if token.lower() in self.SKILLS_DB:\n",
    "                found_skills.add(token)\n",
    "\n",
    "        # we search for each bigram and trigram in our skills database\n",
    "        for ngram in bigrams_trigrams:\n",
    "            if ngram.lower() in self.SKILLS_DB:\n",
    "                found_skills.add(ngram)\n",
    "\n",
    "        return found_skills\n",
    "    \n",
    "    def extractorData(self,file,ext): #\n",
    "        text=\"\"\n",
    "        if ext==\"docx\": \n",
    "            temp = docx2txt.process(file)\n",
    "            text = [line.replace('\\t', ' ') for line in temp.split('\\n') if line]\n",
    "            text = ' '.join(text)\n",
    "        if ext==\"pdf\":\n",
    "            for page in fitz.open(file):\n",
    "                text = text + str(page.get_text())\n",
    "            text = \" \".join(text.split('\\n'))\n",
    "        #text = self.__clean_text(text)\n",
    "        text1=text\n",
    "        name = self.__extract_name(text)\n",
    "        mobile_no = self.__extract_mobile_number(text)\n",
    "        email = self.__extract_email(text)\n",
    "        skills = self.__extract_skills(text)\n",
    "        education1 = self.__extract_education(text)\n",
    "        return (name,mobile_no,email,skills,education1,text1)\n",
    "\n",
    "resumeExtractor = resumeExtraction()\n",
    "\n",
    "print(resumeExtractor.extractorData(fitz.open(r\"C:\\Users\\Asus\\Desktop\\Devansh_CV_latest .pdf\"),\"pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Devansh Menaria Third',\n",
       " ['+919024196343'],\n",
       " 'menaria.1@iitj.ac.in',\n",
       " {'Algorithms',\n",
       "  'Architecture',\n",
       "  'CSS',\n",
       "  'Computer Science',\n",
       "  'DESIGN',\n",
       "  'Database',\n",
       "  'Design',\n",
       "  'Editing',\n",
       "  'Engineering',\n",
       "  'Flask',\n",
       "  'HTML',\n",
       "  'Illustrator',\n",
       "  'JS',\n",
       "  'Java',\n",
       "  'JavaScript',\n",
       "  'Js',\n",
       "  'Machine Learning',\n",
       "  'MySQL',\n",
       "  'Operating Systems',\n",
       "  'PROGRAMMING',\n",
       "  'Pattern',\n",
       "  'Photoshop',\n",
       "  'Programming',\n",
       "  'Python',\n",
       "  'RESEARCH',\n",
       "  'RESEARCH PROJECTS',\n",
       "  'Software Engineering',\n",
       "  'Statistics',\n",
       "  'Technical',\n",
       "  'Video',\n",
       "  'algorithms',\n",
       "  'analysis',\n",
       "  'communication',\n",
       "  'interactive',\n",
       "  'process',\n",
       "  'scheduling'},\n",
       " [('BTech', '2024'), ('CBSE', '2018')],\n",
       " 'Last Updated on 1st December 2022 Devansh Menaria Third Year Undergraduate | Computer Science Engineering | IIT Jodhpur menaria.1@iitj.ac.in | 90241- 96343 EDUCATION IIT JODHPUR Third Year B.Tech in Computer Science Expected 2024 | Jodhpur, India Cum. GPA: 7.88 (Sem 4) DPS, UDAIPUR Class 12 | CBSE 2020 | Udaipur, India Percentage: 94.2% DPS, UDAIPUR Class 10 | CBSE 2018 | Udaipur, India Percentage: 95.2% COURSEWORK UNDERGRADUATE Pattern Recognition and Machine Learning Data Structures and Algorithms Operating Systems Software Engineering Database Management Systems Computer Architecture Design analysis of Algorithms Principles of Programming Languages Maths For Computing Probability and Statistics Mathematics- I, II SKILLS PROGRAMMING Proficient: •Python • C++ Familiar: •Java • Java Script WEB •HTML/CSS/Bootstrap •Django •Express Js •MongoDB •Node.js •React OTHERS •Adobe Premiere Pro •Adobe After Effects •Adobe Photoshop •Adobe Illustrator •Adobe Audition RESEARCH & PROJECTS CPU SCHEDULER VISUALIZER | Course Project Mentor: Dr. Suchetana Chakraborty | Aug 2022 – November 2022 •Applied wide range of CPU scheduling algorithms such as FCFS, LJF, Priority, Round Robin etc. to make a dynamic scheduler for understanding and visualising the different scheduling algorithms. •HTML, CSS, JS, Node.js ACTIVE NOISE CONTROL | Design Credit Project Mentor: Dr. Amrita Puri | December 2021 – May 2022 •Worked on understanding active noise control using different basic algorithms like FxLMS, FxBPNN. Worked on implementing ANC using RNN, RBF and Deep RNN. •Matlab DESIGN CREDITS PORTAL | Course Project Mentor: Dr. Suman Kundu | March 2022 - April 2022 •Portal for communication between Professors and Students of IITJ regarding Design Credits Project Applications. •Solved problem for faculty compiling and communicating with students •Django, Bootstrap FLIGHT TICKET PRICE PREDICTION | Bonus Course Project Mentor: Dr. Richa Singh | May 2022 •Applied ML techniques to make an estimator that predicts flight ticket prices. •Created an interactive front-end page for the user to enter the flight details. •Jupyter Notebook , Python, HTML, CSS, Flask TIME TABLE MANAGER | Course Project Mentor: Dr. Romi Banerjee | Aug 2022 – November 2022 •Developed a time table manager that allows students, admin and class representatives with an effective medium of communication of important information such as time table, notices and personal time tables. •PHP, MySQL Database, HTML, CSS, and JavaScript POSITIONS OF RESPONSIBILITIES 2022-2023 Vice-President, Board of Art Culture | Student Activity Council, IIT Jodhpur •Represented Managed 8 different societies as a part of Board of Art Culture in Student Senate IIT Jodhpur. 2021-2022 Joint Secretary, The Film Making and Video Editing Society | Board of Art and Culture, IIT Jodhpur •Lead the society of 100+ members and managed its activities related to Film Making and Video Editing. 2021-2022 Student Guide | Student Well-being Committee, IIT Jodhpur. •Guided 10 Freshers and helped 450+ students during the registration process, conducted different events as a part of student well-being committee 2022 Assistant Head | Prometeo, The Technical and Entrepreneurial Fest, IIT Jodhpur •Managed the fest with an online footfall of over 5000 attendees. ')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetched_data=resumeExtractor.extractorData(fitz.open(r\"C:\\Users\\Asus\\Desktop\\Devansh_CV_latest .pdf\"),\"pdf\")\n",
    "fetched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resumeScreener:\n",
    "    def __init__(self):\n",
    "        self.setofStopWords = set(stopwords.words('english')+['``',\"''\"])\n",
    "        self.max_length = 500\n",
    "        self.trunc_type = 'post'\n",
    "        self.padding_type = 'post'\n",
    "    \n",
    "    def __cleanResume(self,resumeText):\n",
    "        resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
    "        resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
    "        resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n",
    "        resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
    "        resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
    "        resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n",
    "        resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
    "        resumeText = resumeText.lower()  # convert to lowercase\n",
    "        resumeTextTokens = word_tokenize(resumeText)  # tokenize\n",
    "        filteredText = [w for w in resumeTextTokens if not w in self.setofStopWords]  # remove stopwords\n",
    "        return ' '.join(filteredText)\n",
    "    \n",
    "    def screenResume(self,text):\n",
    "        # Get feature text tokenizer used for model training\n",
    "        with open(r'C:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\ResumeRanker_Shared\\assets\\tokenizer\\feature_tokenizer.pickle', 'rb') as handle:\n",
    "            feature_tokenizer = pickle.load(handle)\n",
    "\n",
    "        # Get label encoding dictionary from model training\n",
    "        with open(r'C:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\ResumeRanker_Shared\\assets\\dictionary\\dictionary.pickle', 'rb') as handle:\n",
    "            encoding_to_label = pickle.load(handle)\n",
    "    \n",
    "        # Handle unknown label case and load original labels\n",
    "        encoding_to_label[0] = 'unknown'\n",
    "        with open(r\"C:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\ResumeRanker_Shared\\assets\\data\\labels.json\", \"r\") as read_file:\n",
    "            original_labels = json.load(read_file)\n",
    "        \n",
    "        cleaned_input = self.__cleanResume(text)\n",
    "        # Convert user input to padded sequence\n",
    "        predict_sequences = feature_tokenizer.texts_to_sequences([cleaned_input])\n",
    "        predict_padded = pad_sequences(predict_sequences, maxlen=self.max_length, padding=self.padding_type, truncating=self.trunc_type)\n",
    "        predict_padded = np.array(predict_padded)\n",
    "        \n",
    "        # Load model and make prediction\n",
    "        model = keras.models.load_model(r'C:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\ResumeRanker_Shared\\assets\\model')\n",
    "        prediction = model.predict(predict_padded)\n",
    "        \n",
    "        # Get encodings of top 5 results\n",
    "        encodings = np.argpartition(prediction[0], -5)[-6:]\n",
    "        encodings = encodings[np.argsort(prediction[0][encodings])]\n",
    "        encodings = reversed(encodings)\n",
    "        \n",
    "        data = {}\n",
    "        # Send results of top 5 encodings and confidences to output\n",
    "        for encoding in encodings:\n",
    "            label = encoding_to_label[encoding]\n",
    "            probability = prediction[0][encoding] * 100\n",
    "            probability = round(probability, 2)\n",
    "            data[original_labels[label]]=probability\n",
    "        \n",
    "        if '.NET Developer' in data.keys():\n",
    "            del(data['.NET Developer'])\n",
    "        return data\n",
    "\n",
    "resumeScreen = resumeScreener()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 234ms/step\n"
     ]
    }
   ],
   "source": [
    "skillsPercentage = resumeScreen.screenResume(fetched_data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Data Scientist': 23.2,\n",
       " 'Web Designer': 7.9,\n",
       " 'Civil Engineer': 6.58,\n",
       " 'DevOps Engineer': 5.65,\n",
       " 'Python Developer': 5.38}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skillsPercentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class jd_profile_comparison:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __matcher(self,job_desc,resume_text):\n",
    "        text=[resume_text,job_desc]\n",
    "        cv=CountVectorizer()\n",
    "        count_matrix=cv.fit_transform(text)\n",
    "        matchper=cosine_similarity(count_matrix)[0][1] * 100\n",
    "        return round(matchper,2)\n",
    "        # model = SentenceTransformer('all-mpnet-base-v2')\n",
    "        # #Encoding:\n",
    "        # score = 0\n",
    "        # sen = job_desc+resume_text\n",
    "        # sen_embeddings = model.encode(sen)\n",
    "        # for i in range(len(job_desc)):\n",
    "        #     if job_desc[i] in resume_text:\n",
    "        #         score += 1\n",
    "        #     else:\n",
    "        #         if max(cosine_similarity([sen_embeddings[i]],sen_embeddings[len(job_desc):])[0]) >= 0.4:\n",
    "        #             score += max(cosine_similarity([sen_embeddings[i]],sen_embeddings[len(job_desc):])[0])\n",
    "        # score = score/len(job_desc)  \n",
    "        # return round(score,3)\n",
    "    \n",
    "    def match(self,jd,resumetext):\n",
    "        return self.__matcher(jd,resumetext)\n",
    "\n",
    "obj_jd_profile_comparison = jd_profile_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractData(file,ext):\n",
    "    text=\"\"\n",
    "    if ext==\"docx\": \n",
    "        temp = docx2txt.process(file)\n",
    "        text = [line.replace('\\t', ' ') for line in temp.split('\\n') if line]\n",
    "        text = ' '.join(text)\n",
    "    if ext==\"pdf\":\n",
    "        for page in fitz.open(file):\n",
    "            text = text + str(page.get_text())\n",
    "        text = \" \".join(text.split('\\n'))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job details: Develop information systems by architecting, designing, and implementing advanced software solutions. Create software by studying business needs, conferring with process owners, and examining systems flow, data usage, and work processes. Author documentation, flowcharts, layouts, diagrams, charts, code comments, and clear code for solutions development. Bachelor’s and/or master’s degree in computer science, computer engineering, data sciences, or related technical discipline 5+ years of professional software development experience Experience with computer vision or nlp Proficiency in Java or C++'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetched_job=extractData(\"C:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\ResumeRanker_Shared\\Implementation\\job_desc.docx\",\"docx\")\n",
    "fetched_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=obj_jd_profile_comparison.match(fetched_job,fetched_data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Last Updated on 1st December 2022 Devansh Menaria Third Year Undergraduate | Computer Science Engineering | IIT Jodhpur menaria.1@iitj.ac.in | 90241- 96343 EDUCATION IIT JODHPUR Third Year B.Tech in Computer Science Expected 2024 | Jodhpur, India Cum. GPA: 7.88 (Sem 4) DPS, UDAIPUR Class 12 | CBSE 2020 | Udaipur, India Percentage: 94.2% DPS, UDAIPUR Class 10 | CBSE 2018 | Udaipur, India Percentage: 95.2% COURSEWORK UNDERGRADUATE Pattern Recognition and Machine Learning Data Structures and Algorithms Operating Systems Software Engineering Database Management Systems Computer Architecture Design analysis of Algorithms Principles of Programming Languages Maths For Computing Probability and Statistics Mathematics- I, II SKILLS PROGRAMMING Proficient: •Python • C++ Familiar: •Java • Java Script WEB •HTML/CSS/Bootstrap •Django •Express Js •MongoDB •Node.js •React OTHERS •Adobe Premiere Pro •Adobe After Effects •Adobe Photoshop •Adobe Illustrator •Adobe Audition RESEARCH & PROJECTS CPU SCHEDULER VISUALIZER | Course Project Mentor: Dr. Suchetana Chakraborty | Aug 2022 – November 2022 •Applied wide range of CPU scheduling algorithms such as FCFS, LJF, Priority, Round Robin etc. to make a dynamic scheduler for understanding and visualising the different scheduling algorithms. •HTML, CSS, JS, Node.js ACTIVE NOISE CONTROL | Design Credit Project Mentor: Dr. Amrita Puri | December 2021 – May 2022 •Worked on understanding active noise control using different basic algorithms like FxLMS, FxBPNN. Worked on implementing ANC using RNN, RBF and Deep RNN. •Matlab DESIGN CREDITS PORTAL | Course Project Mentor: Dr. Suman Kundu | March 2022 - April 2022 •Portal for communication between Professors and Students of IITJ regarding Design Credits Project Applications. •Solved problem for faculty compiling and communicating with students •Django, Bootstrap FLIGHT TICKET PRICE PREDICTION | Bonus Course Project Mentor: Dr. Richa Singh | May 2022 •Applied ML techniques to make an estimator that predicts flight ticket prices. •Created an interactive front-end page for the user to enter the flight details. •Jupyter Notebook , Python, HTML, CSS, Flask TIME TABLE MANAGER | Course Project Mentor: Dr. Romi Banerjee | Aug 2022 – November 2022 •Developed a time table manager that allows students, admin and class representatives with an effective medium of communication of important information such as time table, notices and personal time tables. •PHP, MySQL Database, HTML, CSS, and JavaScript POSITIONS OF RESPONSIBILITIES 2022-2023 Vice-President, Board of Art Culture | Student Activity Council, IIT Jodhpur •Represented Managed 8 different societies as a part of Board of Art Culture in Student Senate IIT Jodhpur. 2021-2022 Joint Secretary, The Film Making and Video Editing Society | Board of Art and Culture, IIT Jodhpur •Lead the society of 100+ members and managed its activities related to Film Making and Video Editing. 2021-2022 Student Guide | Student Well-being Committee, IIT Jodhpur. •Guided 10 Freshers and helped 450+ students during the registration process, conducted different events as a part of student well-being committee 2022 Assistant Head | Prometeo, The Technical and Entrepreneurial Fest, IIT Jodhpur •Managed the fest with an online footfall of over 5000 attendees. '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetched_data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.14"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Computer Skills: â¢ Proficient in MS office (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Testing</td>\n",
       "      <td>â Willingness to accept the challenges. â ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Testing</td>\n",
       "      <td>PERSONAL SKILLS â¢ Quick learner, â¢ Eagerne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Testing</td>\n",
       "      <td>COMPUTER SKILLS &amp; SOFTWARE KNOWLEDGE MS-Power ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Skill Set OS Windows XP/7/8/8.1/10 Database MY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                                             Resume\n",
       "0    Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1    Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2    Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3    Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4    Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...\n",
       "..            ...                                                ...\n",
       "957       Testing  Computer Skills: â¢ Proficient in MS office (...\n",
       "958       Testing  â Willingness to accept the challenges. â ...\n",
       "959       Testing  PERSONAL SKILLS â¢ Quick learner, â¢ Eagerne...\n",
       "960       Testing  COMPUTER SKILLS & SOFTWARE KNOWLEDGE MS-Power ...\n",
       "961       Testing  Skill Set OS Windows XP/7/8/8.1/10 Database MY...\n",
       "\n",
       "[962 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\ResumeRanker_Shared\\assets\\data\\UpdatedResumeDataSet.csv\", engine='python')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.Category != 'Testing']\n",
    "data_size = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_set = set(stopwords.words('english')+['``',\"''\"])\n",
    "def clean_text(resume_text):\n",
    "    resume_text = re.sub('http\\S+\\s*', ' ', resume_text)  # remove URLs\n",
    "    resume_text = re.sub('RT|cc', ' ', resume_text)  # remove RT and cc\n",
    "    resume_text = re.sub('#\\S+', '', resume_text)  # remove hashtags\n",
    "    resume_text = re.sub('@\\S+', '  ', resume_text)  # remove mentions\n",
    "    resume_text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resume_text)  # remove punctuations\n",
    "    resume_text = re.sub(r'[^\\x00-\\x7f]',r' ', resume_text) \n",
    "    resume_text = re.sub('\\s+', ' ', resume_text)  # remove extra whitespace\n",
    "    resume_text = resume_text.lower()  # convert to lowercase\n",
    "    resume_text_tokens = word_tokenize(resume_text)  # tokenize\n",
    "    filtered_text = [w for w in resume_text_tokens if not w in stopwords_set]  # remove stopwords\n",
    "    return ' '.join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original resume ---\n",
      "Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details \n",
      "\n",
      "Data Science Assurance Associate \n",
      "\n",
      "Data Science Assurance Associate - Ernst & Young LLP\n",
      "Skill Details \n",
      "JAVASCRIPT- Exprience - 24 months\n",
      "jQuery- Exprience - 24 months\n",
      "Python- Exprience - 24 monthsCompany Details \n",
      "company - Ernst & Young LLP\n",
      "description - Fraud Investigations and Dispute Services   Assurance\n",
      "TECHNOLOGY ASSISTED REVIEW\n",
      "TAR (Technology Assisted Review) assists in accelerating the review process and run analytics and generate reports.\n",
      "* Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain, this tool implements predictive coding and topic modelling by automating reviews, resulting in reduced labor costs and time spent during the lawyers review.\n",
      "* Understand the end to end flow of the solution, doing research and development for classification models, predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool.\n",
      "* TAR assists in predictive coding, topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify \"red flags\" and fraud-related issues.\n",
      "\n",
      "Tools & Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine similarity, NaÃ¯ve Bayes, LDA, NMF for topic modelling, Vader and text blob for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\n",
      "\n",
      "MULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\n",
      "TEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year. Performed sentiment (Positive, Negative & Neutral) and time series analysis on customer comments across all 4 categories.\n",
      "* Created heat map of terms by survey category based on frequency of words * Extracted Positive and Negative words across all the Survey categories and plotted Word cloud.\n",
      "* Created customized tableau dashboards for effective reporting and visualizations.\n",
      "CHATBOT * Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation, reservation options and so on.\n",
      "* This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer.\n",
      "* This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant /recommended questions.\n",
      "\n",
      "Tools & Technologies: Python, Natural language processing, NLTK, spacy, topic modelling, Sentiment analysis, Word Embedding, scikit-learn, JavaScript/JQuery, SqlServer\n",
      "\n",
      "INFORMATION GOVERNANCE\n",
      "Organizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk.\n",
      "* Scan data from multiple sources of formats and parse different file formats, extract Meta data information, push results for indexing elastic search and created customized, interactive dashboards using kibana.\n",
      "* Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant, Outdated, or Trivial.\n",
      "* Preforming full-text search analysis on elastic search with predefined methods which can tag as (PII) personally identifiable information (social security numbers, addresses, names, etc.) which frequently targeted during cyber-attacks.\n",
      "Tools & Technologies: Python, Flask, Elastic Search, Kibana\n",
      "\n",
      "FRAUD ANALYTIC PLATFORM\n",
      "Fraud Analytics and investigative platform to review all red flag cases.\n",
      "â¢ FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems.\n",
      "* It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics\n",
      "Tools & Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, Node.js, D3.js, DC.js\n"
     ]
    }
   ],
   "source": [
    "# Print a sample original resume\n",
    "print('--- Original resume ---')\n",
    "print(data['Resume'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cleaned resume ---\n",
      "skills programming languages python pandas numpy scipy scikit learn matplotlib sql java javascript jquery machine learning regression svm na bayes knn random forest decision trees boosting techniques cluster analysis word embedding sentiment analysis natural language processing dimensionality reduction topic modelling lda nmf pca neural nets database visualizations mysql sqlserver cassandra hbase elasticsearch d3 js dc js plotly kibana matplotlib ggplot tableau others regular expression html css angular 6 logstash kafka python flask git docker computer vision open cv understanding deep learning education details data science assurance associate data science assurance associate ernst young llp skill details javascript exprience 24 months jquery exprience 24 months python exprience 24 monthscompany details company ernst young llp description fraud investigations dispute services assurance technology assisted review tar technology assisted review assists elerating review process run analytics generate reports core member team helped developing automated review platform tool scratch assisting e discovery domain tool implements predictive coding topic modelling automating reviews resulting reduced labor costs time spent lawyers review understand end end flow solution research development classification models predictive analysis mining information present text data worked analyzing outputs precision monitoring entire tool tar assists predictive coding topic modelling evidence following ey standards developed classifier models order identify red flags fraud related issues tools technologies python scikit learn tfidf word2vec doc2vec cosine similarity na bayes lda nmf topic modelling vader text blob sentiment analysis matplot lib tableau dashboard reporting multiple data science analytic projects usa clients text analytics motor vehicle customer review data received customer feedback survey data past one year performed sentiment positive negative neutral time series analysis customer comments across 4 categories created heat map terms survey category based frequency words extracted positive negative words across survey categories plotted word cloud created customized tableau dashboards effective reporting visualizations chatbot developed user friendly chatbot one products handle simple questions hours operation reservation options chat bot serves entire product related questions giving overview tool via qa platform also give recommendation responses user question build chain relevant answer intelligence build pipeline questions per user requirement asks relevant recommended questions tools technologies python natural language processing nltk spacy topic modelling sentiment analysis word embedding scikit learn javascript jquery sqlserver information governance organizations make informed decisions information store integrated information governance portfolio synthesizes intelligence across unstructured data sources facilitates action ensure organizations best positioned counter information risk scan data multiple sources formats parse different file formats extract meta data information push results indexing elastic search created customized interactive dashboards using kibana preforming rot analysis data give information data helps identify content either redundant outdated trivial preforming full text search analysis elastic search predefined methods tag pii personally identifiable information social security numbers addresses names etc frequently targeted cyber attacks tools technologies python flask elastic search kibana fraud analytic platform fraud analytics investigative platform review red flag cases fap fraud analytics investigative platform inbuilt case manager suite analytics various erp systems used clients interrogate ounting systems identifying anomalies indicators fraud running advanced analytics tools technologies html javascript sqlserver jquery css bootstrap node js d3 js dc js\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_1680\\887221286.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['cleaned_resume'] = data.Resume.apply(lambda x: clean_text(x))\n"
     ]
    }
   ],
   "source": [
    "# Print the same resume after text cleaning\n",
    "data['cleaned_resume'] = data.Resume.apply(lambda x: clean_text(x))\n",
    "\n",
    "print('--- Cleaned resume ---')\n",
    "print(data['cleaned_resume'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "      <th>cleaned_resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "      <td>skills programming languages python pandas num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "      <td>education details may 2013 may 2017 b e uit rg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "      <td>areas interest deep learning control system de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "      <td>skills r python sap hana tableau sap hana sql ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "      <td>education details mca ymcaust faridabad haryan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Blockchain</td>\n",
       "      <td>Hobbies â¢ Playing Chess â¢ Solving Rubik's ...</td>\n",
       "      <td>hobbies playing chess solving rubik cube watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Blockchain</td>\n",
       "      <td>Skills Strong CS fundamentals and problem solv...</td>\n",
       "      <td>skills strong cs fundamentals problem solving ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Blockchain</td>\n",
       "      <td>KEY SKILLS: Programing languages: C, C++, Pyth...</td>\n",
       "      <td>key skills programing languages c c python ape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Blockchain</td>\n",
       "      <td>SOFTWARE SKILLS: Languages: C, C++ &amp; java Oper...</td>\n",
       "      <td>software skills languages c c java operating s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>Blockchain</td>\n",
       "      <td>SKILLS Bitcoin, Ethereum Solidity Hyperledger,...</td>\n",
       "      <td>skills bitcoin ethereum solidity hyperledger b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>892 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                                             Resume  \\\n",
       "0    Data Science  Skills * Programming Languages: Python (pandas...   \n",
       "1    Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...   \n",
       "2    Data Science  Areas of Interest Deep Learning, Control Syste...   \n",
       "3    Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...   \n",
       "4    Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...   \n",
       "..            ...                                                ...   \n",
       "887    Blockchain  Hobbies â¢ Playing Chess â¢ Solving Rubik's ...   \n",
       "888    Blockchain  Skills Strong CS fundamentals and problem solv...   \n",
       "889    Blockchain  KEY SKILLS: Programing languages: C, C++, Pyth...   \n",
       "890    Blockchain  SOFTWARE SKILLS: Languages: C, C++ & java Oper...   \n",
       "891    Blockchain  SKILLS Bitcoin, Ethereum Solidity Hyperledger,...   \n",
       "\n",
       "                                        cleaned_resume  \n",
       "0    skills programming languages python pandas num...  \n",
       "1    education details may 2013 may 2017 b e uit rg...  \n",
       "2    areas interest deep learning control system de...  \n",
       "3    skills r python sap hana tableau sap hana sql ...  \n",
       "4    education details mca ymcaust faridabad haryan...  \n",
       "..                                                 ...  \n",
       "887  hobbies playing chess solving rubik cube watch...  \n",
       "888  skills strong cs fundamentals problem solving ...  \n",
       "889  key skills programing languages c c python ape...  \n",
       "890  software skills languages c c java operating s...  \n",
       "891  skills bitcoin ethereum solidity hyperledger b...  \n",
       "\n",
       "[892 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.14"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cv=obj_jd_profile_comparison.match(fetched_job,fetched_data[5])\n",
    "result_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 12.58,\n",
       " 1: 3.87,\n",
       " 2: 9.67,\n",
       " 3: 14.15,\n",
       " 4: 7.13,\n",
       " 5: 7.34,\n",
       " 6: 21.3,\n",
       " 7: 14.09,\n",
       " 8: 16.7,\n",
       " 9: 16.93,\n",
       " 10: 12.58,\n",
       " 11: 3.87,\n",
       " 12: 9.67,\n",
       " 13: 14.15,\n",
       " 14: 7.13,\n",
       " 15: 7.34,\n",
       " 16: 21.3,\n",
       " 17: 14.09,\n",
       " 18: 16.7,\n",
       " 19: 16.93,\n",
       " 20: 12.58,\n",
       " 21: 3.87,\n",
       " 22: 9.67,\n",
       " 23: 14.15,\n",
       " 24: 7.13,\n",
       " 25: 7.34,\n",
       " 26: 21.3,\n",
       " 27: 14.09,\n",
       " 28: 16.7,\n",
       " 29: 16.93,\n",
       " 30: 12.58,\n",
       " 31: 3.87,\n",
       " 32: 9.67,\n",
       " 33: 14.15,\n",
       " 34: 7.13,\n",
       " 35: 7.34,\n",
       " 36: 21.3,\n",
       " 37: 14.09,\n",
       " 38: 16.7,\n",
       " 39: 16.93,\n",
       " 40: 6.34,\n",
       " 41: 6.91,\n",
       " 42: 4.71,\n",
       " 43: 4.55,\n",
       " 44: 4.55,\n",
       " 45: 7.38,\n",
       " 46: 6.63,\n",
       " 47: 6.82,\n",
       " 48: 2.63,\n",
       " 49: 6.46,\n",
       " 50: 19.13,\n",
       " 51: 6.34,\n",
       " 52: 6.91,\n",
       " 53: 4.71,\n",
       " 54: 4.55,\n",
       " 55: 4.55,\n",
       " 56: 7.38,\n",
       " 57: 6.63,\n",
       " 58: 6.82,\n",
       " 59: 2.63,\n",
       " 60: 6.46,\n",
       " 61: 19.13,\n",
       " 62: 6.34,\n",
       " 63: 6.91,\n",
       " 64: 4.71,\n",
       " 65: 4.55,\n",
       " 66: 4.55,\n",
       " 67: 7.38,\n",
       " 68: 6.63,\n",
       " 69: 6.82,\n",
       " 70: 2.63,\n",
       " 71: 6.46,\n",
       " 72: 19.13,\n",
       " 73: 6.34,\n",
       " 74: 6.91,\n",
       " 75: 4.71,\n",
       " 76: 4.55,\n",
       " 77: 4.55,\n",
       " 78: 7.38,\n",
       " 79: 6.63,\n",
       " 80: 6.82,\n",
       " 81: 2.63,\n",
       " 82: 6.46,\n",
       " 83: 19.13,\n",
       " 84: 2.34,\n",
       " 85: 2.95,\n",
       " 86: 4.79,\n",
       " 87: 3.22,\n",
       " 88: 6.86,\n",
       " 89: 5.05,\n",
       " 90: 4.79,\n",
       " 91: 2.29,\n",
       " 92: 4.83,\n",
       " 93: 2.75,\n",
       " 94: 2.34,\n",
       " 95: 2.95,\n",
       " 96: 4.79,\n",
       " 97: 3.22,\n",
       " 98: 6.86,\n",
       " 99: 5.05,\n",
       " 100: 4.79,\n",
       " 101: 2.29,\n",
       " 102: 4.83,\n",
       " 103: 2.75,\n",
       " 104: 6.23,\n",
       " 105: 6.4,\n",
       " 106: 7.95,\n",
       " 107: 4.91,\n",
       " 108: 4.16,\n",
       " 109: 5.13,\n",
       " 110: 6.23,\n",
       " 111: 6.4,\n",
       " 112: 7.95,\n",
       " 113: 4.91,\n",
       " 114: 4.16,\n",
       " 115: 5.13,\n",
       " 116: 6.23,\n",
       " 117: 6.4,\n",
       " 118: 7.95,\n",
       " 119: 4.91,\n",
       " 120: 4.16,\n",
       " 121: 5.13,\n",
       " 122: 6.23,\n",
       " 123: 6.4,\n",
       " 124: 7.95,\n",
       " 125: 4.91,\n",
       " 126: 4.16,\n",
       " 127: 5.13,\n",
       " 128: 6.23,\n",
       " 129: 6.4,\n",
       " 130: 7.95,\n",
       " 131: 4.91,\n",
       " 132: 4.16,\n",
       " 133: 5.13,\n",
       " 134: 6.23,\n",
       " 135: 6.4,\n",
       " 136: 7.95,\n",
       " 137: 4.91,\n",
       " 138: 4.16,\n",
       " 139: 5.13,\n",
       " 140: 7.15,\n",
       " 141: 9.75,\n",
       " 142: 7.15,\n",
       " 143: 2.69,\n",
       " 144: 11.81,\n",
       " 145: 7.15,\n",
       " 146: 9.75,\n",
       " 147: 7.15,\n",
       " 148: 2.69,\n",
       " 149: 11.81,\n",
       " 150: 7.15,\n",
       " 151: 9.75,\n",
       " 152: 7.15,\n",
       " 153: 2.69,\n",
       " 154: 11.81,\n",
       " 155: 7.15,\n",
       " 156: 9.75,\n",
       " 157: 7.15,\n",
       " 158: 2.69,\n",
       " 159: 11.81,\n",
       " 160: 7.15,\n",
       " 161: 9.75,\n",
       " 162: 7.15,\n",
       " 163: 2.69,\n",
       " 164: 11.81,\n",
       " 165: 7.15,\n",
       " 166: 9.75,\n",
       " 167: 7.15,\n",
       " 168: 2.69,\n",
       " 169: 11.81,\n",
       " 170: 7.15,\n",
       " 171: 9.75,\n",
       " 172: 7.15,\n",
       " 173: 2.69,\n",
       " 174: 11.81,\n",
       " 175: 7.15,\n",
       " 176: 9.75,\n",
       " 177: 7.15,\n",
       " 178: 2.69,\n",
       " 179: 11.81,\n",
       " 180: 7.15,\n",
       " 181: 9.75,\n",
       " 182: 7.15,\n",
       " 183: 2.69,\n",
       " 184: 11.81,\n",
       " 185: 12.66,\n",
       " 186: 7.08,\n",
       " 187: 7.09,\n",
       " 188: 5.07,\n",
       " 189: 5.06,\n",
       " 190: 12.66,\n",
       " 191: 7.08,\n",
       " 192: 7.09,\n",
       " 193: 5.07,\n",
       " 194: 5.06,\n",
       " 195: 12.66,\n",
       " 196: 7.08,\n",
       " 197: 7.09,\n",
       " 198: 5.07,\n",
       " 199: 5.06,\n",
       " 200: 12.66,\n",
       " 201: 7.08,\n",
       " 202: 7.09,\n",
       " 203: 5.07,\n",
       " 204: 5.06,\n",
       " 205: 12.66,\n",
       " 206: 7.08,\n",
       " 207: 7.09,\n",
       " 208: 5.07,\n",
       " 209: 5.06,\n",
       " 210: 12.66,\n",
       " 211: 7.08,\n",
       " 212: 7.09,\n",
       " 213: 5.07,\n",
       " 214: 5.06,\n",
       " 215: 12.66,\n",
       " 216: 7.08,\n",
       " 217: 7.09,\n",
       " 218: 5.07,\n",
       " 219: 5.06,\n",
       " 220: 12.66,\n",
       " 221: 7.08,\n",
       " 222: 7.09,\n",
       " 223: 5.07,\n",
       " 224: 5.06,\n",
       " 225: 5.93,\n",
       " 226: 2.8,\n",
       " 227: 4.55,\n",
       " 228: 3.01,\n",
       " 229: 7.83,\n",
       " 230: 5.93,\n",
       " 231: 2.8,\n",
       " 232: 4.55,\n",
       " 233: 3.01,\n",
       " 234: 7.83,\n",
       " 235: 5.93,\n",
       " 236: 2.8,\n",
       " 237: 4.55,\n",
       " 238: 3.01,\n",
       " 239: 7.83,\n",
       " 240: 5.93,\n",
       " 241: 2.8,\n",
       " 242: 4.55,\n",
       " 243: 3.01,\n",
       " 244: 7.83,\n",
       " 245: 5.93,\n",
       " 246: 2.8,\n",
       " 247: 4.55,\n",
       " 248: 3.01,\n",
       " 249: 7.83,\n",
       " 250: 5.93,\n",
       " 251: 2.8,\n",
       " 252: 4.55,\n",
       " 253: 3.01,\n",
       " 254: 7.83,\n",
       " 255: 5.93,\n",
       " 256: 2.8,\n",
       " 257: 4.55,\n",
       " 258: 3.01,\n",
       " 259: 7.83,\n",
       " 260: 5.93,\n",
       " 261: 2.8,\n",
       " 262: 4.55,\n",
       " 263: 3.01,\n",
       " 264: 7.83,\n",
       " 265: 6.2,\n",
       " 266: 1.97,\n",
       " 267: 5.11,\n",
       " 268: 4.6,\n",
       " 269: 8.06,\n",
       " 270: 4.36,\n",
       " 271: 6.2,\n",
       " 272: 1.97,\n",
       " 273: 5.11,\n",
       " 274: 4.6,\n",
       " 275: 8.06,\n",
       " 276: 4.36,\n",
       " 277: 6.2,\n",
       " 278: 1.97,\n",
       " 279: 5.11,\n",
       " 280: 4.6,\n",
       " 281: 8.06,\n",
       " 282: 4.36,\n",
       " 283: 6.2,\n",
       " 284: 1.97,\n",
       " 285: 5.11,\n",
       " 286: 4.6,\n",
       " 287: 8.06,\n",
       " 288: 4.36,\n",
       " 289: 6.2,\n",
       " 290: 1.97,\n",
       " 291: 5.11,\n",
       " 292: 4.6,\n",
       " 293: 8.06,\n",
       " 294: 4.36,\n",
       " 295: 3.81,\n",
       " 296: 4.59,\n",
       " 297: 5.56,\n",
       " 298: 3.94,\n",
       " 299: 8.84,\n",
       " 300: 6.97,\n",
       " 301: 3.81,\n",
       " 302: 4.59,\n",
       " 303: 5.56,\n",
       " 304: 3.94,\n",
       " 305: 8.84,\n",
       " 306: 6.97,\n",
       " 307: 3.81,\n",
       " 308: 4.59,\n",
       " 309: 5.56,\n",
       " 310: 3.94,\n",
       " 311: 8.84,\n",
       " 312: 6.97,\n",
       " 313: 3.81,\n",
       " 314: 4.59,\n",
       " 315: 5.56,\n",
       " 316: 3.94,\n",
       " 317: 8.84,\n",
       " 318: 6.97,\n",
       " 319: 7.48,\n",
       " 320: 7.23,\n",
       " 321: 17.78,\n",
       " 322: 13.86,\n",
       " 323: 14.37,\n",
       " 324: 5.37,\n",
       " 325: 8.13,\n",
       " 326: 8.13,\n",
       " 327: 8.76,\n",
       " 328: 8.81,\n",
       " 329: 12.02,\n",
       " 330: 5.53,\n",
       " 331: 9.01,\n",
       " 332: 18.0,\n",
       " 333: 7.48,\n",
       " 334: 7.23,\n",
       " 335: 17.78,\n",
       " 336: 13.86,\n",
       " 337: 14.37,\n",
       " 338: 5.37,\n",
       " 339: 8.13,\n",
       " 340: 8.13,\n",
       " 341: 8.76,\n",
       " 342: 8.81,\n",
       " 343: 12.02,\n",
       " 344: 5.53,\n",
       " 345: 9.01,\n",
       " 346: 18.0,\n",
       " 347: 7.48,\n",
       " 348: 7.23,\n",
       " 349: 17.78,\n",
       " 350: 13.86,\n",
       " 351: 14.37,\n",
       " 352: 5.37,\n",
       " 353: 8.13,\n",
       " 354: 8.13,\n",
       " 355: 8.76,\n",
       " 356: 8.81,\n",
       " 357: 12.02,\n",
       " 358: 5.53,\n",
       " 359: 9.01,\n",
       " 360: 18.0,\n",
       " 361: 7.48,\n",
       " 362: 7.23,\n",
       " 363: 17.78,\n",
       " 364: 13.86,\n",
       " 365: 14.37,\n",
       " 366: 5.37,\n",
       " 367: 8.13,\n",
       " 368: 8.13,\n",
       " 369: 8.76,\n",
       " 370: 8.81,\n",
       " 371: 12.02,\n",
       " 372: 5.53,\n",
       " 373: 9.01,\n",
       " 374: 18.0,\n",
       " 375: 7.48,\n",
       " 376: 7.23,\n",
       " 377: 17.78,\n",
       " 378: 13.86,\n",
       " 379: 14.37,\n",
       " 380: 5.37,\n",
       " 381: 8.13,\n",
       " 382: 8.13,\n",
       " 383: 8.76,\n",
       " 384: 8.81,\n",
       " 385: 12.02,\n",
       " 386: 5.53,\n",
       " 387: 9.01,\n",
       " 388: 18.0,\n",
       " 389: 7.48,\n",
       " 390: 7.23,\n",
       " 391: 17.78,\n",
       " 392: 13.86,\n",
       " 393: 14.37,\n",
       " 394: 5.37,\n",
       " 395: 8.13,\n",
       " 396: 8.13,\n",
       " 397: 8.76,\n",
       " 398: 8.81,\n",
       " 399: 12.02,\n",
       " 400: 5.53,\n",
       " 401: 9.01,\n",
       " 402: 18.0,\n",
       " 403: 12.89,\n",
       " 404: 11.0,\n",
       " 405: 9.41,\n",
       " 406: 14.16,\n",
       " 407: 5.09,\n",
       " 408: 5.75,\n",
       " 409: 9.41,\n",
       " 410: 14.16,\n",
       " 411: 5.09,\n",
       " 412: 5.75,\n",
       " 413: 9.41,\n",
       " 414: 14.16,\n",
       " 415: 5.09,\n",
       " 416: 5.75,\n",
       " 417: 12.89,\n",
       " 418: 11.0,\n",
       " 419: 9.41,\n",
       " 420: 14.16,\n",
       " 421: 5.09,\n",
       " 422: 5.75,\n",
       " 423: 9.41,\n",
       " 424: 14.16,\n",
       " 425: 5.09,\n",
       " 426: 5.75,\n",
       " 427: 9.41,\n",
       " 428: 14.16,\n",
       " 429: 5.09,\n",
       " 430: 5.75,\n",
       " 431: 9.0,\n",
       " 432: 7.1,\n",
       " 433: 8.54,\n",
       " 434: 6.66,\n",
       " 435: 10.59,\n",
       " 436: 11.47,\n",
       " 437: 9.0,\n",
       " 438: 7.1,\n",
       " 439: 8.54,\n",
       " 440: 6.66,\n",
       " 441: 10.59,\n",
       " 442: 11.47,\n",
       " 443: 9.0,\n",
       " 444: 7.1,\n",
       " 445: 8.54,\n",
       " 446: 6.66,\n",
       " 447: 10.59,\n",
       " 448: 11.47,\n",
       " 449: 9.0,\n",
       " 450: 7.1,\n",
       " 451: 8.54,\n",
       " 452: 6.66,\n",
       " 453: 10.59,\n",
       " 454: 11.47,\n",
       " 455: 6.7,\n",
       " 456: 9.99,\n",
       " 457: 9.32,\n",
       " 458: 7.27,\n",
       " 459: 10.05,\n",
       " 460: 4.97,\n",
       " 461: 3.37,\n",
       " 462: 7.27,\n",
       " 463: 10.05,\n",
       " 464: 7.27,\n",
       " 465: 10.05,\n",
       " 466: 7.27,\n",
       " 467: 10.05,\n",
       " 468: 6.7,\n",
       " 469: 9.99,\n",
       " 470: 9.32,\n",
       " 471: 7.27,\n",
       " 472: 10.05,\n",
       " 473: 4.97,\n",
       " 474: 3.37,\n",
       " 475: 7.27,\n",
       " 476: 10.05,\n",
       " 477: 7.27,\n",
       " 478: 10.05,\n",
       " 479: 7.27,\n",
       " 480: 10.05,\n",
       " 481: 7.98,\n",
       " 482: 4.82,\n",
       " 483: 9.5,\n",
       " 484: 7.19,\n",
       " 485: 3.31,\n",
       " 486: 7.98,\n",
       " 487: 4.82,\n",
       " 488: 9.5,\n",
       " 489: 7.19,\n",
       " 490: 3.31,\n",
       " 491: 7.98,\n",
       " 492: 4.82,\n",
       " 493: 9.5,\n",
       " 494: 7.19,\n",
       " 495: 3.31,\n",
       " 496: 7.98,\n",
       " 497: 4.82,\n",
       " 498: 9.5,\n",
       " 499: 7.19,\n",
       " 500: 3.31,\n",
       " 501: 7.98,\n",
       " 502: 4.82,\n",
       " 503: 9.5,\n",
       " 504: 7.19,\n",
       " 505: 3.31,\n",
       " 506: 7.98,\n",
       " 507: 4.82,\n",
       " 508: 9.5,\n",
       " 509: 7.19,\n",
       " 510: 3.31,\n",
       " 511: 9.33,\n",
       " 512: 7.55,\n",
       " 513: 5.8,\n",
       " 514: 8.6,\n",
       " 515: 9.33,\n",
       " 516: 7.55,\n",
       " 517: 5.8,\n",
       " 518: 8.6,\n",
       " 519: 9.33,\n",
       " 520: 7.55,\n",
       " 521: 5.8,\n",
       " 522: 8.6,\n",
       " 523: 9.33,\n",
       " 524: 7.55,\n",
       " 525: 5.8,\n",
       " 526: 8.6,\n",
       " 527: 9.33,\n",
       " 528: 7.55,\n",
       " 529: 5.8,\n",
       " 530: 8.6,\n",
       " 531: 9.33,\n",
       " 532: 7.55,\n",
       " 533: 5.8,\n",
       " 534: 8.6,\n",
       " 535: 9.33,\n",
       " 536: 7.55,\n",
       " 537: 5.8,\n",
       " 538: 8.6,\n",
       " 539: 9.33,\n",
       " 540: 7.55,\n",
       " 541: 5.8,\n",
       " 542: 8.6,\n",
       " 543: 9.33,\n",
       " 544: 7.55,\n",
       " 545: 5.8,\n",
       " 546: 8.6,\n",
       " 547: 9.33,\n",
       " 548: 7.55,\n",
       " 549: 5.8,\n",
       " 550: 8.6,\n",
       " 551: 9.47,\n",
       " 552: 15.21,\n",
       " 553: 8.77,\n",
       " 554: 5.29,\n",
       " 555: 7.81,\n",
       " 556: 8.13,\n",
       " 557: 9.47,\n",
       " 558: 15.21,\n",
       " 559: 8.77,\n",
       " 560: 5.29,\n",
       " 561: 7.81,\n",
       " 562: 8.13,\n",
       " 563: 9.47,\n",
       " 564: 15.21,\n",
       " 565: 8.77,\n",
       " 566: 5.29,\n",
       " 567: 7.81,\n",
       " 568: 8.13,\n",
       " 569: 9.47,\n",
       " 570: 15.21,\n",
       " 571: 8.77,\n",
       " 572: 5.29,\n",
       " 573: 7.81,\n",
       " 574: 8.13,\n",
       " 575: 9.47,\n",
       " 576: 15.21,\n",
       " 577: 8.77,\n",
       " 578: 5.29,\n",
       " 579: 7.81,\n",
       " 580: 8.13,\n",
       " 581: 9.47,\n",
       " 582: 15.21,\n",
       " 583: 8.77,\n",
       " 584: 5.29,\n",
       " 585: 7.81,\n",
       " 586: 8.13,\n",
       " 587: 9.47,\n",
       " 588: 15.21,\n",
       " 589: 8.77,\n",
       " 590: 5.29,\n",
       " 591: 7.81,\n",
       " 592: 8.13,\n",
       " 593: 9.47,\n",
       " 594: 15.21,\n",
       " 595: 8.77,\n",
       " 596: 5.29,\n",
       " 597: 7.81,\n",
       " 598: 8.13,\n",
       " 599: 6.87,\n",
       " 600: 6.0,\n",
       " 601: 10.85,\n",
       " 602: 8.02,\n",
       " 603: 8.14,\n",
       " 604: 10.14,\n",
       " 605: 7.64,\n",
       " 606: 6.87,\n",
       " 607: 6.0,\n",
       " 608: 10.85,\n",
       " 609: 6.87,\n",
       " 610: 6.0,\n",
       " 611: 10.85,\n",
       " 612: 6.87,\n",
       " 613: 6.0,\n",
       " 614: 10.85,\n",
       " 615: 6.87,\n",
       " 616: 6.0,\n",
       " 617: 10.85,\n",
       " 618: 6.87,\n",
       " 619: 6.0,\n",
       " 620: 10.85,\n",
       " 621: 6.87,\n",
       " 622: 6.0,\n",
       " 623: 10.85,\n",
       " 624: 6.87,\n",
       " 625: 6.0,\n",
       " 626: 10.85,\n",
       " 627: 6.87,\n",
       " 628: 6.0,\n",
       " 629: 10.85,\n",
       " 630: 6.87,\n",
       " 631: 6.0,\n",
       " 632: 10.85,\n",
       " 633: 6.87,\n",
       " 634: 6.0,\n",
       " 635: 10.85,\n",
       " 636: 6.87,\n",
       " 637: 6.0,\n",
       " 638: 10.85,\n",
       " 639: 6.87,\n",
       " 640: 6.0,\n",
       " 641: 10.85,\n",
       " 642: 6.87,\n",
       " 643: 6.0,\n",
       " 644: 10.85,\n",
       " 645: 6.87,\n",
       " 646: 6.0,\n",
       " 647: 10.85,\n",
       " 648: 6.87,\n",
       " 649: 6.0,\n",
       " 650: 10.85,\n",
       " 651: 6.87,\n",
       " 652: 6.0,\n",
       " 653: 10.85,\n",
       " 654: 10.06,\n",
       " 655: 1.65,\n",
       " 656: 7.01,\n",
       " 657: 6.47,\n",
       " 658: 2.61,\n",
       " 659: 10.06,\n",
       " 660: 1.65,\n",
       " 661: 7.01,\n",
       " 662: 6.47,\n",
       " 663: 2.61,\n",
       " 664: 10.06,\n",
       " 665: 1.65,\n",
       " 666: 7.01,\n",
       " 667: 6.47,\n",
       " 668: 2.61,\n",
       " 669: 10.06,\n",
       " 670: 1.65,\n",
       " 671: 7.01,\n",
       " 672: 6.47,\n",
       " 673: 2.61,\n",
       " 674: 10.06,\n",
       " 675: 1.65,\n",
       " 676: 7.01,\n",
       " 677: 6.47,\n",
       " 678: 2.61,\n",
       " 679: 12.11,\n",
       " 680: 7.37,\n",
       " 681: 11.81,\n",
       " 682: 12.11,\n",
       " 683: 7.37,\n",
       " 684: 11.81,\n",
       " 685: 12.11,\n",
       " 686: 7.37,\n",
       " 687: 11.81,\n",
       " 688: 12.11,\n",
       " 689: 7.37,\n",
       " 690: 11.81,\n",
       " 691: 12.11,\n",
       " 692: 7.37,\n",
       " 693: 11.81,\n",
       " 694: 12.11,\n",
       " 695: 7.37,\n",
       " 696: 11.81,\n",
       " 697: 12.11,\n",
       " 698: 7.37,\n",
       " 699: 11.81,\n",
       " 700: 12.11,\n",
       " 701: 7.37,\n",
       " 702: 11.81,\n",
       " 703: 12.11,\n",
       " 704: 7.37,\n",
       " 705: 11.81,\n",
       " 706: 12.11,\n",
       " 707: 7.37,\n",
       " 708: 11.81,\n",
       " 709: 4.49,\n",
       " 710: 4.66,\n",
       " 711: 4.94,\n",
       " 712: 7.74,\n",
       " 713: 5.08,\n",
       " 714: 6.64,\n",
       " 715: 7.14,\n",
       " 716: 6.83,\n",
       " 717: 11.22,\n",
       " 718: 2.88,\n",
       " 719: 9.8,\n",
       " 720: 4.49,\n",
       " 721: 4.66,\n",
       " 722: 4.94,\n",
       " 723: 7.74,\n",
       " 724: 5.08,\n",
       " 725: 6.64,\n",
       " 726: 7.14,\n",
       " 727: 6.83,\n",
       " 728: 11.22,\n",
       " 729: 2.88,\n",
       " 730: 9.8,\n",
       " 731: 4.49,\n",
       " 732: 4.66,\n",
       " 733: 4.94,\n",
       " 734: 7.74,\n",
       " 735: 5.08,\n",
       " 736: 6.64,\n",
       " 737: 7.14,\n",
       " 738: 6.83,\n",
       " 739: 11.22,\n",
       " 740: 2.88,\n",
       " 741: 9.8,\n",
       " 742: 12.22,\n",
       " 743: 5.63,\n",
       " 744: 13.06,\n",
       " 745: 13.09,\n",
       " 746: 12.47,\n",
       " 747: 8.66,\n",
       " 748: 13.81,\n",
       " 749: 12.22,\n",
       " 750: 5.63,\n",
       " 751: 13.06,\n",
       " 752: 13.09,\n",
       " 753: 12.47,\n",
       " 754: 8.66,\n",
       " 755: 13.81,\n",
       " 756: 12.22,\n",
       " 757: 5.63,\n",
       " 758: 13.06,\n",
       " 759: 13.09,\n",
       " 760: 12.47,\n",
       " 761: 8.66,\n",
       " 762: 13.81,\n",
       " 763: 12.22,\n",
       " 764: 5.63,\n",
       " 765: 13.06,\n",
       " 766: 13.09,\n",
       " 767: 12.47,\n",
       " 768: 8.66,\n",
       " 769: 13.81,\n",
       " 770: 12.22,\n",
       " 771: 5.63,\n",
       " 772: 13.06,\n",
       " 773: 13.09,\n",
       " 774: 12.47,\n",
       " 775: 8.66,\n",
       " 776: 13.81,\n",
       " 777: 12.22,\n",
       " 778: 5.63,\n",
       " 779: 13.06,\n",
       " 780: 13.09,\n",
       " 781: 12.47,\n",
       " 782: 8.66,\n",
       " 783: 13.81,\n",
       " 784: 12.32,\n",
       " 785: 11.42,\n",
       " 786: 7.53,\n",
       " 787: 15.02,\n",
       " 788: 7.97,\n",
       " 789: 12.32,\n",
       " 790: 11.42,\n",
       " 791: 7.53,\n",
       " 792: 15.02,\n",
       " 793: 7.97,\n",
       " 794: 12.32,\n",
       " 795: 11.42,\n",
       " 796: 7.53,\n",
       " 797: 15.02,\n",
       " 798: 7.97,\n",
       " 799: 12.32,\n",
       " 800: 11.42,\n",
       " 801: 7.53,\n",
       " 802: 15.02,\n",
       " 803: 7.97,\n",
       " 804: 12.32,\n",
       " 805: 11.42,\n",
       " 806: 7.53,\n",
       " 807: 15.02,\n",
       " 808: 7.97,\n",
       " 809: 12.32,\n",
       " 810: 11.42,\n",
       " 811: 7.53,\n",
       " 812: 15.02,\n",
       " 813: 7.97,\n",
       " 814: 12.32,\n",
       " 815: 11.42,\n",
       " 816: 7.53,\n",
       " 817: 15.02,\n",
       " 818: 7.97,\n",
       " 819: 12.32,\n",
       " 820: 11.42,\n",
       " 821: 7.53,\n",
       " 822: 15.02,\n",
       " 823: 7.97,\n",
       " 824: 2.09,\n",
       " 825: 7.3,\n",
       " 826: 7.83,\n",
       " 827: 13.34,\n",
       " 828: 4.0,\n",
       " 829: 11.8,\n",
       " 830: 5.46,\n",
       " 831: 2.09,\n",
       " 832: 7.3,\n",
       " 833: 7.83,\n",
       " 834: 13.34,\n",
       " 835: 4.0,\n",
       " 836: 11.8,\n",
       " 837: 5.46,\n",
       " 838: 2.09,\n",
       " 839: 7.3,\n",
       " 840: 7.83,\n",
       " 841: 13.34,\n",
       " 842: 4.0,\n",
       " 843: 11.8,\n",
       " 844: 5.46,\n",
       " 845: 2.09,\n",
       " 846: 7.3,\n",
       " 847: 7.83,\n",
       " 848: 13.34,\n",
       " 849: 4.0,\n",
       " 850: 11.8,\n",
       " 851: 5.46,\n",
       " 852: 4.83,\n",
       " 853: 5.67,\n",
       " 854: 8.66,\n",
       " 855: 5.37,\n",
       " 856: 12.23,\n",
       " 857: 4.83,\n",
       " 858: 5.67,\n",
       " 859: 8.66,\n",
       " 860: 5.37,\n",
       " 861: 12.23,\n",
       " 862: 4.83,\n",
       " 863: 5.67,\n",
       " 864: 8.66,\n",
       " 865: 5.37,\n",
       " 866: 12.23,\n",
       " 867: 4.83,\n",
       " 868: 5.67,\n",
       " 869: 8.66,\n",
       " 870: 5.37,\n",
       " 871: 12.23,\n",
       " 872: 4.83,\n",
       " 873: 5.67,\n",
       " 874: 8.66,\n",
       " 875: 5.37,\n",
       " 876: 12.23,\n",
       " 877: 4.83,\n",
       " 878: 5.67,\n",
       " 879: 8.66,\n",
       " 880: 5.37,\n",
       " 881: 12.23,\n",
       " 882: 4.83,\n",
       " 883: 5.67,\n",
       " 884: 8.66,\n",
       " 885: 5.37,\n",
       " 886: 12.23,\n",
       " 887: 4.83,\n",
       " 888: 5.67,\n",
       " 889: 8.66,\n",
       " 890: 5.37,\n",
       " 891: 12.23}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict={}\n",
    "for i in range(data_size):\n",
    "    result=0\n",
    "    result=obj_jd_profile_comparison.match(fetched_job,data['cleaned_resume'][i])\n",
    "    result_dict[i]=result\n",
    "\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "sorted_dict_results = dict(sorted(result_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "top_5_items = dict(list(sorted_dict_results.items())[:5])\n",
    "\n",
    "print(type(top_5_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: 21.3, 16: 21.3, 26: 21.3, 36: 21.3, 50: 19.13}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResumeID</th>\n",
       "      <th>Matching Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>21.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>21.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>21.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>21.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>19.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ResumeID  Matching Percentage\n",
       "0         6                21.30\n",
       "1        16                21.30\n",
       "2        26                21.30\n",
       "3        36                21.30\n",
       "4        50                19.13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df=pd.DataFrame(top_5_items.items(), columns=['ResumeID', 'Matching Percentage'])\n",
    "result_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sentence transformer(BERT) for encoding and calculating matching percentage using sklearn Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matcher(job_desc,resume_text):\n",
    "        text=[job_desc,resume_text]\n",
    "        model = SentenceTransformer('all-mpnet-base-v2')\n",
    "        # sen = job_desc+fetched_data[5]\n",
    "        sen_embeddings = model.encode(text)\n",
    "        # (sen_embeddings).shape\n",
    "        return(cosine_similarity([sen_embeddings[0],sen_embeddings[1]])[0][1])*100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.69018578529358"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=[fetched_job,fetched_data[5]]\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "# sen = job_desc+fetched_data[5]\n",
    "sen_embeddings = model.encode(text)\n",
    "(sen_embeddings).shape\n",
    "(cosine_similarity([sen_embeddings[0],sen_embeddings[1]])[0][1])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 45.70041596889496,\n",
       " 1: 43.4290736913681,\n",
       " 2: 55.628931522369385,\n",
       " 3: 65.97411632537842,\n",
       " 4: 56.498003005981445,\n",
       " 5: 48.541638255119324,\n",
       " 6: 64.64754343032837,\n",
       " 7: 51.64064168930054,\n",
       " 8: 47.55661487579346,\n",
       " 9: 56.20037317276001,\n",
       " 10: 45.70041596889496,\n",
       " 11: 43.4290736913681,\n",
       " 12: 55.628931522369385,\n",
       " 13: 65.97411632537842,\n",
       " 14: 56.498003005981445,\n",
       " 15: 48.541638255119324,\n",
       " 16: 64.64754343032837,\n",
       " 17: 51.64064168930054,\n",
       " 18: 47.55661487579346,\n",
       " 19: 56.20037317276001,\n",
       " 20: 45.70041596889496,\n",
       " 21: 43.4290736913681,\n",
       " 22: 55.628931522369385,\n",
       " 23: 65.97411632537842,\n",
       " 24: 56.498003005981445,\n",
       " 25: 48.541638255119324,\n",
       " 26: 64.64754343032837,\n",
       " 27: 51.64064168930054,\n",
       " 28: 47.55661487579346,\n",
       " 29: 56.20037317276001,\n",
       " 30: 45.70041596889496,\n",
       " 31: 43.4290736913681,\n",
       " 32: 55.628931522369385,\n",
       " 33: 65.97411632537842,\n",
       " 34: 56.498003005981445,\n",
       " 35: 48.541638255119324,\n",
       " 36: 64.64754343032837,\n",
       " 37: 51.64064168930054,\n",
       " 38: 47.55661487579346,\n",
       " 39: 56.20037317276001,\n",
       " 40: 42.76409447193146,\n",
       " 41: 53.820353746414185,\n",
       " 42: 39.59468603134155,\n",
       " 43: 41.41927361488342,\n",
       " 44: 41.41927361488342,\n",
       " 45: 43.6921626329422,\n",
       " 46: 42.92522668838501,\n",
       " 47: 48.1824517250061,\n",
       " 48: 33.57503414154053,\n",
       " 49: 52.365416288375854,\n",
       " 50: 59.32297706604004,\n",
       " 51: 42.76409447193146,\n",
       " 52: 53.820353746414185,\n",
       " 53: 39.59468603134155,\n",
       " 54: 41.41927361488342,\n",
       " 55: 41.41927361488342,\n",
       " 56: 43.6921626329422,\n",
       " 57: 42.92522668838501,\n",
       " 58: 48.1824517250061,\n",
       " 59: 33.57503414154053,\n",
       " 60: 52.365416288375854,\n",
       " 61: 59.32297706604004,\n",
       " 62: 42.76409447193146,\n",
       " 63: 53.820353746414185,\n",
       " 64: 39.59468603134155,\n",
       " 65: 41.41927361488342,\n",
       " 66: 41.41927361488342,\n",
       " 67: 43.6921626329422,\n",
       " 68: 42.92522668838501,\n",
       " 69: 48.1824517250061,\n",
       " 70: 33.57503414154053,\n",
       " 71: 52.365416288375854,\n",
       " 72: 59.32297706604004,\n",
       " 73: 42.76409447193146,\n",
       " 74: 53.820353746414185,\n",
       " 75: 39.59468603134155,\n",
       " 76: 41.41927361488342,\n",
       " 77: 41.41927361488342,\n",
       " 78: 43.6921626329422,\n",
       " 79: 42.92522668838501,\n",
       " 80: 48.1824517250061,\n",
       " 81: 33.57503414154053,\n",
       " 82: 52.365416288375854,\n",
       " 83: 59.32297706604004,\n",
       " 84: 47.585201263427734,\n",
       " 85: 35.62230169773102,\n",
       " 86: 37.00245022773743,\n",
       " 87: 37.86504864692688,\n",
       " 88: 39.41055238246918,\n",
       " 89: 21.31502628326416,\n",
       " 90: 32.025015354156494,\n",
       " 91: 35.13675034046173,\n",
       " 92: 39.18925225734711,\n",
       " 93: 28.65026891231537,\n",
       " 94: 47.585201263427734,\n",
       " 95: 35.62230169773102,\n",
       " 96: 37.00245022773743,\n",
       " 97: 37.86504864692688,\n",
       " 98: 39.41055238246918,\n",
       " 99: 21.31502628326416,\n",
       " 100: 32.025015354156494,\n",
       " 101: 35.13675034046173,\n",
       " 102: 39.18925225734711,\n",
       " 103: 28.65026891231537,\n",
       " 104: 38.87324333190918,\n",
       " 105: 39.29750919342041,\n",
       " 106: 46.96890711784363,\n",
       " 107: 27.31436789035797,\n",
       " 108: 22.273947298526764,\n",
       " 109: 36.52653992176056,\n",
       " 110: 38.87324333190918,\n",
       " 111: 39.29750919342041,\n",
       " 112: 46.96890711784363,\n",
       " 113: 27.31436789035797,\n",
       " 114: 22.273947298526764,\n",
       " 115: 36.52653992176056,\n",
       " 116: 38.87324333190918,\n",
       " 117: 39.29750919342041,\n",
       " 118: 46.96890711784363,\n",
       " 119: 27.31436789035797,\n",
       " 120: 22.273947298526764,\n",
       " 121: 36.52653992176056,\n",
       " 122: 38.87324333190918,\n",
       " 123: 39.29750919342041,\n",
       " 124: 46.96890711784363,\n",
       " 125: 27.31436789035797,\n",
       " 126: 22.273947298526764,\n",
       " 127: 36.52653992176056,\n",
       " 128: 38.87324333190918,\n",
       " 129: 39.29750919342041,\n",
       " 130: 46.96890711784363,\n",
       " 131: 27.31436789035797,\n",
       " 132: 22.273947298526764,\n",
       " 133: 36.52653992176056,\n",
       " 134: 38.87324333190918,\n",
       " 135: 39.29750919342041,\n",
       " 136: 46.96890711784363,\n",
       " 137: 27.31436789035797,\n",
       " 138: 22.273947298526764,\n",
       " 139: 36.52653992176056,\n",
       " 140: 60.29667258262634,\n",
       " 141: 47.19564914703369,\n",
       " 142: 60.29667258262634,\n",
       " 143: 47.826606035232544,\n",
       " 144: 61.11248731613159,\n",
       " 145: 60.29667258262634,\n",
       " 146: 47.19564914703369,\n",
       " 147: 60.29667258262634,\n",
       " 148: 47.826606035232544,\n",
       " 149: 61.11248731613159,\n",
       " 150: 60.29667258262634,\n",
       " 151: 47.19564914703369,\n",
       " 152: 60.29667258262634,\n",
       " 153: 47.826606035232544,\n",
       " 154: 61.11248731613159,\n",
       " 155: 60.29667258262634,\n",
       " 156: 47.19564914703369,\n",
       " 157: 60.29667258262634,\n",
       " 158: 47.826606035232544,\n",
       " 159: 61.11248731613159,\n",
       " 160: 60.29667258262634,\n",
       " 161: 47.19564914703369,\n",
       " 162: 60.29667258262634,\n",
       " 163: 47.826606035232544,\n",
       " 164: 61.11248731613159,\n",
       " 165: 60.29667258262634,\n",
       " 166: 47.19564914703369,\n",
       " 167: 60.29667258262634,\n",
       " 168: 47.826606035232544,\n",
       " 169: 61.11248731613159,\n",
       " 170: 60.29667258262634,\n",
       " 171: 47.19564914703369,\n",
       " 172: 60.29667258262634,\n",
       " 173: 47.826606035232544,\n",
       " 174: 61.11248731613159,\n",
       " 175: 60.29667258262634,\n",
       " 176: 47.19564914703369,\n",
       " 177: 60.29667258262634,\n",
       " 178: 47.826606035232544,\n",
       " 179: 61.11248731613159,\n",
       " 180: 60.29667258262634,\n",
       " 181: 47.19564914703369,\n",
       " 182: 60.29667258262634,\n",
       " 183: 47.826606035232544,\n",
       " 184: 61.11248731613159,\n",
       " 185: 53.48209738731384,\n",
       " 186: 42.54222512245178,\n",
       " 187: 21.103426814079285,\n",
       " 188: 46.49442434310913,\n",
       " 189: 25.737518072128296,\n",
       " 190: 53.48209738731384,\n",
       " 191: 42.54222512245178,\n",
       " 192: 21.103426814079285,\n",
       " 193: 46.49442434310913,\n",
       " 194: 25.737518072128296,\n",
       " 195: 53.48209738731384,\n",
       " 196: 42.54222512245178,\n",
       " 197: 21.103426814079285,\n",
       " 198: 46.49442434310913,\n",
       " 199: 25.737518072128296,\n",
       " 200: 53.48209738731384,\n",
       " 201: 42.54222512245178,\n",
       " 202: 21.103426814079285,\n",
       " 203: 46.49442434310913,\n",
       " 204: 25.737518072128296,\n",
       " 205: 53.48209738731384,\n",
       " 206: 42.54222512245178,\n",
       " 207: 21.103426814079285,\n",
       " 208: 46.49442434310913,\n",
       " 209: 25.737518072128296,\n",
       " 210: 53.48209738731384,\n",
       " 211: 42.54222512245178,\n",
       " 212: 21.103426814079285,\n",
       " 213: 46.49442434310913,\n",
       " 214: 25.737518072128296,\n",
       " 215: 53.48209738731384,\n",
       " 216: 42.54222512245178,\n",
       " 217: 21.103426814079285,\n",
       " 218: 46.49442434310913,\n",
       " 219: 25.737518072128296,\n",
       " 220: 53.48209738731384,\n",
       " 221: 42.54222512245178,\n",
       " 222: 21.103426814079285,\n",
       " 223: 46.49442434310913,\n",
       " 224: 25.737518072128296,\n",
       " 225: 43.142518401145935,\n",
       " 226: 41.548606753349304,\n",
       " 227: 53.85336875915527,\n",
       " 228: 56.646400690078735,\n",
       " 229: 51.600342988967896,\n",
       " 230: 43.142518401145935,\n",
       " 231: 41.548606753349304,\n",
       " 232: 53.85336875915527,\n",
       " 233: 56.646400690078735,\n",
       " 234: 51.600342988967896,\n",
       " 235: 43.142518401145935,\n",
       " 236: 41.548606753349304,\n",
       " 237: 53.85336875915527,\n",
       " 238: 56.646400690078735,\n",
       " 239: 51.600342988967896,\n",
       " 240: 43.142518401145935,\n",
       " 241: 41.548606753349304,\n",
       " 242: 53.85336875915527,\n",
       " 243: 56.646400690078735,\n",
       " 244: 51.600342988967896,\n",
       " 245: 43.142518401145935,\n",
       " 246: 41.548606753349304,\n",
       " 247: 53.85336875915527,\n",
       " 248: 56.646400690078735,\n",
       " 249: 51.600342988967896,\n",
       " 250: 43.142518401145935,\n",
       " 251: 41.548606753349304,\n",
       " 252: 53.85336875915527,\n",
       " 253: 56.646400690078735,\n",
       " 254: 51.600342988967896,\n",
       " 255: 43.142518401145935,\n",
       " 256: 41.548606753349304,\n",
       " 257: 53.85336875915527,\n",
       " 258: 56.646400690078735,\n",
       " 259: 51.600342988967896,\n",
       " 260: 43.142518401145935,\n",
       " 261: 41.548606753349304,\n",
       " 262: 53.85336875915527,\n",
       " 263: 56.646400690078735,\n",
       " 264: 51.600342988967896,\n",
       " 265: 32.38418698310852,\n",
       " 266: 9.09649059176445,\n",
       " 267: 36.981335282325745,\n",
       " 268: 44.01240348815918,\n",
       " 269: 42.59461760520935,\n",
       " 270: 33.646345138549805,\n",
       " 271: 32.38418698310852,\n",
       " 272: 9.09649059176445,\n",
       " 273: 36.981335282325745,\n",
       " 274: 44.01240348815918,\n",
       " 275: 42.59461760520935,\n",
       " 276: 33.646345138549805,\n",
       " 277: 32.38418698310852,\n",
       " 278: 9.09649059176445,\n",
       " 279: 36.981335282325745,\n",
       " 280: 44.01240348815918,\n",
       " 281: 42.59461760520935,\n",
       " 282: 33.646345138549805,\n",
       " 283: 32.38418698310852,\n",
       " 284: 9.09649059176445,\n",
       " 285: 36.981335282325745,\n",
       " 286: 44.01240348815918,\n",
       " 287: 42.59461760520935,\n",
       " 288: 33.646345138549805,\n",
       " 289: 32.38418698310852,\n",
       " 290: 9.09649059176445,\n",
       " 291: 36.981335282325745,\n",
       " 292: 44.01240348815918,\n",
       " 293: 42.59461760520935,\n",
       " 294: 33.646345138549805,\n",
       " 295: 42.02084541320801,\n",
       " 296: 37.87453770637512,\n",
       " 297: 54.55549955368042,\n",
       " 298: 54.41194772720337,\n",
       " 299: 48.292744159698486,\n",
       " 300: 40.034207701683044,\n",
       " 301: 42.02084541320801,\n",
       " 302: 37.87453770637512,\n",
       " 303: 54.55549955368042,\n",
       " 304: 54.41194772720337,\n",
       " 305: 48.292744159698486,\n",
       " 306: 40.034207701683044,\n",
       " 307: 42.02084541320801,\n",
       " 308: 37.87453770637512,\n",
       " 309: 54.55549955368042,\n",
       " 310: 54.41194772720337,\n",
       " 311: 48.292744159698486,\n",
       " 312: 40.034207701683044,\n",
       " 313: 42.02084541320801,\n",
       " 314: 37.87453770637512,\n",
       " 315: 54.55549955368042,\n",
       " 316: 54.41194772720337,\n",
       " 317: 48.292744159698486,\n",
       " 318: 40.034207701683044,\n",
       " 319: 46.44385874271393,\n",
       " 320: 63.4168803691864,\n",
       " 321: 63.607096672058105,\n",
       " 322: 59.66980457305908,\n",
       " 323: 56.321585178375244,\n",
       " 324: 49.936461448669434,\n",
       " 325: 49.95230436325073,\n",
       " 326: 49.95230436325073,\n",
       " 327: 44.930499792099,\n",
       " 328: 51.3884961605072,\n",
       " 329: 56.28567337989807,\n",
       " 330: 54.943132400512695,\n",
       " 331: 55.646997690200806,\n",
       " 332: 59.286123514175415,\n",
       " 333: 46.44385874271393,\n",
       " 334: 63.4168803691864,\n",
       " 335: 63.607096672058105,\n",
       " 336: 59.66980457305908,\n",
       " 337: 56.321585178375244,\n",
       " 338: 49.936461448669434,\n",
       " 339: 49.95230436325073,\n",
       " 340: 49.95230436325073,\n",
       " 341: 44.930499792099,\n",
       " 342: 51.3884961605072,\n",
       " 343: 56.28567337989807,\n",
       " 344: 54.943132400512695,\n",
       " 345: 55.646997690200806,\n",
       " 346: 59.286123514175415,\n",
       " 347: 46.44385874271393,\n",
       " 348: 63.4168803691864,\n",
       " 349: 63.607096672058105,\n",
       " 350: 59.66980457305908,\n",
       " 351: 56.321585178375244,\n",
       " 352: 49.936461448669434,\n",
       " 353: 49.95230436325073,\n",
       " 354: 49.95230436325073,\n",
       " 355: 44.930499792099,\n",
       " 356: 51.3884961605072,\n",
       " 357: 56.28567337989807,\n",
       " 358: 54.943132400512695,\n",
       " 359: 55.646997690200806,\n",
       " 360: 59.286123514175415,\n",
       " 361: 46.44385874271393,\n",
       " 362: 63.4168803691864,\n",
       " 363: 63.607096672058105,\n",
       " 364: 59.66980457305908,\n",
       " 365: 56.321585178375244,\n",
       " 366: 49.936461448669434,\n",
       " 367: 49.95230436325073,\n",
       " 368: 49.95230436325073,\n",
       " 369: 44.930499792099,\n",
       " 370: 51.3884961605072,\n",
       " 371: 56.28567337989807,\n",
       " 372: 54.943132400512695,\n",
       " 373: 55.646997690200806,\n",
       " 374: 59.286123514175415,\n",
       " 375: 46.44385874271393,\n",
       " 376: 63.4168803691864,\n",
       " 377: 63.607096672058105,\n",
       " 378: 59.66980457305908,\n",
       " 379: 56.321585178375244,\n",
       " 380: 49.936461448669434,\n",
       " 381: 49.95230436325073,\n",
       " 382: 49.95230436325073,\n",
       " 383: 44.930499792099,\n",
       " 384: 51.3884961605072,\n",
       " 385: 56.28567337989807,\n",
       " 386: 54.943132400512695,\n",
       " 387: 55.646997690200806,\n",
       " 388: 59.286123514175415,\n",
       " 389: 46.44385874271393,\n",
       " 390: 63.4168803691864,\n",
       " 391: 63.607096672058105,\n",
       " 392: 59.66980457305908,\n",
       " 393: 56.321585178375244,\n",
       " 394: 49.936461448669434,\n",
       " 395: 49.95230436325073,\n",
       " 396: 49.95230436325073,\n",
       " 397: 44.930499792099,\n",
       " 398: 51.3884961605072,\n",
       " 399: 56.28567337989807,\n",
       " 400: 54.943132400512695,\n",
       " 401: 55.646997690200806,\n",
       " 402: 59.286123514175415,\n",
       " 403: 61.14091873168945,\n",
       " 404: 68.46359968185425,\n",
       " 405: 63.64558935165405,\n",
       " 406: 67.03735589981079,\n",
       " 407: 61.37833595275879,\n",
       " 408: 56.49353861808777,\n",
       " 409: 63.64558935165405,\n",
       " 410: 67.03735589981079,\n",
       " 411: 61.37833595275879,\n",
       " 412: 56.49353861808777,\n",
       " 413: 63.64558935165405,\n",
       " 414: 67.03735589981079,\n",
       " 415: 61.37833595275879,\n",
       " 416: 56.49353861808777,\n",
       " 417: 61.14091873168945,\n",
       " 418: 68.46359968185425,\n",
       " 419: 63.64558935165405,\n",
       " 420: 67.03735589981079,\n",
       " 421: 61.37833595275879,\n",
       " 422: 56.49353861808777,\n",
       " 423: 63.64558935165405,\n",
       " 424: 67.03735589981079,\n",
       " 425: 61.37833595275879,\n",
       " 426: 56.49353861808777,\n",
       " 427: 63.64558935165405,\n",
       " 428: 67.03735589981079,\n",
       " 429: 61.37833595275879,\n",
       " 430: 56.49353861808777,\n",
       " 431: 56.353211402893066,\n",
       " 432: 53.87908220291138,\n",
       " 433: 56.43549561500549,\n",
       " 434: 50.7468581199646,\n",
       " 435: 61.00812554359436,\n",
       " 436: 59.65890884399414,\n",
       " 437: 56.353211402893066,\n",
       " 438: 53.87908220291138,\n",
       " 439: 56.43549561500549,\n",
       " 440: 50.7468581199646,\n",
       " 441: 61.00812554359436,\n",
       " 442: 59.65890884399414,\n",
       " 443: 56.353211402893066,\n",
       " 444: 53.87908220291138,\n",
       " 445: 56.43549561500549,\n",
       " 446: 50.7468581199646,\n",
       " 447: 61.00812554359436,\n",
       " 448: 59.65890884399414,\n",
       " 449: 56.353211402893066,\n",
       " 450: 53.87908220291138,\n",
       " 451: 56.43549561500549,\n",
       " 452: 50.7468581199646,\n",
       " 453: 61.00812554359436,\n",
       " 454: 59.65890884399414,\n",
       " 455: 58.87834429740906,\n",
       " 456: 47.62524366378784,\n",
       " 457: 61.99064254760742,\n",
       " 458: 57.601845264434814,\n",
       " 459: 62.72224187850952,\n",
       " 460: 56.12592697143555,\n",
       " 461: 52.42298245429993,\n",
       " 462: 57.601845264434814,\n",
       " 463: 62.72224187850952,\n",
       " 464: 57.601845264434814,\n",
       " 465: 62.72224187850952,\n",
       " 466: 57.601845264434814,\n",
       " 467: 62.72224187850952,\n",
       " 468: 58.87834429740906,\n",
       " 469: 47.62524366378784,\n",
       " 470: 61.99064254760742,\n",
       " 471: 57.601845264434814,\n",
       " 472: 62.72224187850952,\n",
       " 473: 56.12592697143555,\n",
       " 474: 52.42298245429993,\n",
       " 475: 57.601845264434814,\n",
       " 476: 62.72224187850952,\n",
       " 477: 57.601845264434814,\n",
       " 478: 62.72224187850952,\n",
       " 479: 57.601845264434814,\n",
       " 480: 62.72224187850952,\n",
       " 481: 53.58377695083618,\n",
       " 482: 44.495412707328796,\n",
       " 483: 48.90998601913452,\n",
       " 484: 24.968399107456207,\n",
       " 485: 25.058257579803467,\n",
       " 486: 53.58377695083618,\n",
       " 487: 44.495412707328796,\n",
       " 488: 48.90998601913452,\n",
       " 489: 24.968399107456207,\n",
       " 490: 25.058257579803467,\n",
       " 491: 53.58377695083618,\n",
       " 492: 44.495412707328796,\n",
       " 493: 48.90998601913452,\n",
       " 494: 24.968399107456207,\n",
       " 495: 25.058257579803467,\n",
       " 496: 53.58377695083618,\n",
       " 497: 44.495412707328796,\n",
       " 498: 48.90998601913452,\n",
       " 499: 24.968399107456207,\n",
       " 500: 25.058257579803467,\n",
       " 501: 53.58377695083618,\n",
       " 502: 44.495412707328796,\n",
       " 503: 48.90998601913452,\n",
       " 504: 24.968399107456207,\n",
       " 505: 25.058257579803467,\n",
       " 506: 53.58377695083618,\n",
       " 507: 44.495412707328796,\n",
       " 508: 48.90998601913452,\n",
       " 509: 24.968399107456207,\n",
       " 510: 25.058257579803467,\n",
       " 511: 48.13104867935181,\n",
       " 512: 53.9756178855896,\n",
       " 513: 50.820374488830566,\n",
       " 514: 52.897411584854126,\n",
       " 515: 48.13104867935181,\n",
       " 516: 53.9756178855896,\n",
       " 517: 50.820374488830566,\n",
       " 518: 52.897411584854126,\n",
       " 519: 48.13104867935181,\n",
       " 520: 53.9756178855896,\n",
       " 521: 50.820374488830566,\n",
       " 522: 52.897411584854126,\n",
       " 523: 48.13104867935181,\n",
       " 524: 53.9756178855896,\n",
       " 525: 50.820374488830566,\n",
       " 526: 52.897411584854126,\n",
       " 527: 48.13104867935181,\n",
       " 528: 53.9756178855896,\n",
       " 529: 50.820374488830566,\n",
       " 530: 52.897411584854126,\n",
       " 531: 48.13104867935181,\n",
       " 532: 53.9756178855896,\n",
       " 533: 50.820374488830566,\n",
       " 534: 52.897411584854126,\n",
       " 535: 48.13104867935181,\n",
       " 536: 53.9756178855896,\n",
       " 537: 50.820374488830566,\n",
       " 538: 52.897411584854126,\n",
       " 539: 48.13104867935181,\n",
       " 540: 53.9756178855896,\n",
       " 541: 50.820374488830566,\n",
       " 542: 52.897411584854126,\n",
       " 543: 48.13104867935181,\n",
       " 544: 53.9756178855896,\n",
       " 545: 50.820374488830566,\n",
       " 546: 52.897411584854126,\n",
       " 547: 48.13104867935181,\n",
       " 548: 53.9756178855896,\n",
       " 549: 50.820374488830566,\n",
       " 550: 52.897411584854126,\n",
       " 551: 57.42274522781372,\n",
       " 552: 50.3841757774353,\n",
       " 553: 50.93642473220825,\n",
       " 554: 53.59237194061279,\n",
       " 555: 41.33250713348389,\n",
       " 556: 55.007851123809814,\n",
       " 557: 57.42274522781372,\n",
       " 558: 50.3841757774353,\n",
       " 559: 50.93642473220825,\n",
       " 560: 53.59237194061279,\n",
       " 561: 41.33250713348389,\n",
       " 562: 55.007851123809814,\n",
       " 563: 57.42274522781372,\n",
       " 564: 50.3841757774353,\n",
       " 565: 50.93642473220825,\n",
       " 566: 53.59237194061279,\n",
       " 567: 41.33250713348389,\n",
       " 568: 55.007851123809814,\n",
       " 569: 57.42274522781372,\n",
       " 570: 50.3841757774353,\n",
       " 571: 50.93642473220825,\n",
       " 572: 53.59237194061279,\n",
       " 573: 41.33250713348389,\n",
       " 574: 55.007851123809814,\n",
       " 575: 57.42274522781372,\n",
       " 576: 50.3841757774353,\n",
       " 577: 50.93642473220825,\n",
       " 578: 53.59237194061279,\n",
       " 579: 41.33250713348389,\n",
       " 580: 55.007851123809814,\n",
       " 581: 57.42274522781372,\n",
       " 582: 50.3841757774353,\n",
       " 583: 50.93642473220825,\n",
       " 584: 53.59237194061279,\n",
       " 585: 41.33250713348389,\n",
       " 586: 55.007851123809814,\n",
       " 587: 57.42274522781372,\n",
       " 588: 50.3841757774353,\n",
       " 589: 50.93642473220825,\n",
       " 590: 53.59237194061279,\n",
       " 591: 41.33250713348389,\n",
       " 592: 55.007851123809814,\n",
       " 593: 57.42274522781372,\n",
       " 594: 50.3841757774353,\n",
       " 595: 50.93642473220825,\n",
       " 596: 53.59237194061279,\n",
       " 597: 41.33250713348389,\n",
       " 598: 55.007851123809814,\n",
       " 599: 47.631752490997314,\n",
       " 600: 59.31817293167114,\n",
       " 601: 56.04954957962036,\n",
       " 602: 62.16464638710022,\n",
       " 603: 60.92923879623413,\n",
       " 604: 63.22193145751953,\n",
       " 605: 59.65895056724548,\n",
       " 606: 47.631752490997314,\n",
       " 607: 59.31817293167114,\n",
       " 608: 56.04954957962036,\n",
       " 609: 47.631752490997314,\n",
       " 610: 59.31817293167114,\n",
       " 611: 56.04954957962036,\n",
       " 612: 47.631752490997314,\n",
       " 613: 59.31817293167114,\n",
       " 614: 56.04954957962036,\n",
       " 615: 47.631752490997314,\n",
       " 616: 59.31817293167114,\n",
       " 617: 56.04954957962036,\n",
       " 618: 47.631752490997314,\n",
       " 619: 59.31817293167114,\n",
       " 620: 56.04954957962036,\n",
       " 621: 47.631752490997314,\n",
       " 622: 59.31817293167114,\n",
       " 623: 56.04954957962036,\n",
       " 624: 47.631752490997314,\n",
       " 625: 59.31817293167114,\n",
       " 626: 56.04954957962036,\n",
       " 627: 47.631752490997314,\n",
       " 628: 59.31817293167114,\n",
       " 629: 56.04954957962036,\n",
       " 630: 47.631752490997314,\n",
       " 631: 59.31817293167114,\n",
       " 632: 56.04954957962036,\n",
       " 633: 47.631752490997314,\n",
       " 634: 59.31817293167114,\n",
       " 635: 56.04954957962036,\n",
       " 636: 47.631752490997314,\n",
       " 637: 59.31817293167114,\n",
       " 638: 56.04954957962036,\n",
       " 639: 47.631752490997314,\n",
       " 640: 59.31817293167114,\n",
       " 641: 56.04954957962036,\n",
       " 642: 47.631752490997314,\n",
       " 643: 59.31817293167114,\n",
       " 644: 56.04954957962036,\n",
       " 645: 47.631752490997314,\n",
       " 646: 59.31817293167114,\n",
       " 647: 56.04954957962036,\n",
       " 648: 47.631752490997314,\n",
       " 649: 59.31817293167114,\n",
       " 650: 56.04954957962036,\n",
       " 651: 47.631752490997314,\n",
       " 652: 59.31817293167114,\n",
       " 653: 56.04954957962036,\n",
       " 654: 56.54681921005249,\n",
       " 655: 46.75326645374298,\n",
       " 656: 49.971094727516174,\n",
       " 657: 40.24244844913483,\n",
       " 658: 45.23110389709473,\n",
       " 659: 56.54681921005249,\n",
       " 660: 46.75326645374298,\n",
       " 661: 49.971094727516174,\n",
       " 662: 40.24244844913483,\n",
       " 663: 45.23110389709473,\n",
       " 664: 56.54681921005249,\n",
       " 665: 46.75326645374298,\n",
       " 666: 49.971094727516174,\n",
       " 667: 40.24244844913483,\n",
       " 668: 45.23110389709473,\n",
       " 669: 56.54681921005249,\n",
       " 670: 46.75326645374298,\n",
       " 671: 49.971094727516174,\n",
       " 672: 40.24244844913483,\n",
       " 673: 45.23110389709473,\n",
       " 674: 56.54681921005249,\n",
       " 675: 46.75326645374298,\n",
       " 676: 49.971094727516174,\n",
       " 677: 40.24244844913483,\n",
       " 678: 45.23110389709473,\n",
       " 679: 59.36329364776611,\n",
       " 680: 63.267433643341064,\n",
       " 681: 56.116801500320435,\n",
       " 682: 59.36329364776611,\n",
       " 683: 63.267433643341064,\n",
       " 684: 56.116801500320435,\n",
       " 685: 59.36329364776611,\n",
       " 686: 63.267433643341064,\n",
       " 687: 56.116801500320435,\n",
       " 688: 59.36329364776611,\n",
       " 689: 63.267433643341064,\n",
       " 690: 56.116801500320435,\n",
       " 691: 59.36329364776611,\n",
       " 692: 63.267433643341064,\n",
       " 693: 56.116801500320435,\n",
       " 694: 59.36329364776611,\n",
       " 695: 63.267433643341064,\n",
       " 696: 56.116801500320435,\n",
       " 697: 59.36329364776611,\n",
       " 698: 63.267433643341064,\n",
       " 699: 56.116801500320435,\n",
       " 700: 59.36329364776611,\n",
       " 701: 63.267433643341064,\n",
       " 702: 56.116801500320435,\n",
       " 703: 59.36329364776611,\n",
       " 704: 63.267433643341064,\n",
       " 705: 56.116801500320435,\n",
       " 706: 59.36329364776611,\n",
       " 707: 63.267433643341064,\n",
       " 708: 56.116801500320435,\n",
       " 709: 54.93406057357788,\n",
       " 710: 53.687697649002075,\n",
       " 711: 50.52350163459778,\n",
       " 712: 51.487576961517334,\n",
       " 713: 41.07310771942139,\n",
       " 714: 45.283085107803345,\n",
       " 715: 54.39608097076416,\n",
       " 716: 52.87653207778931,\n",
       " 717: 58.938682079315186,\n",
       " 718: 49.806755781173706,\n",
       " 719: 61.599791049957275,\n",
       " 720: 54.93406057357788,\n",
       " 721: 53.687697649002075,\n",
       " 722: 50.52350163459778,\n",
       " 723: 51.487576961517334,\n",
       " 724: 41.07310771942139,\n",
       " 725: 45.283085107803345,\n",
       " 726: 54.39608097076416,\n",
       " 727: 52.87653207778931,\n",
       " 728: 58.938682079315186,\n",
       " 729: 49.806755781173706,\n",
       " 730: 61.599791049957275,\n",
       " 731: 54.93406057357788,\n",
       " 732: 53.687697649002075,\n",
       " 733: 50.52350163459778,\n",
       " 734: 51.487576961517334,\n",
       " 735: 41.07310771942139,\n",
       " 736: 45.283085107803345,\n",
       " 737: 54.39608097076416,\n",
       " 738: 52.87653207778931,\n",
       " 739: 58.938682079315186,\n",
       " 740: 49.806755781173706,\n",
       " 741: 61.599791049957275,\n",
       " 742: 40.75847268104553,\n",
       " 743: 52.582621574401855,\n",
       " 744: 42.7787184715271,\n",
       " 745: 62.49920129776001,\n",
       " 746: 55.12650012969971,\n",
       " 747: 52.62388586997986,\n",
       " 748: 55.50868511199951,\n",
       " 749: 40.75847268104553,\n",
       " 750: 52.582621574401855,\n",
       " 751: 42.7787184715271,\n",
       " 752: 62.49920129776001,\n",
       " 753: 55.12650012969971,\n",
       " 754: 52.62388586997986,\n",
       " 755: 55.50868511199951,\n",
       " 756: 40.75847268104553,\n",
       " 757: 52.582621574401855,\n",
       " 758: 42.7787184715271,\n",
       " 759: 62.49920129776001,\n",
       " 760: 55.12650012969971,\n",
       " 761: 52.62388586997986,\n",
       " 762: 55.50868511199951,\n",
       " 763: 40.75847268104553,\n",
       " 764: 52.582621574401855,\n",
       " 765: 42.7787184715271,\n",
       " 766: 62.49920129776001,\n",
       " 767: 55.12650012969971,\n",
       " 768: 52.62388586997986,\n",
       " 769: 55.50868511199951,\n",
       " 770: 40.75847268104553,\n",
       " 771: 52.582621574401855,\n",
       " 772: 42.7787184715271,\n",
       " 773: 62.49920129776001,\n",
       " 774: 55.12650012969971,\n",
       " 775: 52.62388586997986,\n",
       " 776: 55.50868511199951,\n",
       " 777: 40.75847268104553,\n",
       " 778: 52.582621574401855,\n",
       " 779: 42.7787184715271,\n",
       " 780: 62.49920129776001,\n",
       " 781: 55.12650012969971,\n",
       " 782: 52.62388586997986,\n",
       " 783: 55.50868511199951,\n",
       " 784: 54.09802198410034,\n",
       " 785: 59.218597412109375,\n",
       " 786: 67.095947265625,\n",
       " 787: 48.211681842803955,\n",
       " 788: 50.25906562805176,\n",
       " 789: 54.09802198410034,\n",
       " 790: 59.218597412109375,\n",
       " 791: 67.095947265625,\n",
       " 792: 48.211681842803955,\n",
       " 793: 50.25906562805176,\n",
       " 794: 54.09802198410034,\n",
       " 795: 59.218597412109375,\n",
       " 796: 67.095947265625,\n",
       " 797: 48.211681842803955,\n",
       " 798: 50.25906562805176,\n",
       " 799: 54.09802198410034,\n",
       " 800: 59.218597412109375,\n",
       " 801: 67.095947265625,\n",
       " 802: 48.211681842803955,\n",
       " 803: 50.25906562805176,\n",
       " 804: 54.09802198410034,\n",
       " 805: 59.218597412109375,\n",
       " 806: 67.095947265625,\n",
       " 807: 48.211681842803955,\n",
       " 808: 50.25906562805176,\n",
       " 809: 54.09802198410034,\n",
       " 810: 59.218597412109375,\n",
       " 811: 67.095947265625,\n",
       " 812: 48.211681842803955,\n",
       " 813: 50.25906562805176,\n",
       " 814: 54.09802198410034,\n",
       " 815: 59.218597412109375,\n",
       " 816: 67.095947265625,\n",
       " 817: 48.211681842803955,\n",
       " 818: 50.25906562805176,\n",
       " 819: 54.09802198410034,\n",
       " 820: 59.218597412109375,\n",
       " 821: 67.095947265625,\n",
       " 822: 48.211681842803955,\n",
       " 823: 50.25906562805176,\n",
       " 824: 60.97540855407715,\n",
       " 825: 45.055580139160156,\n",
       " 826: 62.45344281196594,\n",
       " 827: 56.791967153549194,\n",
       " 828: 49.63603615760803,\n",
       " 829: 59.06475782394409,\n",
       " 830: 52.312302589416504,\n",
       " 831: 60.97540855407715,\n",
       " 832: 45.055580139160156,\n",
       " 833: 62.45344281196594,\n",
       " 834: 56.791967153549194,\n",
       " 835: 49.63603615760803,\n",
       " 836: 59.06475782394409,\n",
       " 837: 52.312302589416504,\n",
       " 838: 60.97540855407715,\n",
       " 839: 45.055580139160156,\n",
       " 840: 62.45344281196594,\n",
       " 841: 56.791967153549194,\n",
       " 842: 49.63603615760803,\n",
       " 843: 59.06475782394409,\n",
       " 844: 52.312302589416504,\n",
       " 845: 60.97540855407715,\n",
       " 846: 45.055580139160156,\n",
       " 847: 62.45344281196594,\n",
       " 848: 56.791967153549194,\n",
       " 849: 49.63603615760803,\n",
       " 850: 59.06475782394409,\n",
       " 851: 52.312302589416504,\n",
       " 852: 52.9876708984375,\n",
       " 853: 58.11382532119751,\n",
       " 854: 55.43547868728638,\n",
       " 855: 50.770485401153564,\n",
       " 856: 54.91322875022888,\n",
       " 857: 52.9876708984375,\n",
       " 858: 58.11382532119751,\n",
       " 859: 55.43547868728638,\n",
       " 860: 50.770485401153564,\n",
       " 861: 54.91322875022888,\n",
       " 862: 52.9876708984375,\n",
       " 863: 58.11382532119751,\n",
       " 864: 55.43547868728638,\n",
       " 865: 50.770485401153564,\n",
       " 866: 54.91322875022888,\n",
       " 867: 52.9876708984375,\n",
       " 868: 58.11382532119751,\n",
       " 869: 55.43547868728638,\n",
       " 870: 50.770485401153564,\n",
       " 871: 54.91322875022888,\n",
       " 872: 52.9876708984375,\n",
       " 873: 58.11382532119751,\n",
       " 874: 55.43547868728638,\n",
       " 875: 50.770485401153564,\n",
       " 876: 54.91322875022888,\n",
       " 877: 52.9876708984375,\n",
       " 878: 58.11382532119751,\n",
       " 879: 55.43547868728638,\n",
       " 880: 50.770485401153564,\n",
       " 881: 54.91322875022888,\n",
       " 882: 52.9876708984375,\n",
       " 883: 58.11382532119751,\n",
       " 884: 55.43547868728638,\n",
       " 885: 50.770485401153564,\n",
       " 886: 54.91322875022888,\n",
       " 887: 52.9876708984375,\n",
       " 888: 58.11382532119751,\n",
       " 889: 55.43547868728638,\n",
       " 890: 50.770485401153564,\n",
       " 891: 54.91322875022888}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_2={}\n",
    "for i in range(data_size):\n",
    "    result=0\n",
    "    result=matcher(fetched_job,data['cleaned_resume'][i])\n",
    "    result_dict_2[i]=result\n",
    "\n",
    "result_dict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "sorted_dict_results_2 = dict(sorted(result_dict_2.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "top_5_items_2 = dict(list(sorted_dict_results_2.items())[:5])\n",
    "\n",
    "print(type(top_5_items_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResumeID</th>\n",
       "      <th>Matching Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>404</td>\n",
       "      <td>68.463600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>418</td>\n",
       "      <td>68.463600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>786</td>\n",
       "      <td>67.095947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>791</td>\n",
       "      <td>67.095947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>796</td>\n",
       "      <td>67.095947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ResumeID  Matching Percentage\n",
       "0       404            68.463600\n",
       "1       418            68.463600\n",
       "2       786            67.095947\n",
       "3       791            67.095947\n",
       "4       796            67.095947"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_2=pd.DataFrame(top_5_items_2.items(), columns=['ResumeID', 'Matching Percentage'])\n",
    "result_df_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Sklearn's cosine similarity takes about 5.7 seconds per resume to screen, took a total of 48 mins to screen 891 resumes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Mover's  with word2vec model to calculate percentage similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note: This function calculated WMD without tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk import download\n",
    "# import gensim\n",
    "# from gensim.models import Word2Vec\n",
    "# from numba import jit\n",
    "# download('stopwords')  # Download stopwords list.\n",
    "# # @jit#(target=\"cuda\")\n",
    "# def matcher_2(job_desc, res_text):\n",
    "#     # Remove stopwords.\n",
    "#     stop_words = stopwords.words('english')\n",
    "#     job_desc = [w for w in job_desc if w not in stop_words]\n",
    "#     res_text = [w for w in res_text if w not in stop_words]\n",
    "#     model = gensim.models.KeyedVectors.load_word2vec_format('C:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\ResumeRanker_Shared\\Implementation\\GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "#     model.init_sims(replace=True)  # Normalizes the vectors in the word2vec class.\n",
    "#     distance = model.wmdistance(job_desc, res_text)\n",
    "#     return distance  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matcher_2(fetched_job,fetched_data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_dict_3={}\n",
    "# for i in range(data_size):\n",
    "#     result=0\n",
    "#     result=matcher_2(fetched_job,data['cleaned_resume'][i])\n",
    "#     result_dict_3[i]=result\n",
    "\n",
    "# result_dict_3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WMD takes about 90 seconds to screen 1 resume"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sentence transformer(BERT) for encoding and calculating matching percentage using Scipy Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.30981123447418"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "text=[fetched_job,fetched_data[5]]\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "# sen = job_desc+fetched_data[5]\n",
    "sen_embeddings = model.encode(text)\n",
    "(sen_embeddings).shape\n",
    "(distance.cosine(sen_embeddings[0],sen_embeddings[1]))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def matcher_4(job_desc,resume_text):\n",
    "        text=[job_desc,resume_text]\n",
    "        model = SentenceTransformer('all-mpnet-base-v2')\n",
    "        # sen = job_desc+fetched_data[5]\n",
    "        sen_embeddings = model.encode(text)\n",
    "        # (sen_embeddings).shape\n",
    "        return(distance.cosine(sen_embeddings[0],sen_embeddings[1]))*100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(data_size):\n\u001b[0;32m      3\u001b[0m     result\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m     result\u001b[39m=\u001b[39mmatcher_4(fetched_job,data[\u001b[39m'\u001b[39;49m\u001b[39mcleaned_resume\u001b[39;49m\u001b[39m'\u001b[39;49m][i])\n\u001b[0;32m      5\u001b[0m     result_dict_4[i]\u001b[39m=\u001b[39mresult\n\u001b[0;32m      7\u001b[0m result_dict_4\n",
      "Cell \u001b[1;32mIn[33], line 7\u001b[0m, in \u001b[0;36mmatcher_4\u001b[1;34m(job_desc, resume_text)\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[39m=\u001b[39m SentenceTransformer(\u001b[39m'\u001b[39m\u001b[39mall-mpnet-base-v2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# sen = job_desc+fetched_data[5]\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m sen_embeddings \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mencode(text)\n\u001b[0;32m      8\u001b[0m \u001b[39m# (sen_embeddings).shape\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m(distance\u001b[39m.\u001b[39mcosine(sen_embeddings[\u001b[39m0\u001b[39m],sen_embeddings[\u001b[39m1\u001b[39m]))\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[0;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[0;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrans_features, return_dict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[0;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:550\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    549\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids\u001b[39m=\u001b[39minput_ids, position_ids\u001b[39m=\u001b[39mposition_ids, inputs_embeds\u001b[39m=\u001b[39minputs_embeds)\n\u001b[1;32m--> 550\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    551\u001b[0m     embedding_output,\n\u001b[0;32m    552\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    553\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    554\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    555\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    556\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    557\u001b[0m )\n\u001b[0;32m    558\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    559\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:339\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    337\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[1;32m--> 339\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    340\u001b[0m     hidden_states,\n\u001b[0;32m    341\u001b[0m     attention_mask,\n\u001b[0;32m    342\u001b[0m     head_mask[i],\n\u001b[0;32m    343\u001b[0m     position_bias,\n\u001b[0;32m    344\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[0;32m    345\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    346\u001b[0m )\n\u001b[0;32m    347\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    349\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:298\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    290\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    291\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    297\u001b[0m ):\n\u001b[1;32m--> 298\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    299\u001b[0m         hidden_states,\n\u001b[0;32m    300\u001b[0m         attention_mask,\n\u001b[0;32m    301\u001b[0m         head_mask,\n\u001b[0;32m    302\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[0;32m    303\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    304\u001b[0m     )\n\u001b[0;32m    305\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    306\u001b[0m     outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:239\u001b[0m, in \u001b[0;36mMPNetAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    231\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    232\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    238\u001b[0m ):\n\u001b[1;32m--> 239\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[0;32m    240\u001b[0m         hidden_states,\n\u001b[0;32m    241\u001b[0m         attention_mask,\n\u001b[0;32m    242\u001b[0m         head_mask,\n\u001b[0;32m    243\u001b[0m         position_bias,\n\u001b[0;32m    244\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    245\u001b[0m     )\n\u001b[0;32m    246\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(self_outputs[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m hidden_states)\n\u001b[0;32m    247\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:186\u001b[0m, in \u001b[0;36mMPNetSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m     attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m+\u001b[39m attention_mask\n\u001b[0;32m    185\u001b[0m \u001b[39m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m attention_probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49msoftmax(attention_scores, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    188\u001b[0m attention_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_probs)\n\u001b[0;32m    190\u001b[0m \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\torch\\nn\\functional.py:1843\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1842\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1843\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[0;32m   1844\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1845\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result_dict_4={}\n",
    "for i in range(data_size):\n",
    "    result=0\n",
    "    result=matcher_4(fetched_job,data['cleaned_resume'][i])\n",
    "    result_dict_4[i]=result\n",
    "\n",
    "result_dict_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "sorted_dict_results_4 = dict(sorted(result_dict_4.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "top_5_items_4 = dict(list(sorted_dict_results_4.items())[:5])\n",
    "\n",
    "print(type(top_5_items_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResumeID</th>\n",
       "      <th>Matching Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>266</td>\n",
       "      <td>90.90351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272</td>\n",
       "      <td>90.90351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>278</td>\n",
       "      <td>90.90351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>90.90351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>290</td>\n",
       "      <td>90.90351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ResumeID  Matching Percentage\n",
       "0       266             90.90351\n",
       "1       272             90.90351\n",
       "2       278             90.90351\n",
       "3       284             90.90351\n",
       "4       290             90.90351"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_4=pd.DataFrame(top_5_items_4.items(), columns=['ResumeID', 'Matching Percentage'])\n",
    "result_df_4\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy cosine similarity along with Bert transformer shows a very high matching percentage but takes overall 48 mins to screen 891 resumes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sentence transformer(BERT{all-MiniLM-L6-v2}) for encoding and calculating matching percentage using Sklearn Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matcher_5(job_desc,resume_text):\n",
    "        text=[job_desc,resume_text]\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        # sen = job_desc+fetched_data[5]\n",
    "        sen_embeddings = model.encode(text)\n",
    "        # (sen_embeddings).shape\n",
    "        return(cosine_similarity([sen_embeddings[0],sen_embeddings[1]])[0][1])*100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.332659006118774"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=[fetched_job,fetched_data[5]]\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# sen = job_desc+fetched_data[5]\n",
    "sen_embeddings = model.encode(text)\n",
    "(sen_embeddings).shape\n",
    "(cosine_similarity([sen_embeddings[0],sen_embeddings[1]])[0][1])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 40.07311463356018,\n",
       " 1: 32.90212154388428,\n",
       " 2: 40.32559394836426,\n",
       " 3: 39.92169201374054,\n",
       " 4: 48.866093158721924,\n",
       " 5: 45.89669704437256,\n",
       " 6: 41.048941016197205,\n",
       " 7: 38.672298192977905,\n",
       " 8: 38.76413106918335,\n",
       " 9: 40.71744084358215,\n",
       " 10: 40.07311463356018,\n",
       " 11: 32.90212154388428,\n",
       " 12: 40.32559394836426,\n",
       " 13: 39.92169201374054,\n",
       " 14: 48.866093158721924,\n",
       " 15: 45.89669704437256,\n",
       " 16: 41.048941016197205,\n",
       " 17: 38.672298192977905,\n",
       " 18: 38.76413106918335,\n",
       " 19: 40.71744084358215,\n",
       " 20: 40.07311463356018,\n",
       " 21: 32.90212154388428,\n",
       " 22: 40.32559394836426,\n",
       " 23: 39.92169201374054,\n",
       " 24: 48.866093158721924,\n",
       " 25: 45.89669704437256,\n",
       " 26: 41.048941016197205,\n",
       " 27: 38.672298192977905,\n",
       " 28: 38.76413106918335,\n",
       " 29: 40.71744084358215,\n",
       " 30: 40.07311463356018,\n",
       " 31: 32.90212154388428,\n",
       " 32: 40.32559394836426,\n",
       " 33: 39.92169201374054,\n",
       " 34: 48.866093158721924,\n",
       " 35: 45.89669704437256,\n",
       " 36: 41.048941016197205,\n",
       " 37: 38.672298192977905,\n",
       " 38: 38.76413106918335,\n",
       " 39: 40.71744084358215,\n",
       " 40: 48.94891381263733,\n",
       " 41: 31.170955300331116,\n",
       " 42: 33.77979397773743,\n",
       " 43: 35.94610393047333,\n",
       " 44: 35.94610393047333,\n",
       " 45: 36.58369779586792,\n",
       " 46: 37.35981583595276,\n",
       " 47: 49.641984701156616,\n",
       " 48: 24.551290273666382,\n",
       " 49: 47.75729179382324,\n",
       " 50: 56.417882442474365,\n",
       " 51: 48.94891381263733,\n",
       " 52: 31.170955300331116,\n",
       " 53: 33.77979397773743,\n",
       " 54: 35.94610393047333,\n",
       " 55: 35.94610393047333,\n",
       " 56: 36.58369779586792,\n",
       " 57: 37.35981583595276,\n",
       " 58: 49.641984701156616,\n",
       " 59: 24.551290273666382,\n",
       " 60: 47.75729179382324,\n",
       " 61: 56.417882442474365,\n",
       " 62: 48.94891381263733,\n",
       " 63: 31.170955300331116,\n",
       " 64: 33.77979397773743,\n",
       " 65: 35.94610393047333,\n",
       " 66: 35.94610393047333,\n",
       " 67: 36.58369779586792,\n",
       " 68: 37.35981583595276,\n",
       " 69: 49.641984701156616,\n",
       " 70: 24.551290273666382,\n",
       " 71: 47.75729179382324,\n",
       " 72: 56.417882442474365,\n",
       " 73: 48.94891381263733,\n",
       " 74: 31.170955300331116,\n",
       " 75: 33.77979397773743,\n",
       " 76: 35.94610393047333,\n",
       " 77: 35.94610393047333,\n",
       " 78: 36.58369779586792,\n",
       " 79: 37.35981583595276,\n",
       " 80: 49.641984701156616,\n",
       " 81: 24.551290273666382,\n",
       " 82: 47.75729179382324,\n",
       " 83: 56.417882442474365,\n",
       " 84: 33.95147919654846,\n",
       " 85: 36.649444699287415,\n",
       " 86: 39.96313214302063,\n",
       " 87: 44.220125675201416,\n",
       " 88: 35.17277240753174,\n",
       " 89: 40.24357199668884,\n",
       " 90: 44.812557101249695,\n",
       " 91: 28.358185291290283,\n",
       " 92: 34.21493172645569,\n",
       " 93: 38.96835148334503,\n",
       " 94: 33.95147919654846,\n",
       " 95: 36.649444699287415,\n",
       " 96: 39.96313214302063,\n",
       " 97: 44.220125675201416,\n",
       " 98: 35.17277240753174,\n",
       " 99: 40.24357199668884,\n",
       " 100: 44.812557101249695,\n",
       " 101: 28.358185291290283,\n",
       " 102: 34.21493172645569,\n",
       " 103: 38.96835148334503,\n",
       " 104: 34.01094079017639,\n",
       " 105: 43.34137439727783,\n",
       " 106: 32.38303065299988,\n",
       " 107: 28.5957932472229,\n",
       " 108: 17.74456650018692,\n",
       " 109: 36.061397194862366,\n",
       " 110: 34.01094079017639,\n",
       " 111: 43.34137439727783,\n",
       " 112: 32.38303065299988,\n",
       " 113: 28.5957932472229,\n",
       " 114: 17.74456650018692,\n",
       " 115: 36.061397194862366,\n",
       " 116: 34.01094079017639,\n",
       " 117: 43.34137439727783,\n",
       " 118: 32.38303065299988,\n",
       " 119: 28.5957932472229,\n",
       " 120: 17.74456650018692,\n",
       " 121: 36.061397194862366,\n",
       " 122: 34.01094079017639,\n",
       " 123: 43.34137439727783,\n",
       " 124: 32.38303065299988,\n",
       " 125: 28.5957932472229,\n",
       " 126: 17.74456650018692,\n",
       " 127: 36.061397194862366,\n",
       " 128: 34.01094079017639,\n",
       " 129: 43.34137439727783,\n",
       " 130: 32.38303065299988,\n",
       " 131: 28.5957932472229,\n",
       " 132: 17.74456650018692,\n",
       " 133: 36.061397194862366,\n",
       " 134: 34.01094079017639,\n",
       " 135: 43.34137439727783,\n",
       " 136: 32.38303065299988,\n",
       " 137: 28.5957932472229,\n",
       " 138: 17.74456650018692,\n",
       " 139: 36.061397194862366,\n",
       " 140: 38.273024559020996,\n",
       " 141: 35.49858331680298,\n",
       " 142: 38.273024559020996,\n",
       " 143: 47.41508364677429,\n",
       " 144: 47.25220799446106,\n",
       " 145: 38.273024559020996,\n",
       " 146: 35.49858331680298,\n",
       " 147: 38.273024559020996,\n",
       " 148: 47.41508364677429,\n",
       " 149: 47.25220799446106,\n",
       " 150: 38.273024559020996,\n",
       " 151: 35.49858331680298,\n",
       " 152: 38.273024559020996,\n",
       " 153: 47.41508364677429,\n",
       " 154: 47.25220799446106,\n",
       " 155: 38.273024559020996,\n",
       " 156: 35.49858331680298,\n",
       " 157: 38.273024559020996,\n",
       " 158: 47.41508364677429,\n",
       " 159: 47.25220799446106,\n",
       " 160: 38.273024559020996,\n",
       " 161: 35.49858331680298,\n",
       " 162: 38.273024559020996,\n",
       " 163: 47.41508364677429,\n",
       " 164: 47.25220799446106,\n",
       " 165: 38.273024559020996,\n",
       " 166: 35.49858331680298,\n",
       " 167: 38.273024559020996,\n",
       " 168: 47.41508364677429,\n",
       " 169: 47.25220799446106,\n",
       " 170: 38.273024559020996,\n",
       " 171: 35.49858331680298,\n",
       " 172: 38.273024559020996,\n",
       " 173: 47.41508364677429,\n",
       " 174: 47.25220799446106,\n",
       " 175: 38.273024559020996,\n",
       " 176: 35.49858331680298,\n",
       " 177: 38.273024559020996,\n",
       " 178: 47.41508364677429,\n",
       " 179: 47.25220799446106,\n",
       " 180: 38.273024559020996,\n",
       " 181: 35.49858331680298,\n",
       " 182: 38.273024559020996,\n",
       " 183: 47.41508364677429,\n",
       " 184: 47.25220799446106,\n",
       " 185: 32.915207743644714,\n",
       " 186: 34.67630743980408,\n",
       " 187: 31.829017400741577,\n",
       " 188: 26.055750250816345,\n",
       " 189: 30.06996512413025,\n",
       " 190: 32.915207743644714,\n",
       " 191: 34.67630743980408,\n",
       " 192: 31.829017400741577,\n",
       " 193: 26.055750250816345,\n",
       " 194: 30.06996512413025,\n",
       " 195: 32.915207743644714,\n",
       " 196: 34.67630743980408,\n",
       " 197: 31.829017400741577,\n",
       " 198: 26.055750250816345,\n",
       " 199: 30.06996512413025,\n",
       " 200: 32.915207743644714,\n",
       " 201: 34.67630743980408,\n",
       " 202: 31.829017400741577,\n",
       " 203: 26.055750250816345,\n",
       " 204: 30.06996512413025,\n",
       " 205: 32.915207743644714,\n",
       " 206: 34.67630743980408,\n",
       " 207: 31.829017400741577,\n",
       " 208: 26.055750250816345,\n",
       " 209: 30.06996512413025,\n",
       " 210: 32.915207743644714,\n",
       " 211: 34.67630743980408,\n",
       " 212: 31.829017400741577,\n",
       " 213: 26.055750250816345,\n",
       " 214: 30.06996512413025,\n",
       " 215: 32.915207743644714,\n",
       " 216: 34.67630743980408,\n",
       " 217: 31.829017400741577,\n",
       " 218: 26.055750250816345,\n",
       " 219: 30.06996512413025,\n",
       " 220: 32.915207743644714,\n",
       " 221: 34.67630743980408,\n",
       " 222: 31.829017400741577,\n",
       " 223: 26.055750250816345,\n",
       " 224: 30.06996512413025,\n",
       " 225: 36.099958419799805,\n",
       " 226: 36.664408445358276,\n",
       " 227: 29.731938242912292,\n",
       " 228: 30.500483512878418,\n",
       " 229: 36.80936098098755,\n",
       " 230: 36.099958419799805,\n",
       " 231: 36.664408445358276,\n",
       " 232: 29.731938242912292,\n",
       " 233: 30.500483512878418,\n",
       " 234: 36.80936098098755,\n",
       " 235: 36.099958419799805,\n",
       " 236: 36.664408445358276,\n",
       " 237: 29.731938242912292,\n",
       " 238: 30.500483512878418,\n",
       " 239: 36.80936098098755,\n",
       " 240: 36.099958419799805,\n",
       " 241: 36.664408445358276,\n",
       " 242: 29.731938242912292,\n",
       " 243: 30.500483512878418,\n",
       " 244: 36.80936098098755,\n",
       " 245: 36.099958419799805,\n",
       " 246: 36.664408445358276,\n",
       " 247: 29.731938242912292,\n",
       " 248: 30.500483512878418,\n",
       " 249: 36.80936098098755,\n",
       " 250: 36.099958419799805,\n",
       " 251: 36.664408445358276,\n",
       " 252: 29.731938242912292,\n",
       " 253: 30.500483512878418,\n",
       " 254: 36.80936098098755,\n",
       " 255: 36.099958419799805,\n",
       " 256: 36.664408445358276,\n",
       " 257: 29.731938242912292,\n",
       " 258: 30.500483512878418,\n",
       " 259: 36.80936098098755,\n",
       " 260: 36.099958419799805,\n",
       " 261: 36.664408445358276,\n",
       " 262: 29.731938242912292,\n",
       " 263: 30.500483512878418,\n",
       " 264: 36.80936098098755,\n",
       " 265: 30.572137236595154,\n",
       " 266: 12.32793852686882,\n",
       " 267: 14.416664838790894,\n",
       " 268: 18.541978299617767,\n",
       " 269: 25.552934408187866,\n",
       " 270: 12.224884331226349,\n",
       " 271: 30.572137236595154,\n",
       " 272: 12.32793852686882,\n",
       " 273: 14.416664838790894,\n",
       " 274: 18.541978299617767,\n",
       " 275: 25.552934408187866,\n",
       " 276: 12.224884331226349,\n",
       " 277: 30.572137236595154,\n",
       " 278: 12.32793852686882,\n",
       " 279: 14.416664838790894,\n",
       " 280: 18.541978299617767,\n",
       " 281: 25.552934408187866,\n",
       " 282: 12.224884331226349,\n",
       " 283: 30.572137236595154,\n",
       " 284: 12.32793852686882,\n",
       " 285: 14.416664838790894,\n",
       " 286: 18.541978299617767,\n",
       " 287: 25.552934408187866,\n",
       " 288: 12.224884331226349,\n",
       " 289: 30.572137236595154,\n",
       " 290: 12.32793852686882,\n",
       " 291: 14.416664838790894,\n",
       " 292: 18.541978299617767,\n",
       " 293: 25.552934408187866,\n",
       " 294: 12.224884331226349,\n",
       " 295: 25.940951704978943,\n",
       " 296: 39.559340476989746,\n",
       " 297: 27.333730459213257,\n",
       " 298: 30.334562063217163,\n",
       " 299: 39.24682438373566,\n",
       " 300: 48.00972938537598,\n",
       " 301: 25.940951704978943,\n",
       " 302: 39.559340476989746,\n",
       " 303: 27.333730459213257,\n",
       " 304: 30.334562063217163,\n",
       " 305: 39.24682438373566,\n",
       " 306: 48.00972938537598,\n",
       " 307: 25.940951704978943,\n",
       " 308: 39.559340476989746,\n",
       " 309: 27.333730459213257,\n",
       " 310: 30.334562063217163,\n",
       " 311: 39.24682438373566,\n",
       " 312: 48.00972938537598,\n",
       " 313: 25.940951704978943,\n",
       " 314: 39.559340476989746,\n",
       " 315: 27.333730459213257,\n",
       " 316: 30.334562063217163,\n",
       " 317: 39.24682438373566,\n",
       " 318: 48.00972938537598,\n",
       " 319: 38.18403780460358,\n",
       " 320: 39.53738808631897,\n",
       " 321: 47.345009446144104,\n",
       " 322: 41.97717308998108,\n",
       " 323: 36.05200946331024,\n",
       " 324: 42.969417572021484,\n",
       " 325: 33.761584758758545,\n",
       " 326: 33.761584758758545,\n",
       " 327: 38.97462785243988,\n",
       " 328: 38.38420510292053,\n",
       " 329: 37.41750121116638,\n",
       " 330: 39.15776610374451,\n",
       " 331: 44.01660859584808,\n",
       " 332: 46.272772550582886,\n",
       " 333: 38.18403780460358,\n",
       " 334: 39.53738808631897,\n",
       " 335: 47.345009446144104,\n",
       " 336: 41.97717308998108,\n",
       " 337: 36.05200946331024,\n",
       " 338: 42.969417572021484,\n",
       " 339: 33.761584758758545,\n",
       " 340: 33.761584758758545,\n",
       " 341: 38.97462785243988,\n",
       " 342: 38.38420510292053,\n",
       " 343: 37.41750121116638,\n",
       " 344: 39.15776610374451,\n",
       " 345: 44.01660859584808,\n",
       " 346: 46.272772550582886,\n",
       " 347: 38.18403780460358,\n",
       " 348: 39.53738808631897,\n",
       " 349: 47.345009446144104,\n",
       " 350: 41.97717308998108,\n",
       " 351: 36.05200946331024,\n",
       " 352: 42.969417572021484,\n",
       " 353: 33.761584758758545,\n",
       " 354: 33.761584758758545,\n",
       " 355: 38.97462785243988,\n",
       " 356: 38.38420510292053,\n",
       " 357: 37.41750121116638,\n",
       " 358: 39.15776610374451,\n",
       " 359: 44.01660859584808,\n",
       " 360: 46.272772550582886,\n",
       " 361: 38.18403780460358,\n",
       " 362: 39.53738808631897,\n",
       " 363: 47.345009446144104,\n",
       " 364: 41.97717308998108,\n",
       " 365: 36.05200946331024,\n",
       " 366: 42.969417572021484,\n",
       " 367: 33.761584758758545,\n",
       " 368: 33.761584758758545,\n",
       " 369: 38.97462785243988,\n",
       " 370: 38.38420510292053,\n",
       " 371: 37.41750121116638,\n",
       " 372: 39.15776610374451,\n",
       " 373: 44.01660859584808,\n",
       " 374: 46.272772550582886,\n",
       " 375: 38.18403780460358,\n",
       " 376: 39.53738808631897,\n",
       " 377: 47.345009446144104,\n",
       " 378: 41.97717308998108,\n",
       " 379: 36.05200946331024,\n",
       " 380: 42.969417572021484,\n",
       " 381: 33.761584758758545,\n",
       " 382: 33.761584758758545,\n",
       " 383: 38.97462785243988,\n",
       " 384: 38.38420510292053,\n",
       " 385: 37.41750121116638,\n",
       " 386: 39.15776610374451,\n",
       " 387: 44.01660859584808,\n",
       " 388: 46.272772550582886,\n",
       " 389: 38.18403780460358,\n",
       " 390: 39.53738808631897,\n",
       " 391: 47.345009446144104,\n",
       " 392: 41.97717308998108,\n",
       " 393: 36.05200946331024,\n",
       " 394: 42.969417572021484,\n",
       " 395: 33.761584758758545,\n",
       " 396: 33.761584758758545,\n",
       " 397: 38.97462785243988,\n",
       " 398: 38.38420510292053,\n",
       " 399: 37.41750121116638,\n",
       " 400: 39.15776610374451,\n",
       " 401: 44.01660859584808,\n",
       " 402: 46.272772550582886,\n",
       " 403: 38.73107433319092,\n",
       " 404: 43.274566531181335,\n",
       " 405: 46.676936745643616,\n",
       " 406: 42.28909909725189,\n",
       " 407: 45.075589418411255,\n",
       " 408: 36.37459874153137,\n",
       " 409: 46.676936745643616,\n",
       " 410: 42.28909909725189,\n",
       " 411: 45.075589418411255,\n",
       " 412: 36.37459874153137,\n",
       " 413: 46.676936745643616,\n",
       " 414: 42.28909909725189,\n",
       " 415: 45.075589418411255,\n",
       " 416: 36.37459874153137,\n",
       " 417: 38.73107433319092,\n",
       " 418: 43.274566531181335,\n",
       " 419: 46.676936745643616,\n",
       " 420: 42.28909909725189,\n",
       " 421: 45.075589418411255,\n",
       " 422: 36.37459874153137,\n",
       " 423: 46.676936745643616,\n",
       " 424: 42.28909909725189,\n",
       " 425: 45.075589418411255,\n",
       " 426: 36.37459874153137,\n",
       " 427: 46.676936745643616,\n",
       " 428: 42.28909909725189,\n",
       " 429: 45.075589418411255,\n",
       " 430: 36.37459874153137,\n",
       " 431: 40.16313850879669,\n",
       " 432: 36.9376003742218,\n",
       " 433: 31.311732530593872,\n",
       " 434: 44.98424530029297,\n",
       " 435: 59.36129689216614,\n",
       " 436: 43.694883584976196,\n",
       " 437: 40.16313850879669,\n",
       " 438: 36.9376003742218,\n",
       " 439: 31.311732530593872,\n",
       " 440: 44.98424530029297,\n",
       " 441: 59.36129689216614,\n",
       " 442: 43.694883584976196,\n",
       " 443: 40.16313850879669,\n",
       " 444: 36.9376003742218,\n",
       " 445: 31.311732530593872,\n",
       " 446: 44.98424530029297,\n",
       " 447: 59.36129689216614,\n",
       " 448: 43.694883584976196,\n",
       " 449: 40.16313850879669,\n",
       " 450: 36.9376003742218,\n",
       " 451: 31.311732530593872,\n",
       " 452: 44.98424530029297,\n",
       " 453: 59.36129689216614,\n",
       " 454: 43.694883584976196,\n",
       " 455: 33.515435457229614,\n",
       " 456: 29.047903418540955,\n",
       " 457: 38.107699155807495,\n",
       " 458: 40.34246802330017,\n",
       " 459: 44.38070356845856,\n",
       " 460: 32.705098390579224,\n",
       " 461: 40.09132981300354,\n",
       " 462: 40.34246802330017,\n",
       " 463: 44.38070356845856,\n",
       " 464: 40.34246802330017,\n",
       " 465: 44.38070356845856,\n",
       " 466: 40.34246802330017,\n",
       " 467: 44.38070356845856,\n",
       " 468: 33.515435457229614,\n",
       " 469: 29.047903418540955,\n",
       " 470: 38.107699155807495,\n",
       " 471: 40.34246802330017,\n",
       " 472: 44.38070356845856,\n",
       " 473: 32.705098390579224,\n",
       " 474: 40.09132981300354,\n",
       " 475: 40.34246802330017,\n",
       " 476: 44.38070356845856,\n",
       " 477: 40.34246802330017,\n",
       " 478: 44.38070356845856,\n",
       " 479: 40.34246802330017,\n",
       " 480: 44.38070356845856,\n",
       " 481: 36.49608790874481,\n",
       " 482: 40.532708168029785,\n",
       " 483: 28.552886843681335,\n",
       " 484: 32.582712173461914,\n",
       " 485: 19.13684606552124,\n",
       " 486: 36.49608790874481,\n",
       " 487: 40.532708168029785,\n",
       " 488: 28.552886843681335,\n",
       " 489: 32.582712173461914,\n",
       " 490: 19.13684606552124,\n",
       " 491: 36.49608790874481,\n",
       " 492: 40.532708168029785,\n",
       " 493: 28.552886843681335,\n",
       " 494: 32.582712173461914,\n",
       " 495: 19.13684606552124,\n",
       " 496: 36.49608790874481,\n",
       " 497: 40.532708168029785,\n",
       " 498: 28.552886843681335,\n",
       " 499: 32.582712173461914,\n",
       " 500: 19.13684606552124,\n",
       " 501: 36.49608790874481,\n",
       " 502: 40.532708168029785,\n",
       " 503: 28.552886843681335,\n",
       " 504: 32.582712173461914,\n",
       " 505: 19.13684606552124,\n",
       " 506: 36.49608790874481,\n",
       " 507: 40.532708168029785,\n",
       " 508: 28.552886843681335,\n",
       " 509: 32.582712173461914,\n",
       " 510: 19.13684606552124,\n",
       " 511: 29.85616624355316,\n",
       " 512: 35.05493104457855,\n",
       " 513: 31.202715635299683,\n",
       " 514: 27.918249368667603,\n",
       " 515: 29.85616624355316,\n",
       " 516: 35.05493104457855,\n",
       " 517: 31.202715635299683,\n",
       " 518: 27.918249368667603,\n",
       " 519: 29.85616624355316,\n",
       " 520: 35.05493104457855,\n",
       " 521: 31.202715635299683,\n",
       " 522: 27.918249368667603,\n",
       " 523: 29.85616624355316,\n",
       " 524: 35.05493104457855,\n",
       " 525: 31.202715635299683,\n",
       " 526: 27.918249368667603,\n",
       " 527: 29.85616624355316,\n",
       " 528: 35.05493104457855,\n",
       " 529: 31.202715635299683,\n",
       " 530: 27.918249368667603,\n",
       " 531: 29.85616624355316,\n",
       " 532: 35.05493104457855,\n",
       " 533: 31.202715635299683,\n",
       " 534: 27.918249368667603,\n",
       " 535: 29.85616624355316,\n",
       " 536: 35.05493104457855,\n",
       " 537: 31.202715635299683,\n",
       " 538: 27.918249368667603,\n",
       " 539: 29.85616624355316,\n",
       " 540: 35.05493104457855,\n",
       " 541: 31.202715635299683,\n",
       " 542: 27.918249368667603,\n",
       " 543: 29.85616624355316,\n",
       " 544: 35.05493104457855,\n",
       " 545: 31.202715635299683,\n",
       " 546: 27.918249368667603,\n",
       " 547: 29.85616624355316,\n",
       " 548: 35.05493104457855,\n",
       " 549: 31.202715635299683,\n",
       " 550: 27.918249368667603,\n",
       " 551: 42.439329624176025,\n",
       " 552: 52.57691740989685,\n",
       " 553: 40.91246724128723,\n",
       " 554: 43.972593545913696,\n",
       " 555: 29.92662489414215,\n",
       " 556: 51.92009210586548,\n",
       " 557: 42.439329624176025,\n",
       " 558: 52.57691740989685,\n",
       " 559: 40.91246724128723,\n",
       " 560: 43.972593545913696,\n",
       " 561: 29.92662489414215,\n",
       " 562: 51.92009210586548,\n",
       " 563: 42.439329624176025,\n",
       " 564: 52.57691740989685,\n",
       " 565: 40.91246724128723,\n",
       " 566: 43.972593545913696,\n",
       " 567: 29.92662489414215,\n",
       " 568: 51.92009210586548,\n",
       " 569: 42.439329624176025,\n",
       " 570: 52.57691740989685,\n",
       " 571: 40.91246724128723,\n",
       " 572: 43.972593545913696,\n",
       " 573: 29.92662489414215,\n",
       " 574: 51.92009210586548,\n",
       " 575: 42.439329624176025,\n",
       " 576: 52.57691740989685,\n",
       " 577: 40.91246724128723,\n",
       " 578: 43.972593545913696,\n",
       " 579: 29.92662489414215,\n",
       " 580: 51.92009210586548,\n",
       " 581: 42.439329624176025,\n",
       " 582: 52.57691740989685,\n",
       " 583: 40.91246724128723,\n",
       " 584: 43.972593545913696,\n",
       " 585: 29.92662489414215,\n",
       " 586: 51.92009210586548,\n",
       " 587: 42.439329624176025,\n",
       " 588: 52.57691740989685,\n",
       " 589: 40.91246724128723,\n",
       " 590: 43.972593545913696,\n",
       " 591: 29.92662489414215,\n",
       " 592: 51.92009210586548,\n",
       " 593: 42.439329624176025,\n",
       " 594: 52.57691740989685,\n",
       " 595: 40.91246724128723,\n",
       " 596: 43.972593545913696,\n",
       " 597: 29.92662489414215,\n",
       " 598: 51.92009210586548,\n",
       " 599: 36.91572546958923,\n",
       " 600: 49.338871240615845,\n",
       " 601: 33.70429873466492,\n",
       " 602: 40.117138624191284,\n",
       " 603: 42.344874143600464,\n",
       " 604: 40.99704325199127,\n",
       " 605: 36.02084517478943,\n",
       " 606: 36.91572546958923,\n",
       " 607: 49.338871240615845,\n",
       " 608: 33.70429873466492,\n",
       " 609: 36.91572546958923,\n",
       " 610: 49.338871240615845,\n",
       " 611: 33.70429873466492,\n",
       " 612: 36.91572546958923,\n",
       " 613: 49.338871240615845,\n",
       " 614: 33.70429873466492,\n",
       " 615: 36.91572546958923,\n",
       " 616: 49.338871240615845,\n",
       " 617: 33.70429873466492,\n",
       " 618: 36.91572546958923,\n",
       " 619: 49.338871240615845,\n",
       " 620: 33.70429873466492,\n",
       " 621: 36.91572546958923,\n",
       " 622: 49.338871240615845,\n",
       " 623: 33.70429873466492,\n",
       " 624: 36.91572546958923,\n",
       " 625: 49.338871240615845,\n",
       " 626: 33.70429873466492,\n",
       " 627: 36.91572546958923,\n",
       " 628: 49.338871240615845,\n",
       " 629: 33.70429873466492,\n",
       " 630: 36.91572546958923,\n",
       " 631: 49.338871240615845,\n",
       " 632: 33.70429873466492,\n",
       " 633: 36.91572546958923,\n",
       " 634: 49.338871240615845,\n",
       " 635: 33.70429873466492,\n",
       " 636: 36.91572546958923,\n",
       " 637: 49.338871240615845,\n",
       " 638: 33.70429873466492,\n",
       " 639: 36.91572546958923,\n",
       " 640: 49.338871240615845,\n",
       " 641: 33.70429873466492,\n",
       " 642: 36.91572546958923,\n",
       " 643: 49.338871240615845,\n",
       " 644: 33.70429873466492,\n",
       " 645: 36.91572546958923,\n",
       " 646: 49.338871240615845,\n",
       " 647: 33.70429873466492,\n",
       " 648: 36.91572546958923,\n",
       " 649: 49.338871240615845,\n",
       " 650: 33.70429873466492,\n",
       " 651: 36.91572546958923,\n",
       " 652: 49.338871240615845,\n",
       " 653: 33.70429873466492,\n",
       " 654: 36.142972111701965,\n",
       " 655: 23.32623302936554,\n",
       " 656: 34.00481343269348,\n",
       " 657: 31.633776426315308,\n",
       " 658: 24.210456013679504,\n",
       " 659: 36.142972111701965,\n",
       " 660: 23.32623302936554,\n",
       " 661: 34.00481343269348,\n",
       " 662: 31.633776426315308,\n",
       " 663: 24.210456013679504,\n",
       " 664: 36.142972111701965,\n",
       " 665: 23.32623302936554,\n",
       " 666: 34.00481343269348,\n",
       " 667: 31.633776426315308,\n",
       " 668: 24.210456013679504,\n",
       " 669: 36.142972111701965,\n",
       " 670: 23.32623302936554,\n",
       " 671: 34.00481343269348,\n",
       " 672: 31.633776426315308,\n",
       " 673: 24.210456013679504,\n",
       " 674: 36.142972111701965,\n",
       " 675: 23.32623302936554,\n",
       " 676: 34.00481343269348,\n",
       " 677: 31.633776426315308,\n",
       " 678: 24.210456013679504,\n",
       " 679: 45.00574469566345,\n",
       " 680: 43.222951889038086,\n",
       " 681: 35.19543409347534,\n",
       " 682: 45.00574469566345,\n",
       " 683: 43.222951889038086,\n",
       " 684: 35.19543409347534,\n",
       " 685: 45.00574469566345,\n",
       " 686: 43.222951889038086,\n",
       " 687: 35.19543409347534,\n",
       " 688: 45.00574469566345,\n",
       " 689: 43.222951889038086,\n",
       " 690: 35.19543409347534,\n",
       " 691: 45.00574469566345,\n",
       " 692: 43.222951889038086,\n",
       " 693: 35.19543409347534,\n",
       " 694: 45.00574469566345,\n",
       " 695: 43.222951889038086,\n",
       " 696: 35.19543409347534,\n",
       " 697: 45.00574469566345,\n",
       " 698: 43.222951889038086,\n",
       " 699: 35.19543409347534,\n",
       " 700: 45.00574469566345,\n",
       " 701: 43.222951889038086,\n",
       " 702: 35.19543409347534,\n",
       " 703: 45.00574469566345,\n",
       " 704: 43.222951889038086,\n",
       " 705: 35.19543409347534,\n",
       " 706: 45.00574469566345,\n",
       " 707: 43.222951889038086,\n",
       " 708: 35.19543409347534,\n",
       " 709: 37.052541971206665,\n",
       " 710: 42.25364327430725,\n",
       " 711: 38.201987743377686,\n",
       " 712: 39.068907499313354,\n",
       " 713: 34.285932779312134,\n",
       " 714: 38.48777711391449,\n",
       " 715: 35.71384251117706,\n",
       " 716: 38.35999369621277,\n",
       " 717: 41.607269644737244,\n",
       " 718: 39.86353576183319,\n",
       " 719: 39.683908224105835,\n",
       " 720: 37.052541971206665,\n",
       " 721: 42.25364327430725,\n",
       " 722: 38.201987743377686,\n",
       " 723: 39.068907499313354,\n",
       " 724: 34.285932779312134,\n",
       " 725: 38.48777711391449,\n",
       " 726: 35.71384251117706,\n",
       " 727: 38.35999369621277,\n",
       " 728: 41.607269644737244,\n",
       " 729: 39.86353576183319,\n",
       " 730: 39.683908224105835,\n",
       " 731: 37.052541971206665,\n",
       " 732: 42.25364327430725,\n",
       " 733: 38.201987743377686,\n",
       " 734: 39.068907499313354,\n",
       " 735: 34.285932779312134,\n",
       " 736: 38.48777711391449,\n",
       " 737: 35.71384251117706,\n",
       " 738: 38.35999369621277,\n",
       " 739: 41.607269644737244,\n",
       " 740: 39.86353576183319,\n",
       " 741: 39.683908224105835,\n",
       " 742: 26.51163935661316,\n",
       " 743: 33.07206332683563,\n",
       " 744: 25.15617311000824,\n",
       " 745: 37.32943832874298,\n",
       " 746: 34.94551181793213,\n",
       " 747: 46.60930037498474,\n",
       " 748: 31.37207329273224,\n",
       " 749: 26.51163935661316,\n",
       " 750: 33.07206332683563,\n",
       " 751: 25.15617311000824,\n",
       " 752: 37.32943832874298,\n",
       " 753: 34.94551181793213,\n",
       " 754: 46.60930037498474,\n",
       " 755: 31.37207329273224,\n",
       " 756: 26.51163935661316,\n",
       " 757: 33.07206332683563,\n",
       " 758: 25.15617311000824,\n",
       " 759: 37.32943832874298,\n",
       " 760: 34.94551181793213,\n",
       " 761: 46.60930037498474,\n",
       " 762: 31.37207329273224,\n",
       " 763: 26.51163935661316,\n",
       " 764: 33.07206332683563,\n",
       " 765: 25.15617311000824,\n",
       " 766: 37.32943832874298,\n",
       " 767: 34.94551181793213,\n",
       " 768: 46.60930037498474,\n",
       " 769: 31.37207329273224,\n",
       " 770: 26.51163935661316,\n",
       " 771: 33.07206332683563,\n",
       " 772: 25.15617311000824,\n",
       " 773: 37.32943832874298,\n",
       " 774: 34.94551181793213,\n",
       " 775: 46.60930037498474,\n",
       " 776: 31.37207329273224,\n",
       " 777: 26.51163935661316,\n",
       " 778: 33.07206332683563,\n",
       " 779: 25.15617311000824,\n",
       " 780: 37.32943832874298,\n",
       " 781: 34.94551181793213,\n",
       " 782: 46.60930037498474,\n",
       " 783: 31.37207329273224,\n",
       " 784: 43.478116393089294,\n",
       " 785: 33.03448557853699,\n",
       " 786: 48.250776529312134,\n",
       " 787: 40.21484553813934,\n",
       " 788: 44.71197724342346,\n",
       " 789: 43.478116393089294,\n",
       " 790: 33.03448557853699,\n",
       " 791: 48.250776529312134,\n",
       " 792: 40.21484553813934,\n",
       " 793: 44.71197724342346,\n",
       " 794: 43.478116393089294,\n",
       " 795: 33.03448557853699,\n",
       " 796: 48.250776529312134,\n",
       " 797: 40.21484553813934,\n",
       " 798: 44.71197724342346,\n",
       " 799: 43.478116393089294,\n",
       " 800: 33.03448557853699,\n",
       " 801: 48.250776529312134,\n",
       " 802: 40.21484553813934,\n",
       " 803: 44.71197724342346,\n",
       " 804: 43.478116393089294,\n",
       " 805: 33.03448557853699,\n",
       " 806: 48.250776529312134,\n",
       " 807: 40.21484553813934,\n",
       " 808: 44.71197724342346,\n",
       " 809: 43.478116393089294,\n",
       " 810: 33.03448557853699,\n",
       " 811: 48.250776529312134,\n",
       " 812: 40.21484553813934,\n",
       " 813: 44.71197724342346,\n",
       " 814: 43.478116393089294,\n",
       " 815: 33.03448557853699,\n",
       " 816: 48.250776529312134,\n",
       " 817: 40.21484553813934,\n",
       " 818: 44.71197724342346,\n",
       " 819: 43.478116393089294,\n",
       " 820: 33.03448557853699,\n",
       " 821: 48.250776529312134,\n",
       " 822: 40.21484553813934,\n",
       " 823: 44.71197724342346,\n",
       " 824: 42.295944690704346,\n",
       " 825: 38.76255750656128,\n",
       " 826: 34.912097454071045,\n",
       " 827: 55.4507851600647,\n",
       " 828: 34.70042645931244,\n",
       " 829: 35.71991324424744,\n",
       " 830: 32.44980573654175,\n",
       " 831: 42.295944690704346,\n",
       " 832: 38.76255750656128,\n",
       " 833: 34.912097454071045,\n",
       " 834: 55.4507851600647,\n",
       " 835: 34.70042645931244,\n",
       " 836: 35.71991324424744,\n",
       " 837: 32.44980573654175,\n",
       " 838: 42.295944690704346,\n",
       " 839: 38.76255750656128,\n",
       " 840: 34.912097454071045,\n",
       " 841: 55.4507851600647,\n",
       " 842: 34.70042645931244,\n",
       " 843: 35.71991324424744,\n",
       " 844: 32.44980573654175,\n",
       " 845: 42.295944690704346,\n",
       " 846: 38.76255750656128,\n",
       " 847: 34.912097454071045,\n",
       " 848: 55.4507851600647,\n",
       " 849: 34.70042645931244,\n",
       " 850: 35.71991324424744,\n",
       " 851: 32.44980573654175,\n",
       " 852: 44.24559473991394,\n",
       " 853: 42.25122034549713,\n",
       " 854: 51.692986488342285,\n",
       " 855: 42.1818882226944,\n",
       " 856: 35.1059764623642,\n",
       " 857: 44.24559473991394,\n",
       " 858: 42.25122034549713,\n",
       " 859: 51.692986488342285,\n",
       " 860: 42.1818882226944,\n",
       " 861: 35.1059764623642,\n",
       " 862: 44.24559473991394,\n",
       " 863: 42.25122034549713,\n",
       " 864: 51.692986488342285,\n",
       " 865: 42.1818882226944,\n",
       " 866: 35.1059764623642,\n",
       " 867: 44.24559473991394,\n",
       " 868: 42.25122034549713,\n",
       " 869: 51.692986488342285,\n",
       " 870: 42.1818882226944,\n",
       " 871: 35.1059764623642,\n",
       " 872: 44.24559473991394,\n",
       " 873: 42.25122034549713,\n",
       " 874: 51.692986488342285,\n",
       " 875: 42.1818882226944,\n",
       " 876: 35.1059764623642,\n",
       " 877: 44.24559473991394,\n",
       " 878: 42.25122034549713,\n",
       " 879: 51.692986488342285,\n",
       " 880: 42.1818882226944,\n",
       " 881: 35.1059764623642,\n",
       " 882: 44.24559473991394,\n",
       " 883: 42.25122034549713,\n",
       " 884: 51.692986488342285,\n",
       " 885: 42.1818882226944,\n",
       " 886: 35.1059764623642,\n",
       " 887: 44.24559473991394,\n",
       " 888: 42.25122034549713,\n",
       " 889: 51.692986488342285,\n",
       " 890: 42.1818882226944,\n",
       " 891: 35.1059764623642}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_5={}\n",
    "for i in range(data_size):\n",
    "    result=0\n",
    "    result=matcher_5(fetched_job,data['cleaned_resume'][i])\n",
    "    result_dict_5[i]=result\n",
    "\n",
    "result_dict_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "sorted_dict_results_5 = dict(sorted(result_dict_5.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "top_5_items_5 = dict(list(sorted_dict_results_5.items())[:5])\n",
    "\n",
    "print(type(top_5_items_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResumeID</th>\n",
       "      <th>Matching Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>435</td>\n",
       "      <td>59.361297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>441</td>\n",
       "      <td>59.361297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>447</td>\n",
       "      <td>59.361297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>453</td>\n",
       "      <td>59.361297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>56.417882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ResumeID  Matching Percentage\n",
       "0       435            59.361297\n",
       "1       441            59.361297\n",
       "2       447            59.361297\n",
       "3       453            59.361297\n",
       "4        50            56.417882"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_5=pd.DataFrame(top_5_items_5.items(), columns=['ResumeID', 'Matching Percentage'])\n",
    "result_df_5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using glove with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_30880\\2120685729.py:8: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(PATH_TO_GLOVE, tmp_file)\n",
      "2023-06-21 19:16:51,146 : WARNING : duplicate word '����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������' in word2vec file, ignoring all but first\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m PATH_TO_GLOVE \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mWorkspace\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mProjects\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mResume Summarizer\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mResumeRanker_Shared\u001b[39m\u001b[39m\\\u001b[39m\u001b[39menv\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mResumeRanker_Shared\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mImplementation\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mglove.840B.300d\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mglove.840B.300d.txt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m tmp_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mWorkspace\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mProjects\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mResume Summarizer\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mResumeRanker_Shared\u001b[39m\u001b[39m\\\u001b[39m\u001b[39menv\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mResumeRanker_Shared\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mImplementation\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mGoogleNews-vectors-negative300.bin.gz\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m glove2word2vec(PATH_TO_GLOVE, tmp_file)\n\u001b[0;32m      9\u001b[0m \u001b[39m# glove = gensim.models.KeyedVectors.load_word2vec_format(tmp_file)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\gensim\\utils.py:1522\u001b[0m, in \u001b[0;36mdeprecated.<locals>.decorator.<locals>.new_func1\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m   1516\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_func1\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1517\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1518\u001b[0m         fmt\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, reason\u001b[39m=\u001b[39mreason),\n\u001b[0;32m   1519\u001b[0m         category\u001b[39m=\u001b[39m\u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m   1520\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m   1521\u001b[0m     )\n\u001b[1;32m-> 1522\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\gensim\\scripts\\glove2word2vec.py:109\u001b[0m, in \u001b[0;36mglove2word2vec\u001b[1;34m(glove_input_file, word2vec_output_file)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39m@deprecated\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mKeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mglove2word2vec\u001b[39m(glove_input_file, word2vec_output_file):\n\u001b[0;32m     94\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert `glove_input_file` in GloVe format to word2vec format and write it to `word2vec_output_file`.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[0;32m     96\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \n\u001b[0;32m    108\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     glovekv \u001b[39m=\u001b[39m KeyedVectors\u001b[39m.\u001b[39;49mload_word2vec_format(glove_input_file, binary\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, no_header\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    111\u001b[0m     num_lines, num_dims \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(glovekv), glovekv\u001b[39m.\u001b[39mvector_size\n\u001b[0;32m    112\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mconverting \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m vectors from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, num_lines, glove_input_file, word2vec_output_file)\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[39mcls\u001b[39m, fname, fvocab\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m, unicode_errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, datatype\u001b[39m=\u001b[39mREAL, no_header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[39m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[0;32m   1720\u001b[0m         \u001b[39mcls\u001b[39;49m, fname, fvocab\u001b[39m=\u001b[39;49mfvocab, binary\u001b[39m=\u001b[39;49mbinary, encoding\u001b[39m=\u001b[39;49mencoding, unicode_errors\u001b[39m=\u001b[39;49municode_errors,\n\u001b[0;32m   1721\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit, datatype\u001b[39m=\u001b[39;49mdatatype, no_header\u001b[39m=\u001b[39;49mno_header,\n\u001b[0;32m   1722\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2069\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2065\u001b[0m         _word2vec_read_binary(\n\u001b[0;32m   2066\u001b[0m             fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[0;32m   2067\u001b[0m         )\n\u001b[0;32m   2068\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2069\u001b[0m         _word2vec_read_text(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\n\u001b[0;32m   2070\u001b[0m \u001b[39mif\u001b[39;00m kv\u001b[39m.\u001b[39mvectors\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(kv):\n\u001b[0;32m   2071\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m   2072\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mduplicate words detected, shrinking matrix size from \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2073\u001b[0m         kv\u001b[39m.\u001b[39mvectors\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39mlen\u001b[39m(kv),\n\u001b[0;32m   2074\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1971\u001b[0m, in \u001b[0;36m_word2vec_read_text\u001b[1;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[0;32m   1969\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_word2vec_read_text\u001b[39m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding):\n\u001b[0;32m   1970\u001b[0m     \u001b[39mfor\u001b[39;00m line_no \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(vocab_size):\n\u001b[1;32m-> 1971\u001b[0m         line \u001b[39m=\u001b[39m fin\u001b[39m.\u001b[39;49mreadline()\n\u001b[0;32m   1972\u001b[0m         \u001b[39mif\u001b[39;00m line \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1973\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munexpected end of input; is count incorrect or file otherwise damaged?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "PATH_TO_GLOVE = \"C:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\ResumeRanker_Shared\\Implementation\\glove.840B.300d\\glove.840B.300d.txt\"\n",
    "\n",
    "tmp_file = \"C:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\ResumeRanker_Shared\\Implementation\\GoogleNews-vectors-negative300.bin.gz\"\n",
    "glove2word2vec(PATH_TO_GLOVE, tmp_file)\n",
    "# glove = gensim.models.KeyedVectors.load_word2vec_format(tmp_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the predictions of models manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job details: Develop information systems by architecting, designing, and implementing advanced software solutions. Create software by studying business needs, conferring with process owners, and examining systems flow, data usage, and work processes. Author documentation, flowcharts, layouts, diagrams, charts, code comments, and clear code for solutions development. Bachelor’s and/or master’s degree in computer science, computer engineering, data sciences, or related technical discipline 5+ years of professional software development experience Experience with computer vision or nlp Proficiency in Java or C++\n"
     ]
    }
   ],
   "source": [
    "print(fetched_job)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Science\n",
      "Data Science\n",
      "Data Science\n",
      "Data Science\n",
      "HR\n"
     ]
    }
   ],
   "source": [
    "print(data['Category'][6])\n",
    "print(data['Category'][16])\n",
    "print(data['Category'][26])\n",
    "print(data['Category'][36])\n",
    "print(data['Category'][50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Analyst\n",
      "Business Analyst\n",
      "ETL Developer\n",
      "ETL Developer\n",
      "ETL Developer\n"
     ]
    }
   ],
   "source": [
    "print(data['Category'][404])\n",
    "print(data['Category'][418])\n",
    "print(data['Category'][786])\n",
    "print(data['Category'][791])\n",
    "print(data['Category'][796])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health and fitness\n",
      "Health and fitness\n",
      "Health and fitness\n",
      "Health and fitness\n",
      "Health and fitness\n"
     ]
    }
   ],
   "source": [
    "print(data['Category'][266])\n",
    "print(data['Category'][272])\n",
    "print(data['Category'][278])\n",
    "print(data['Category'][284])\n",
    "print(data['Category'][290])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAP Developer\n",
      "SAP Developer\n",
      "SAP Developer\n",
      "SAP Developer\n",
      "HR\n"
     ]
    }
   ],
   "source": [
    "print(data['Category'][435])\n",
    "print(data['Category'][441])\n",
    "print(data['Category'][447])\n",
    "print(data['Category'][453])\n",
    "print(data['Category'][50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR\n",
      "HR\n",
      "HR\n",
      "HR\n",
      "SAP Developer\n"
     ]
    }
   ],
   "source": [
    "print(data['Category'][50])\n",
    "print(data['Category'][61])\n",
    "print(data['Category'][72])\n",
    "print(data['Category'][83])\n",
    "print(data['Category'][435])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach II (Targetting just skills extracted instead of supplying complete resume and job descriptions as text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " [],\n",
       " None,\n",
       " {'Java',\n",
       "  'computer science',\n",
       "  'documentation',\n",
       "  'engineering',\n",
       "  'process',\n",
       "  'technical'},\n",
       " [],\n",
       " 'Job details: Develop information systems by architecting, designing, and implementing advanced software solutions. Create software by studying business needs, conferring with process owners, and examining systems flow, data usage, and work processes. Author documentation, flowcharts, layouts, diagrams, charts, code comments, and clear code for solutions development. Bachelor’s and/or master’s degree in computer science, computer engineering, data sciences, or related technical discipline 5+ years of professional software development experience Experience with computer vision or nlp Proficiency in Java or C++')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_job=resumeExtractor.extractorData((r\"C:\\Workspace\\Projects\\Resume Summarizer\\ResumeRanker_Shared\\env\\ResumeRanker_Shared\\Implementation\\job_desc.docx\"),\"docx\")\n",
    "fetch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_job_skills=list(fetch_job[3])\n",
    "type(fetch_job_skills)\n",
    "fetch_data_skills=list(fetched_data[3])\n",
    "type(fetch_data_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.15554332733154"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=[fetch_job_skills,fetch_data_skills]\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# sen = job_desc+fetched_data[5]\n",
    "sen_embeddings = model.encode(text)\n",
    "(sen_embeddings).shape\n",
    "(cosine_similarity([sen_embeddings[0],sen_embeddings[1]])[0][1])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 43.05124282836914,\n",
       " 1: 32.539376616477966,\n",
       " 2: 41.83146357536316,\n",
       " 3: 35.34024953842163,\n",
       " 4: 47.32142388820648,\n",
       " 5: 45.67066431045532,\n",
       " 6: 40.717458724975586,\n",
       " 7: 37.57208585739136,\n",
       " 8: 40.71521759033203,\n",
       " 9: 34.33138728141785,\n",
       " 10: 43.05124282836914,\n",
       " 11: 32.539376616477966,\n",
       " 12: 41.83146357536316,\n",
       " 13: 35.34024953842163,\n",
       " 14: 47.32142388820648,\n",
       " 15: 45.67066431045532,\n",
       " 16: 40.717458724975586,\n",
       " 17: 37.57208585739136,\n",
       " 18: 40.71521759033203,\n",
       " 19: 34.33138728141785,\n",
       " 20: 43.05124282836914,\n",
       " 21: 32.539376616477966,\n",
       " 22: 41.83146357536316,\n",
       " 23: 35.34024953842163,\n",
       " 24: 47.32142388820648,\n",
       " 25: 45.67066431045532,\n",
       " 26: 40.717458724975586,\n",
       " 27: 37.57208585739136,\n",
       " 28: 40.71521759033203,\n",
       " 29: 34.33138728141785,\n",
       " 30: 43.05124282836914,\n",
       " 31: 32.539376616477966,\n",
       " 32: 41.83146357536316,\n",
       " 33: 35.34024953842163,\n",
       " 34: 47.32142388820648,\n",
       " 35: 45.67066431045532,\n",
       " 36: 40.717458724975586,\n",
       " 37: 37.57208585739136,\n",
       " 38: 40.71521759033203,\n",
       " 39: 34.33138728141785,\n",
       " 40: 46.720218658447266,\n",
       " 41: 29.898402094841003,\n",
       " 42: 32.628023624420166,\n",
       " 43: 32.260143756866455,\n",
       " 44: 32.260143756866455,\n",
       " 45: 34.94042456150055,\n",
       " 46: 34.4704806804657,\n",
       " 47: 42.824989557266235,\n",
       " 48: 25.462999939918518,\n",
       " 49: 47.106072306632996,\n",
       " 50: 56.2012255191803,\n",
       " 51: 46.720218658447266,\n",
       " 52: 29.898402094841003,\n",
       " 53: 32.628023624420166,\n",
       " 54: 32.260143756866455,\n",
       " 55: 32.260143756866455,\n",
       " 56: 34.94042456150055,\n",
       " 57: 34.4704806804657,\n",
       " 58: 42.824989557266235,\n",
       " 59: 25.462999939918518,\n",
       " 60: 47.106072306632996,\n",
       " 61: 56.2012255191803,\n",
       " 62: 46.720218658447266,\n",
       " 63: 29.898402094841003,\n",
       " 64: 32.628023624420166,\n",
       " 65: 32.260143756866455,\n",
       " 66: 32.260143756866455,\n",
       " 67: 34.94042456150055,\n",
       " 68: 34.4704806804657,\n",
       " 69: 42.824989557266235,\n",
       " 70: 25.462999939918518,\n",
       " 71: 47.106072306632996,\n",
       " 72: 56.2012255191803,\n",
       " 73: 46.720218658447266,\n",
       " 74: 29.898402094841003,\n",
       " 75: 32.628023624420166,\n",
       " 76: 32.260143756866455,\n",
       " 77: 32.260143756866455,\n",
       " 78: 34.94042456150055,\n",
       " 79: 34.4704806804657,\n",
       " 80: 42.824989557266235,\n",
       " 81: 25.462999939918518,\n",
       " 82: 47.106072306632996,\n",
       " 83: 56.2012255191803,\n",
       " 84: 31.238314509391785,\n",
       " 85: 40.966230630874634,\n",
       " 86: 22.245126962661743,\n",
       " 87: 28.37728261947632,\n",
       " 88: 28.775572776794434,\n",
       " 89: 34.82339382171631,\n",
       " 90: 41.181403398513794,\n",
       " 91: 26.774993538856506,\n",
       " 92: 28.534787893295288,\n",
       " 93: 34.99539494514465,\n",
       " 94: 31.238314509391785,\n",
       " 95: 40.966230630874634,\n",
       " 96: 22.245126962661743,\n",
       " 97: 28.37728261947632,\n",
       " 98: 28.775572776794434,\n",
       " 99: 34.82339382171631,\n",
       " 100: 41.181403398513794,\n",
       " 101: 26.774993538856506,\n",
       " 102: 28.534787893295288,\n",
       " 103: 34.99539494514465,\n",
       " 104: 33.516451716423035,\n",
       " 105: 45.26365399360657,\n",
       " 106: 26.357179880142212,\n",
       " 107: 23.577359318733215,\n",
       " 108: 22.364723682403564,\n",
       " 109: 39.32866156101227,\n",
       " 110: 33.516451716423035,\n",
       " 111: 45.26365399360657,\n",
       " 112: 26.357179880142212,\n",
       " 113: 23.577359318733215,\n",
       " 114: 22.364723682403564,\n",
       " 115: 39.32866156101227,\n",
       " 116: 33.516451716423035,\n",
       " 117: 45.26365399360657,\n",
       " 118: 26.357179880142212,\n",
       " 119: 23.577359318733215,\n",
       " 120: 22.364723682403564,\n",
       " 121: 39.32866156101227,\n",
       " 122: 33.516451716423035,\n",
       " 123: 45.26365399360657,\n",
       " 124: 26.357179880142212,\n",
       " 125: 23.577359318733215,\n",
       " 126: 22.364723682403564,\n",
       " 127: 39.32866156101227,\n",
       " 128: 33.516451716423035,\n",
       " 129: 45.26365399360657,\n",
       " 130: 26.357179880142212,\n",
       " 131: 23.577359318733215,\n",
       " 132: 22.364723682403564,\n",
       " 133: 39.32866156101227,\n",
       " 134: 33.516451716423035,\n",
       " 135: 45.26365399360657,\n",
       " 136: 26.357179880142212,\n",
       " 137: 23.577359318733215,\n",
       " 138: 22.364723682403564,\n",
       " 139: 39.32866156101227,\n",
       " 140: 32.25955367088318,\n",
       " 141: 39.570263028144836,\n",
       " 142: 32.25955367088318,\n",
       " 143: 42.58585870265961,\n",
       " 144: 48.552703857421875,\n",
       " 145: 32.25955367088318,\n",
       " 146: 39.570263028144836,\n",
       " 147: 32.25955367088318,\n",
       " 148: 42.58585870265961,\n",
       " 149: 48.552703857421875,\n",
       " 150: 32.25955367088318,\n",
       " 151: 39.570263028144836,\n",
       " 152: 32.25955367088318,\n",
       " 153: 42.58585870265961,\n",
       " 154: 48.552703857421875,\n",
       " 155: 32.25955367088318,\n",
       " 156: 39.570263028144836,\n",
       " 157: 32.25955367088318,\n",
       " 158: 42.58585870265961,\n",
       " 159: 48.552703857421875,\n",
       " 160: 32.25955367088318,\n",
       " 161: 39.570263028144836,\n",
       " 162: 32.25955367088318,\n",
       " 163: 42.58585870265961,\n",
       " 164: 48.552703857421875,\n",
       " 165: 32.25955367088318,\n",
       " 166: 39.570263028144836,\n",
       " 167: 32.25955367088318,\n",
       " 168: 42.58585870265961,\n",
       " 169: 48.552703857421875,\n",
       " 170: 32.25955367088318,\n",
       " 171: 39.570263028144836,\n",
       " 172: 32.25955367088318,\n",
       " 173: 42.58585870265961,\n",
       " 174: 48.552703857421875,\n",
       " 175: 32.25955367088318,\n",
       " 176: 39.570263028144836,\n",
       " 177: 32.25955367088318,\n",
       " 178: 42.58585870265961,\n",
       " 179: 48.552703857421875,\n",
       " 180: 32.25955367088318,\n",
       " 181: 39.570263028144836,\n",
       " 182: 32.25955367088318,\n",
       " 183: 42.58585870265961,\n",
       " 184: 48.552703857421875,\n",
       " 185: 34.990161657333374,\n",
       " 186: 38.59925866127014,\n",
       " 187: 36.586761474609375,\n",
       " 188: 36.84258460998535,\n",
       " 189: 39.86731171607971,\n",
       " 190: 34.990161657333374,\n",
       " 191: 38.59925866127014,\n",
       " 192: 36.586761474609375,\n",
       " 193: 36.84258460998535,\n",
       " 194: 39.86731171607971,\n",
       " 195: 34.990161657333374,\n",
       " 196: 38.59925866127014,\n",
       " 197: 36.586761474609375,\n",
       " 198: 36.84258460998535,\n",
       " 199: 39.86731171607971,\n",
       " 200: 34.990161657333374,\n",
       " 201: 38.59925866127014,\n",
       " 202: 36.586761474609375,\n",
       " 203: 36.84258460998535,\n",
       " 204: 39.86731171607971,\n",
       " 205: 34.990161657333374,\n",
       " 206: 38.59925866127014,\n",
       " 207: 36.586761474609375,\n",
       " 208: 36.84258460998535,\n",
       " 209: 39.86731171607971,\n",
       " 210: 34.990161657333374,\n",
       " 211: 38.59925866127014,\n",
       " 212: 36.586761474609375,\n",
       " 213: 36.84258460998535,\n",
       " 214: 39.86731171607971,\n",
       " 215: 34.990161657333374,\n",
       " 216: 38.59925866127014,\n",
       " 217: 36.586761474609375,\n",
       " 218: 36.84258460998535,\n",
       " 219: 39.86731171607971,\n",
       " 220: 34.990161657333374,\n",
       " 221: 38.59925866127014,\n",
       " 222: 36.586761474609375,\n",
       " 223: 36.84258460998535,\n",
       " 224: 39.86731171607971,\n",
       " 225: 29.955971240997314,\n",
       " 226: 32.16138184070587,\n",
       " 227: 27.756643295288086,\n",
       " 228: 23.59502613544464,\n",
       " 229: 38.222312927246094,\n",
       " 230: 29.955971240997314,\n",
       " 231: 32.16138184070587,\n",
       " 232: 27.756643295288086,\n",
       " 233: 23.59502613544464,\n",
       " 234: 38.222312927246094,\n",
       " 235: 29.955971240997314,\n",
       " 236: 32.16138184070587,\n",
       " 237: 27.756643295288086,\n",
       " 238: 23.59502613544464,\n",
       " 239: 38.222312927246094,\n",
       " 240: 29.955971240997314,\n",
       " 241: 32.16138184070587,\n",
       " 242: 27.756643295288086,\n",
       " 243: 23.59502613544464,\n",
       " 244: 38.222312927246094,\n",
       " 245: 29.955971240997314,\n",
       " 246: 32.16138184070587,\n",
       " 247: 27.756643295288086,\n",
       " 248: 23.59502613544464,\n",
       " 249: 38.222312927246094,\n",
       " 250: 29.955971240997314,\n",
       " 251: 32.16138184070587,\n",
       " 252: 27.756643295288086,\n",
       " 253: 23.59502613544464,\n",
       " 254: 38.222312927246094,\n",
       " 255: 29.955971240997314,\n",
       " 256: 32.16138184070587,\n",
       " 257: 27.756643295288086,\n",
       " 258: 23.59502613544464,\n",
       " 259: 38.222312927246094,\n",
       " 260: 29.955971240997314,\n",
       " 261: 32.16138184070587,\n",
       " 262: 27.756643295288086,\n",
       " 263: 23.59502613544464,\n",
       " 264: 38.222312927246094,\n",
       " 265: 31.247252225875854,\n",
       " 266: 19.201558828353882,\n",
       " 267: 19.232268631458282,\n",
       " 268: 18.04724484682083,\n",
       " 269: 26.098763942718506,\n",
       " 270: 4.278603941202164,\n",
       " 271: 31.247252225875854,\n",
       " 272: 19.201558828353882,\n",
       " 273: 19.232268631458282,\n",
       " 274: 18.04724484682083,\n",
       " 275: 26.098763942718506,\n",
       " 276: 4.278603941202164,\n",
       " 277: 31.247252225875854,\n",
       " 278: 19.201558828353882,\n",
       " 279: 19.232268631458282,\n",
       " 280: 18.04724484682083,\n",
       " 281: 26.098763942718506,\n",
       " 282: 4.278603941202164,\n",
       " 283: 31.247252225875854,\n",
       " 284: 19.201558828353882,\n",
       " 285: 19.232268631458282,\n",
       " 286: 18.04724484682083,\n",
       " 287: 26.098763942718506,\n",
       " 288: 4.278603941202164,\n",
       " 289: 31.247252225875854,\n",
       " 290: 19.201558828353882,\n",
       " 291: 19.232268631458282,\n",
       " 292: 18.04724484682083,\n",
       " 293: 26.098763942718506,\n",
       " 294: 4.278603941202164,\n",
       " 295: 29.977867007255554,\n",
       " 296: 41.128844022750854,\n",
       " 297: 27.77075171470642,\n",
       " 298: 28.272873163223267,\n",
       " 299: 37.96985745429993,\n",
       " 300: 46.74554467201233,\n",
       " 301: 29.977867007255554,\n",
       " 302: 41.128844022750854,\n",
       " 303: 27.77075171470642,\n",
       " 304: 28.272873163223267,\n",
       " 305: 37.96985745429993,\n",
       " 306: 46.74554467201233,\n",
       " 307: 29.977867007255554,\n",
       " 308: 41.128844022750854,\n",
       " 309: 27.77075171470642,\n",
       " 310: 28.272873163223267,\n",
       " 311: 37.96985745429993,\n",
       " 312: 46.74554467201233,\n",
       " 313: 29.977867007255554,\n",
       " 314: 41.128844022750854,\n",
       " 315: 27.77075171470642,\n",
       " 316: 28.272873163223267,\n",
       " 317: 37.96985745429993,\n",
       " 318: 46.74554467201233,\n",
       " 319: 38.04645538330078,\n",
       " 320: 41.98977053165436,\n",
       " 321: 48.762622475624084,\n",
       " 322: 43.314045667648315,\n",
       " 323: 42.08550751209259,\n",
       " 324: 43.92269253730774,\n",
       " 325: 37.87580728530884,\n",
       " 326: 37.87580728530884,\n",
       " 327: 39.32836055755615,\n",
       " 328: 42.889922857284546,\n",
       " 329: 43.625301122665405,\n",
       " 330: 41.06817543506622,\n",
       " 331: 53.25326323509216,\n",
       " 332: 44.99098360538483,\n",
       " 333: 38.04645538330078,\n",
       " 334: 41.98977053165436,\n",
       " 335: 48.762622475624084,\n",
       " 336: 43.314045667648315,\n",
       " 337: 42.08550751209259,\n",
       " 338: 43.92269253730774,\n",
       " 339: 37.87580728530884,\n",
       " 340: 37.87580728530884,\n",
       " 341: 39.32836055755615,\n",
       " 342: 42.889922857284546,\n",
       " 343: 43.625301122665405,\n",
       " 344: 41.06817543506622,\n",
       " 345: 53.25326323509216,\n",
       " 346: 44.99098360538483,\n",
       " 347: 38.04645538330078,\n",
       " 348: 41.98977053165436,\n",
       " 349: 48.762622475624084,\n",
       " 350: 43.314045667648315,\n",
       " 351: 42.08550751209259,\n",
       " 352: 43.92269253730774,\n",
       " 353: 37.87580728530884,\n",
       " 354: 37.87580728530884,\n",
       " 355: 39.32836055755615,\n",
       " 356: 42.889922857284546,\n",
       " 357: 43.625301122665405,\n",
       " 358: 41.06817543506622,\n",
       " 359: 53.25326323509216,\n",
       " 360: 44.99098360538483,\n",
       " 361: 38.04645538330078,\n",
       " 362: 41.98977053165436,\n",
       " 363: 48.762622475624084,\n",
       " 364: 43.314045667648315,\n",
       " 365: 42.08550751209259,\n",
       " 366: 43.92269253730774,\n",
       " 367: 37.87580728530884,\n",
       " 368: 37.87580728530884,\n",
       " 369: 39.32836055755615,\n",
       " 370: 42.889922857284546,\n",
       " 371: 43.625301122665405,\n",
       " 372: 41.06817543506622,\n",
       " 373: 53.25326323509216,\n",
       " 374: 44.99098360538483,\n",
       " 375: 38.04645538330078,\n",
       " 376: 41.98977053165436,\n",
       " 377: 48.762622475624084,\n",
       " 378: 43.314045667648315,\n",
       " 379: 42.08550751209259,\n",
       " 380: 43.92269253730774,\n",
       " 381: 37.87580728530884,\n",
       " 382: 37.87580728530884,\n",
       " 383: 39.32836055755615,\n",
       " 384: 42.889922857284546,\n",
       " 385: 43.625301122665405,\n",
       " 386: 41.06817543506622,\n",
       " 387: 53.25326323509216,\n",
       " 388: 44.99098360538483,\n",
       " 389: 38.04645538330078,\n",
       " 390: 41.98977053165436,\n",
       " 391: 48.762622475624084,\n",
       " 392: 43.314045667648315,\n",
       " 393: 42.08550751209259,\n",
       " 394: 43.92269253730774,\n",
       " 395: 37.87580728530884,\n",
       " 396: 37.87580728530884,\n",
       " 397: 39.32836055755615,\n",
       " 398: 42.889922857284546,\n",
       " 399: 43.625301122665405,\n",
       " 400: 41.06817543506622,\n",
       " 401: 53.25326323509216,\n",
       " 402: 44.99098360538483,\n",
       " 403: 40.362149477005005,\n",
       " 404: 35.77786684036255,\n",
       " 405: 44.86386477947235,\n",
       " 406: 39.602041244506836,\n",
       " 407: 42.34923720359802,\n",
       " 408: 28.318604826927185,\n",
       " 409: 44.86386477947235,\n",
       " 410: 39.602041244506836,\n",
       " 411: 42.34923720359802,\n",
       " 412: 28.318604826927185,\n",
       " 413: 44.86386477947235,\n",
       " 414: 39.602041244506836,\n",
       " 415: 42.34923720359802,\n",
       " 416: 28.318604826927185,\n",
       " 417: 40.362149477005005,\n",
       " 418: 35.77786684036255,\n",
       " 419: 44.86386477947235,\n",
       " 420: 39.602041244506836,\n",
       " 421: 42.34923720359802,\n",
       " 422: 28.318604826927185,\n",
       " 423: 44.86386477947235,\n",
       " 424: 39.602041244506836,\n",
       " 425: 42.34923720359802,\n",
       " 426: 28.318604826927185,\n",
       " 427: 44.86386477947235,\n",
       " 428: 39.602041244506836,\n",
       " 429: 42.34923720359802,\n",
       " 430: 28.318604826927185,\n",
       " 431: 37.067848443984985,\n",
       " 432: 31.697440147399902,\n",
       " 433: 32.50204622745514,\n",
       " 434: 46.01438343524933,\n",
       " 435: 54.21258211135864,\n",
       " 436: 36.29329800605774,\n",
       " 437: 37.067848443984985,\n",
       " 438: 31.697440147399902,\n",
       " 439: 32.50204622745514,\n",
       " 440: 46.01438343524933,\n",
       " 441: 54.21258211135864,\n",
       " 442: 36.29329800605774,\n",
       " 443: 37.067848443984985,\n",
       " 444: 31.697440147399902,\n",
       " 445: 32.50204622745514,\n",
       " 446: 46.01438343524933,\n",
       " 447: 54.21258211135864,\n",
       " 448: 36.29329800605774,\n",
       " 449: 37.067848443984985,\n",
       " 450: 31.697440147399902,\n",
       " 451: 32.50204622745514,\n",
       " 452: 46.01438343524933,\n",
       " 453: 54.21258211135864,\n",
       " 454: 36.29329800605774,\n",
       " 455: 33.897531032562256,\n",
       " 456: 35.95683574676514,\n",
       " 457: 37.529540061950684,\n",
       " 458: 36.99004054069519,\n",
       " 459: 45.45503258705139,\n",
       " 460: 30.216670036315918,\n",
       " 461: 39.1521155834198,\n",
       " 462: 36.99004054069519,\n",
       " 463: 45.45503258705139,\n",
       " 464: 36.99004054069519,\n",
       " 465: 45.45503258705139,\n",
       " 466: 36.99004054069519,\n",
       " 467: 45.45503258705139,\n",
       " 468: 33.897531032562256,\n",
       " 469: 35.95683574676514,\n",
       " 470: 37.529540061950684,\n",
       " 471: 36.99004054069519,\n",
       " 472: 45.45503258705139,\n",
       " 473: 30.216670036315918,\n",
       " 474: 39.1521155834198,\n",
       " 475: 36.99004054069519,\n",
       " 476: 45.45503258705139,\n",
       " 477: 36.99004054069519,\n",
       " 478: 45.45503258705139,\n",
       " 479: 36.99004054069519,\n",
       " 480: 45.45503258705139,\n",
       " 481: 40.00069499015808,\n",
       " 482: 41.964191198349,\n",
       " 483: 33.56344699859619,\n",
       " 484: 31.756743788719177,\n",
       " 485: 25.188320875167847,\n",
       " 486: 40.00069499015808,\n",
       " 487: 41.964191198349,\n",
       " 488: 33.56344699859619,\n",
       " 489: 31.756743788719177,\n",
       " 490: 25.188320875167847,\n",
       " 491: 40.00069499015808,\n",
       " 492: 41.964191198349,\n",
       " 493: 33.56344699859619,\n",
       " 494: 31.756743788719177,\n",
       " 495: 25.188320875167847,\n",
       " 496: 40.00069499015808,\n",
       " 497: 41.964191198349,\n",
       " 498: 33.56344699859619,\n",
       " 499: 31.756743788719177,\n",
       " 500: 25.188320875167847,\n",
       " 501: 40.00069499015808,\n",
       " 502: 41.964191198349,\n",
       " 503: 33.56344699859619,\n",
       " 504: 31.756743788719177,\n",
       " 505: 25.188320875167847,\n",
       " 506: 40.00069499015808,\n",
       " 507: 41.964191198349,\n",
       " 508: 33.56344699859619,\n",
       " 509: 31.756743788719177,\n",
       " 510: 25.188320875167847,\n",
       " 511: 22.899597883224487,\n",
       " 512: 25.129014253616333,\n",
       " 513: 21.37444019317627,\n",
       " 514: 30.8408260345459,\n",
       " 515: 22.899597883224487,\n",
       " 516: 25.129014253616333,\n",
       " 517: 21.37444019317627,\n",
       " 518: 30.8408260345459,\n",
       " 519: 22.899597883224487,\n",
       " 520: 25.129014253616333,\n",
       " 521: 21.37444019317627,\n",
       " 522: 30.8408260345459,\n",
       " 523: 22.899597883224487,\n",
       " 524: 25.129014253616333,\n",
       " 525: 21.37444019317627,\n",
       " 526: 30.8408260345459,\n",
       " 527: 22.899597883224487,\n",
       " 528: 25.129014253616333,\n",
       " 529: 21.37444019317627,\n",
       " 530: 30.8408260345459,\n",
       " 531: 22.899597883224487,\n",
       " 532: 25.129014253616333,\n",
       " 533: 21.37444019317627,\n",
       " 534: 30.8408260345459,\n",
       " 535: 22.899597883224487,\n",
       " 536: 25.129014253616333,\n",
       " 537: 21.37444019317627,\n",
       " 538: 30.8408260345459,\n",
       " 539: 22.899597883224487,\n",
       " 540: 25.129014253616333,\n",
       " 541: 21.37444019317627,\n",
       " 542: 30.8408260345459,\n",
       " 543: 22.899597883224487,\n",
       " 544: 25.129014253616333,\n",
       " 545: 21.37444019317627,\n",
       " 546: 30.8408260345459,\n",
       " 547: 22.899597883224487,\n",
       " 548: 25.129014253616333,\n",
       " 549: 21.37444019317627,\n",
       " 550: 30.8408260345459,\n",
       " 551: 37.12121248245239,\n",
       " 552: 44.93628740310669,\n",
       " 553: 42.75934100151062,\n",
       " 554: 40.984147787094116,\n",
       " 555: 34.31462049484253,\n",
       " 556: 51.115429401397705,\n",
       " 557: 37.12121248245239,\n",
       " 558: 44.93628740310669,\n",
       " 559: 42.75934100151062,\n",
       " 560: 40.984147787094116,\n",
       " 561: 34.31462049484253,\n",
       " 562: 51.115429401397705,\n",
       " 563: 37.12121248245239,\n",
       " 564: 44.93628740310669,\n",
       " 565: 42.75934100151062,\n",
       " 566: 40.984147787094116,\n",
       " 567: 34.31462049484253,\n",
       " 568: 51.115429401397705,\n",
       " 569: 37.12121248245239,\n",
       " 570: 44.93628740310669,\n",
       " 571: 42.75934100151062,\n",
       " 572: 40.984147787094116,\n",
       " 573: 34.31462049484253,\n",
       " 574: 51.115429401397705,\n",
       " 575: 37.12121248245239,\n",
       " 576: 44.93628740310669,\n",
       " 577: 42.75934100151062,\n",
       " 578: 40.984147787094116,\n",
       " 579: 34.31462049484253,\n",
       " 580: 51.115429401397705,\n",
       " 581: 37.12121248245239,\n",
       " 582: 44.93628740310669,\n",
       " 583: 42.75934100151062,\n",
       " 584: 40.984147787094116,\n",
       " 585: 34.31462049484253,\n",
       " 586: 51.115429401397705,\n",
       " 587: 37.12121248245239,\n",
       " 588: 44.93628740310669,\n",
       " 589: 42.75934100151062,\n",
       " 590: 40.984147787094116,\n",
       " 591: 34.31462049484253,\n",
       " 592: 51.115429401397705,\n",
       " 593: 37.12121248245239,\n",
       " 594: 44.93628740310669,\n",
       " 595: 42.75934100151062,\n",
       " 596: 40.984147787094116,\n",
       " 597: 34.31462049484253,\n",
       " 598: 51.115429401397705,\n",
       " 599: 30.841118097305298,\n",
       " 600: 48.99514317512512,\n",
       " 601: 36.52437925338745,\n",
       " 602: 41.30861759185791,\n",
       " 603: 37.76639997959137,\n",
       " 604: 37.11235523223877,\n",
       " 605: 34.876906871795654,\n",
       " 606: 30.841118097305298,\n",
       " 607: 48.99514317512512,\n",
       " 608: 36.52437925338745,\n",
       " 609: 30.841118097305298,\n",
       " 610: 48.99514317512512,\n",
       " 611: 36.52437925338745,\n",
       " 612: 30.841118097305298,\n",
       " 613: 48.99514317512512,\n",
       " 614: 36.52437925338745,\n",
       " 615: 30.841118097305298,\n",
       " 616: 48.99514317512512,\n",
       " 617: 36.52437925338745,\n",
       " 618: 30.841118097305298,\n",
       " 619: 48.99514317512512,\n",
       " 620: 36.52437925338745,\n",
       " 621: 30.841118097305298,\n",
       " 622: 48.99514317512512,\n",
       " 623: 36.52437925338745,\n",
       " 624: 30.841118097305298,\n",
       " 625: 48.99514317512512,\n",
       " 626: 36.52437925338745,\n",
       " 627: 30.841118097305298,\n",
       " 628: 48.99514317512512,\n",
       " 629: 36.52437925338745,\n",
       " 630: 30.841118097305298,\n",
       " 631: 48.99514317512512,\n",
       " 632: 36.52437925338745,\n",
       " 633: 30.841118097305298,\n",
       " 634: 48.99514317512512,\n",
       " 635: 36.52437925338745,\n",
       " 636: 30.841118097305298,\n",
       " 637: 48.99514317512512,\n",
       " 638: 36.52437925338745,\n",
       " 639: 30.841118097305298,\n",
       " 640: 48.99514317512512,\n",
       " 641: 36.52437925338745,\n",
       " 642: 30.841118097305298,\n",
       " 643: 48.99514317512512,\n",
       " 644: 36.52437925338745,\n",
       " 645: 30.841118097305298,\n",
       " 646: 48.99514317512512,\n",
       " 647: 36.52437925338745,\n",
       " 648: 30.841118097305298,\n",
       " 649: 48.99514317512512,\n",
       " 650: 36.52437925338745,\n",
       " 651: 30.841118097305298,\n",
       " 652: 48.99514317512512,\n",
       " 653: 36.52437925338745,\n",
       " 654: 32.89068341255188,\n",
       " 655: 35.28355360031128,\n",
       " 656: 33.563822507858276,\n",
       " 657: 32.08284676074982,\n",
       " 658: 29.8301100730896,\n",
       " 659: 32.89068341255188,\n",
       " 660: 35.28355360031128,\n",
       " 661: 33.563822507858276,\n",
       " 662: 32.08284676074982,\n",
       " 663: 29.8301100730896,\n",
       " 664: 32.89068341255188,\n",
       " 665: 35.28355360031128,\n",
       " 666: 33.563822507858276,\n",
       " 667: 32.08284676074982,\n",
       " 668: 29.8301100730896,\n",
       " 669: 32.89068341255188,\n",
       " 670: 35.28355360031128,\n",
       " 671: 33.563822507858276,\n",
       " 672: 32.08284676074982,\n",
       " 673: 29.8301100730896,\n",
       " 674: 32.89068341255188,\n",
       " 675: 35.28355360031128,\n",
       " 676: 33.563822507858276,\n",
       " 677: 32.08284676074982,\n",
       " 678: 29.8301100730896,\n",
       " 679: 39.58894610404968,\n",
       " 680: 38.337671756744385,\n",
       " 681: 33.464476466178894,\n",
       " 682: 39.58894610404968,\n",
       " 683: 38.337671756744385,\n",
       " 684: 33.464476466178894,\n",
       " 685: 39.58894610404968,\n",
       " 686: 38.337671756744385,\n",
       " 687: 33.464476466178894,\n",
       " 688: 39.58894610404968,\n",
       " 689: 38.337671756744385,\n",
       " 690: 33.464476466178894,\n",
       " 691: 39.58894610404968,\n",
       " 692: 38.337671756744385,\n",
       " 693: 33.464476466178894,\n",
       " 694: 39.58894610404968,\n",
       " 695: 38.337671756744385,\n",
       " 696: 33.464476466178894,\n",
       " 697: 39.58894610404968,\n",
       " 698: 38.337671756744385,\n",
       " 699: 33.464476466178894,\n",
       " 700: 39.58894610404968,\n",
       " 701: 38.337671756744385,\n",
       " 702: 33.464476466178894,\n",
       " 703: 39.58894610404968,\n",
       " 704: 38.337671756744385,\n",
       " 705: 33.464476466178894,\n",
       " 706: 39.58894610404968,\n",
       " 707: 38.337671756744385,\n",
       " 708: 33.464476466178894,\n",
       " 709: 35.442692041397095,\n",
       " 710: 37.68472075462341,\n",
       " 711: 33.11850130558014,\n",
       " 712: 37.1778666973114,\n",
       " 713: 31.118375062942505,\n",
       " 714: 37.38996386528015,\n",
       " 715: 35.52519083023071,\n",
       " 716: 29.841864109039307,\n",
       " 717: 44.9741005897522,\n",
       " 718: 40.755921602249146,\n",
       " 719: 32.83863663673401,\n",
       " 720: 35.442692041397095,\n",
       " 721: 37.68472075462341,\n",
       " 722: 33.11850130558014,\n",
       " 723: 37.1778666973114,\n",
       " 724: 31.118375062942505,\n",
       " 725: 37.38996386528015,\n",
       " 726: 35.52519083023071,\n",
       " 727: 29.841864109039307,\n",
       " 728: 44.9741005897522,\n",
       " 729: 40.755921602249146,\n",
       " 730: 32.83863663673401,\n",
       " 731: 35.442692041397095,\n",
       " 732: 37.68472075462341,\n",
       " 733: 33.11850130558014,\n",
       " 734: 37.1778666973114,\n",
       " 735: 31.118375062942505,\n",
       " 736: 37.38996386528015,\n",
       " 737: 35.52519083023071,\n",
       " 738: 29.841864109039307,\n",
       " 739: 44.9741005897522,\n",
       " 740: 40.755921602249146,\n",
       " 741: 32.83863663673401,\n",
       " 742: 28.70897650718689,\n",
       " 743: 34.42971408367157,\n",
       " 744: 26.63325071334839,\n",
       " 745: 34.084635972976685,\n",
       " 746: 33.750128746032715,\n",
       " 747: 49.34956431388855,\n",
       " 748: 28.944507241249084,\n",
       " 749: 28.70897650718689,\n",
       " 750: 34.42971408367157,\n",
       " 751: 26.63325071334839,\n",
       " 752: 34.084635972976685,\n",
       " 753: 33.750128746032715,\n",
       " 754: 49.34956431388855,\n",
       " 755: 28.944507241249084,\n",
       " 756: 28.70897650718689,\n",
       " 757: 34.42971408367157,\n",
       " 758: 26.63325071334839,\n",
       " 759: 34.084635972976685,\n",
       " 760: 33.750128746032715,\n",
       " 761: 49.34956431388855,\n",
       " 762: 28.944507241249084,\n",
       " 763: 28.70897650718689,\n",
       " 764: 34.42971408367157,\n",
       " 765: 26.63325071334839,\n",
       " 766: 34.084635972976685,\n",
       " 767: 33.750128746032715,\n",
       " 768: 49.34956431388855,\n",
       " 769: 28.944507241249084,\n",
       " 770: 28.70897650718689,\n",
       " 771: 34.42971408367157,\n",
       " 772: 26.63325071334839,\n",
       " 773: 34.084635972976685,\n",
       " 774: 33.750128746032715,\n",
       " 775: 49.34956431388855,\n",
       " 776: 28.944507241249084,\n",
       " 777: 28.70897650718689,\n",
       " 778: 34.42971408367157,\n",
       " 779: 26.63325071334839,\n",
       " 780: 34.084635972976685,\n",
       " 781: 33.750128746032715,\n",
       " 782: 49.34956431388855,\n",
       " 783: 28.944507241249084,\n",
       " 784: 34.68095660209656,\n",
       " 785: 27.600693702697754,\n",
       " 786: 45.56864798069,\n",
       " 787: 36.92168593406677,\n",
       " 788: 40.85920751094818,\n",
       " 789: 34.68095660209656,\n",
       " 790: 27.600693702697754,\n",
       " 791: 45.56864798069,\n",
       " 792: 36.92168593406677,\n",
       " 793: 40.85920751094818,\n",
       " 794: 34.68095660209656,\n",
       " 795: 27.600693702697754,\n",
       " 796: 45.56864798069,\n",
       " 797: 36.92168593406677,\n",
       " 798: 40.85920751094818,\n",
       " 799: 34.68095660209656,\n",
       " 800: 27.600693702697754,\n",
       " 801: 45.56864798069,\n",
       " 802: 36.92168593406677,\n",
       " 803: 40.85920751094818,\n",
       " 804: 34.68095660209656,\n",
       " 805: 27.600693702697754,\n",
       " 806: 45.56864798069,\n",
       " 807: 36.92168593406677,\n",
       " 808: 40.85920751094818,\n",
       " 809: 34.68095660209656,\n",
       " 810: 27.600693702697754,\n",
       " 811: 45.56864798069,\n",
       " 812: 36.92168593406677,\n",
       " 813: 40.85920751094818,\n",
       " 814: 34.68095660209656,\n",
       " 815: 27.600693702697754,\n",
       " 816: 45.56864798069,\n",
       " 817: 36.92168593406677,\n",
       " 818: 40.85920751094818,\n",
       " 819: 34.68095660209656,\n",
       " 820: 27.600693702697754,\n",
       " 821: 45.56864798069,\n",
       " 822: 36.92168593406677,\n",
       " 823: 40.85920751094818,\n",
       " 824: 40.75692892074585,\n",
       " 825: 39.406752586364746,\n",
       " 826: 33.26999843120575,\n",
       " 827: 39.562609791755676,\n",
       " 828: 32.73393511772156,\n",
       " 829: 38.79936933517456,\n",
       " 830: 31.415265798568726,\n",
       " 831: 40.75692892074585,\n",
       " 832: 39.406752586364746,\n",
       " 833: 33.26999843120575,\n",
       " 834: 39.562609791755676,\n",
       " 835: 32.73393511772156,\n",
       " 836: 38.79936933517456,\n",
       " 837: 31.415265798568726,\n",
       " 838: 40.75692892074585,\n",
       " 839: 39.406752586364746,\n",
       " 840: 33.26999843120575,\n",
       " 841: 39.562609791755676,\n",
       " 842: 32.73393511772156,\n",
       " 843: 38.79936933517456,\n",
       " 844: 31.415265798568726,\n",
       " 845: 40.75692892074585,\n",
       " 846: 39.406752586364746,\n",
       " 847: 33.26999843120575,\n",
       " 848: 39.562609791755676,\n",
       " 849: 32.73393511772156,\n",
       " 850: 38.79936933517456,\n",
       " 851: 31.415265798568726,\n",
       " 852: 40.504246950149536,\n",
       " 853: 39.708900451660156,\n",
       " 854: 53.086650371551514,\n",
       " 855: 42.488718032836914,\n",
       " 856: 30.45620024204254,\n",
       " 857: 40.504246950149536,\n",
       " 858: 39.708900451660156,\n",
       " 859: 53.086650371551514,\n",
       " 860: 42.488718032836914,\n",
       " 861: 30.45620024204254,\n",
       " 862: 40.504246950149536,\n",
       " 863: 39.708900451660156,\n",
       " 864: 53.086650371551514,\n",
       " 865: 42.488718032836914,\n",
       " 866: 30.45620024204254,\n",
       " 867: 40.504246950149536,\n",
       " 868: 39.708900451660156,\n",
       " 869: 53.086650371551514,\n",
       " 870: 42.488718032836914,\n",
       " 871: 30.45620024204254,\n",
       " 872: 40.504246950149536,\n",
       " 873: 39.708900451660156,\n",
       " 874: 53.086650371551514,\n",
       " 875: 42.488718032836914,\n",
       " 876: 30.45620024204254,\n",
       " 877: 40.504246950149536,\n",
       " 878: 39.708900451660156,\n",
       " 879: 53.086650371551514,\n",
       " 880: 42.488718032836914,\n",
       " 881: 30.45620024204254,\n",
       " 882: 40.504246950149536,\n",
       " 883: 39.708900451660156,\n",
       " 884: 53.086650371551514,\n",
       " 885: 42.488718032836914,\n",
       " 886: 30.45620024204254,\n",
       " 887: 40.504246950149536,\n",
       " 888: 39.708900451660156,\n",
       " 889: 53.086650371551514,\n",
       " 890: 42.488718032836914,\n",
       " 891: 30.45620024204254}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_6={}\n",
    "for i in range(data_size):\n",
    "    result=0\n",
    "    result=matcher_5(fetch_job_skills,data['cleaned_resume'][i])\n",
    "    result_dict_6[i]=result\n",
    "\n",
    "result_dict_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResumeID</th>\n",
       "      <th>Matching Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>56.201226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>56.201226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>56.201226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83</td>\n",
       "      <td>56.201226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>435</td>\n",
       "      <td>54.212582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ResumeID  Matching Percentage\n",
       "0        50            56.201226\n",
       "1        61            56.201226\n",
       "2        72            56.201226\n",
       "3        83            56.201226\n",
       "4       435            54.212582"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dict_results_6 = dict(sorted(result_dict_6.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "top_5_items_6 = dict(list(sorted_dict_results_6.items())[:5])\n",
    "\n",
    "print(type(top_5_items_6))\n",
    "result_df_6=pd.DataFrame(top_5_items_6.items(), columns=['ResumeID', 'Matching Percentage'])\n",
    "result_df_6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
